{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_files_path = '../'\n",
    "import sys\n",
    "sys.path.append(py_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from utils import adjust_learning_rate\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "encoder_dim = 512\n",
    "emb_dim = 256  # dimension of word embeddings\n",
    "attention_dim = 256  # dimension of attention linear layers\n",
    "decoder_dim = 256  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# training parameters\n",
    "epochs = 1  # number of epochs to train for (if early stopping is not triggered)\n",
    "batch_size = 32\n",
    "workers = 4\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:00<00:00, 358207.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# load vocab\n",
    "vocab = build_vocab('../data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4451"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Dataset split: train\n",
      "Unique images: 6000\n",
      "Total size: 30000\n",
      "Dataset split: val\n",
      "Unique images: 1000\n",
      "Total size: 5000\n",
      "__________________________________________________\n",
      "-------------------- Fitting --------------------\n",
      "Epoch: [0][0/938]\tBatch Time 0.792 (0.792)\tData Load Time 0.593 (0.593)\tLoss 9.3271 (9.3271)\tTop-5 Accuracy 0.687 (0.687)\n",
      "Epoch: [0][100/938]\tBatch Time 0.174 (0.182)\tData Load Time 0.000 (0.006)\tLoss 6.1308 (6.7088)\tTop-5 Accuracy 34.824 (29.400)\n",
      "Epoch: [0][200/938]\tBatch Time 0.157 (0.177)\tData Load Time 0.000 (0.003)\tLoss 5.6063 (6.3051)\tTop-5 Accuracy 41.554 (32.847)\n",
      "Epoch: [0][300/938]\tBatch Time 0.182 (0.176)\tData Load Time 0.000 (0.002)\tLoss 5.6357 (6.0563)\tTop-5 Accuracy 43.003 (36.081)\n",
      "Epoch: [0][400/938]\tBatch Time 0.172 (0.174)\tData Load Time 0.000 (0.002)\tLoss 5.3434 (5.8833)\tTop-5 Accuracy 46.724 (38.698)\n",
      "Epoch: [0][500/938]\tBatch Time 0.168 (0.174)\tData Load Time 0.000 (0.001)\tLoss 4.9073 (5.7391)\tTop-5 Accuracy 52.786 (40.882)\n",
      "Epoch: [0][600/938]\tBatch Time 0.146 (0.174)\tData Load Time 0.000 (0.001)\tLoss 5.2694 (5.6286)\tTop-5 Accuracy 48.684 (42.516)\n",
      "Epoch: [0][700/938]\tBatch Time 0.171 (0.174)\tData Load Time 0.000 (0.001)\tLoss 4.9673 (5.5354)\tTop-5 Accuracy 50.156 (43.833)\n",
      "Epoch: [0][800/938]\tBatch Time 0.190 (0.174)\tData Load Time 0.000 (0.001)\tLoss 4.7173 (5.4577)\tTop-5 Accuracy 55.455 (44.997)\n",
      "Epoch: [0][900/938]\tBatch Time 0.185 (0.175)\tData Load Time 0.000 (0.001)\tLoss 4.8929 (5.3824)\tTop-5 Accuracy 52.038 (46.098)\n",
      "Validation: [0/157]\tBatch Time 0.684 (0.684)\tLoss 5.7259 (5.7259)\tTop-5 Accuracy 47.561 (47.561)\t\n",
      "Validation: [100/157]\tBatch Time 0.139 (0.155)\tLoss 5.8433 (5.7146)\tTop-5 Accuracy 46.302 (49.155)\t\n",
      "\n",
      " * LOSS - 5.671, TOP-5 ACCURACY - 49.569, BLEU-4 - 0.004648268726912672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_params = {\n",
    "    'data_name': 'flickr8k_5_cap_per_img_2_min_word_freq',\n",
    "    'imgs_path': '../flickr/Images/',\n",
    "    'df_path': '../data.json',\n",
    "    'vocab': vocab,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'workers': workers,\n",
    "    'decoder_lr': decoder_lr,\n",
    "    'encoder_lr': encoder_lr,\n",
    "    'fine_tune_encoder': fine_tune_encoder\n",
    "}\n",
    "\n",
    "m_params = {\n",
    "    'attention_dim': attention_dim,\n",
    "    'embed_dim': emb_dim,\n",
    "    'decoder_dim': decoder_dim,\n",
    "    'encoder_dim': encoder_dim,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "\n",
    "fit(t_params=t_params, m_params=m_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
