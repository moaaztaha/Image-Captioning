{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !rm -r Image-Captioning/","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:05.299957Z","iopub.execute_input":"2021-06-24T12:33:05.300393Z","iopub.status.idle":"2021-06-24T12:33:06.139740Z","shell.execute_reply.started":"2021-06-24T12:33:05.300342Z","shell.execute_reply":"2021-06-24T12:33:06.138148Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# get the code for kaggle\n!git clone https://github.com/moaaztaha/Image-Captioning\npy_files_path = '/kaggle/working/Image-Captioning/'\nimport sys\nsys.path.append(py_files_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:09.174035Z","iopub.execute_input":"2021-06-24T12:33:09.174529Z","iopub.status.idle":"2021-06-24T12:33:14.507938Z","shell.execute_reply.started":"2021-06-24T12:33:09.174477Z","shell.execute_reply":"2021-06-24T12:33:14.506751Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Cloning into 'Image-Captioning'...\nremote: Enumerating objects: 526, done.\u001b[K\nremote: Counting objects: 100% (526/526), done.\u001b[K\nremote: Compressing objects: 100% (233/233), done.\u001b[K\nremote: Total 526 (delta 320), reused 491 (delta 285), pack-reused 0\u001b[K\nReceiving objects: 100% (526/526), 36.81 MiB | 16.02 MiB/s, done.\nResolving deltas: 100% (320/320), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:14.510174Z","iopub.execute_input":"2021-06-24T12:33:14.510640Z","iopub.status.idle":"2021-06-24T12:33:14.591637Z","shell.execute_reply.started":"2021-06-24T12:33:14.510590Z","shell.execute_reply":"2021-06-24T12:33:14.590555Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import time \nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nfrom torch import nn\nfrom torch.nn.utils.rnn import pack_padded_sequence\nfrom models import Encoder, DecoderWithAttention\nfrom dataset import *\nfrom utils import *\nfrom train import *\nfrom torch.utils.tensorboard import SummaryWriter\nfrom os import path as osp","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:14.594929Z","iopub.execute_input":"2021-06-24T12:33:14.595405Z","iopub.status.idle":"2021-06-24T12:33:15.481583Z","shell.execute_reply.started":"2021-06-24T12:33:14.595363Z","shell.execute_reply":"2021-06-24T12:33:15.480089Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Model parameters\nencoder_dim = 2048 # resnet101\nemb_dim = 512  # dimension of word embeddings\nattention_dim = 512  # dimension of attention linear layers\ndecoder_dim = 512  # dimension of decoder RNN\ndropout = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\ncudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n\n# training parameters\nepochs = 30  # number of epochs to train for (if early stopping is not triggered)\nbatch_size = 256\nworkers = 2\nencoder_lr = 1e-4  # learning rate for encoder if fine-tuning\ndecoder_lr = 4e-4  # learning rate for decoder\nfine_tune_encoder = False  # fine-tune encoder?\npretrained_embeddings = False\nfine_tune_embeddings = False\ncheckpoint = None  # path to checkpoint, None if none","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:15.483730Z","iopub.execute_input":"2021-06-24T12:33:15.484172Z","iopub.status.idle":"2021-06-24T12:33:15.572918Z","shell.execute_reply.started":"2021-06-24T12:33:15.484125Z","shell.execute_reply":"2021-06-24T12:33:15.571705Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"DATA_NAME = 'flickr30k_10k'\n\n# local\n# DATA_JSON_PATH = 'data.json'\n# IMGS_PATH = 'flickr/Images/'\n# kaggle paths\nDATA_JSON_PATH = '/kaggle/working/Image-Captioning/data30.json'\nIMGS_PATH = '../input/flickr30k/images/flickr30k_images/'","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:15.574467Z","iopub.execute_input":"2021-06-24T12:33:15.575149Z","iopub.status.idle":"2021-06-24T12:33:15.665589Z","shell.execute_reply.started":"2021-06-24T12:33:15.575103Z","shell.execute_reply":"2021-06-24T12:33:15.664182Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# load vocab\n# vocab = build_vocab(DATA_JSON_PATH)\ntop10k_words = get_10k_vocab(\"./Image-Captioning/10k_words.txt\")\nvocab = top10k_vocab(top10k_words)\nvocab_len = len(vocab)\nvocab_len","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-24T12:33:17.401123Z","iopub.execute_input":"2021-06-24T12:33:17.401540Z","iopub.status.idle":"2021-06-24T12:33:17.508529Z","shell.execute_reply.started":"2021-06-24T12:33:17.401508Z","shell.execute_reply":"2021-06-24T12:33:17.507449Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 111.14it/s]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"10004"},"metadata":{}}]},{"cell_type":"code","source":"t_params = {\n    'data_name': DATA_NAME,\n    'imgs_path': IMGS_PATH,\n    'df_path': DATA_JSON_PATH,\n    'vocab': vocab,\n    'epochs': epochs,\n    'batch_size': batch_size,\n    'workers': workers,\n    'decoder_lr': decoder_lr,\n    'encoder_lr': encoder_lr,\n    'fine_tune_encoder': fine_tune_encoder,\n    'pretrained_embeddings': pretrained_embeddings,\n}\n\nm_params = {\n    'attention_dim': attention_dim,\n    'embed_dim': emb_dim,\n    'decoder_dim': decoder_dim,\n    'encoder_dim': encoder_dim,\n    'dropout': dropout\n}\n\nlogger_dic = {\n    'decoder_lr': decoder_lr,\n    'encoder_lr': encoder_lr,\n    'fine_tune_encoder': fine_tune_encoder,\n    'pretrained_embeddings': pretrained_embeddings,\n    'max_seq_length': 100,\n    'vocab_size': vocab_len,\n    'enocder': 'resnet101',\n    'dropout': dropout,\n    'attention_dim': attention_dim,\n    'embed_dim': emb_dim,\n    'decoder_dim': decoder_dim,\n    'encoder_dim': encoder_dim \n    \n}","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:18.575769Z","iopub.execute_input":"2021-06-24T12:33:18.576292Z","iopub.status.idle":"2021-06-24T12:33:18.667785Z","shell.execute_reply.started":"2021-06-24T12:33:18.576207Z","shell.execute_reply":"2021-06-24T12:33:18.666336Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"t_params","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:19.962241Z","iopub.execute_input":"2021-06-24T12:33:19.962757Z","iopub.status.idle":"2021-06-24T12:33:20.055269Z","shell.execute_reply.started":"2021-06-24T12:33:19.962709Z","shell.execute_reply":"2021-06-24T12:33:20.053451Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'data_name': 'flickr30k_10k',\n 'imgs_path': '../input/flickr30k/images/flickr30k_images/',\n 'df_path': '/kaggle/working/Image-Captioning/data30.json',\n 'vocab': <dataset.Vocabulary at 0x7f8f91fc0750>,\n 'epochs': 30,\n 'batch_size': 256,\n 'workers': 2,\n 'decoder_lr': 0.0004,\n 'encoder_lr': 0.0001,\n 'fine_tune_encoder': False,\n 'pretrained_embeddings': False}"},"metadata":{}}]},{"cell_type":"code","source":"# experiment name\nname = DATA_NAME + \"_10k_words\"\n# path\nlog_dir = 'experiments'\n\nlogger = SummaryWriter(log_dir=osp.join(log_dir, name))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:21.796356Z","iopub.execute_input":"2021-06-24T12:33:21.796746Z","iopub.status.idle":"2021-06-24T12:33:23.913330Z","shell.execute_reply.started":"2021-06-24T12:33:21.796715Z","shell.execute_reply":"2021-06-24T12:33:23.912006Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:23.915506Z","iopub.execute_input":"2021-06-24T12:33:23.916062Z","iopub.status.idle":"2021-06-24T12:33:24.061159Z","shell.execute_reply.started":"2021-06-24T12:33:23.915957Z","shell.execute_reply":"2021-06-24T12:33:24.059782Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"fit(t_params=t_params, m_params=m_params, logger=logger)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T12:33:24.063410Z","iopub.execute_input":"2021-06-24T12:33:24.063897Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Loading Data\nDataset split: train\nUnique images: 29000\nTotal size: 145000\nDataset split: val\nUnique images: 1014\nTotal size: 5070\n__________________________________________________\n-------------------- Fitting --------------------\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [0][0/567]\tBatch Time 9.796 (9.796)\tData Load Time 5.565 (5.565)\tLoss 10.0955 (10.0955)\tTop-5 Accuracy 0.057 (0.057)\nEpoch: [0][100/567]\tBatch Time 4.151 (2.998)\tData Load Time 2.278 (1.158)\tLoss 5.3575 (5.9454)\tTop-5 Accuracy 47.827 (40.556)\nEpoch: [0][200/567]\tBatch Time 3.244 (2.879)\tData Load Time 1.512 (1.068)\tLoss 4.9234 (5.5583)\tTop-5 Accuracy 54.001 (45.571)\nEpoch: [0][300/567]\tBatch Time 2.961 (2.806)\tData Load Time 1.105 (0.978)\tLoss 4.7621 (5.3522)\tTop-5 Accuracy 56.495 (48.234)\nEpoch: [0][400/567]\tBatch Time 2.933 (2.761)\tData Load Time 1.032 (0.932)\tLoss 4.8033 (5.2131)\tTop-5 Accuracy 55.053 (49.994)\nEpoch: [0][500/567]\tBatch Time 3.232 (2.738)\tData Load Time 1.421 (0.895)\tLoss 4.6624 (5.1114)\tTop-5 Accuracy 56.533 (51.266)\nEpoch train time 1541.706 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.652 (6.652)\tLoss 4.3453 (4.3453)\tTop-5 Accuracy 62.951 (62.951)\t\n----- Bleu-n Scores -----\n1: 61.623644995312475\n2: 38.28047106962061\n3: 22.852901538408858\n4: 14.33295754172329\n-------------------------\n\n * LOSS - 4.342, TOP-5 ACCURACY - 62.300, BLEU-4 - 14.33295754172329\n\nEpoch validation time 66.983 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [1][0/567]\tBatch Time 6.437 (6.437)\tData Load Time 3.889 (3.889)\tLoss 4.5331 (4.5331)\tTop-5 Accuracy 58.311 (58.311)\nEpoch: [1][100/567]\tBatch Time 4.116 (2.687)\tData Load Time 1.526 (0.814)\tLoss 4.4996 (4.5311)\tTop-5 Accuracy 58.493 (58.378)\nEpoch: [1][200/567]\tBatch Time 2.908 (2.648)\tData Load Time 1.280 (0.767)\tLoss 4.4995 (4.5068)\tTop-5 Accuracy 58.874 (58.663)\nEpoch: [1][300/567]\tBatch Time 2.872 (2.641)\tData Load Time 1.104 (0.759)\tLoss 4.3951 (4.4803)\tTop-5 Accuracy 60.023 (59.029)\nEpoch: [1][400/567]\tBatch Time 3.730 (2.638)\tData Load Time 1.199 (0.754)\tLoss 4.3653 (4.4557)\tTop-5 Accuracy 59.885 (59.352)\nEpoch: [1][500/567]\tBatch Time 3.132 (2.632)\tData Load Time 1.368 (0.744)\tLoss 4.3432 (4.4332)\tTop-5 Accuracy 60.556 (59.632)\nEpoch train time 1485.629 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.619 (6.619)\tLoss 4.2713 (4.2713)\tTop-5 Accuracy 63.407 (63.407)\t\n----- Bleu-n Scores -----\n1: 62.81659377081067\n2: 39.31454408680518\n3: 23.74771813731427\n4: 15.081313861703594\n-------------------------\n\n * LOSS - 4.144, TOP-5 ACCURACY - 64.915, BLEU-4 - 15.081313861703594\n\nEpoch validation time 63.680 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [2][0/567]\tBatch Time 6.322 (6.322)\tData Load Time 4.133 (4.133)\tLoss 4.3726 (4.3726)\tTop-5 Accuracy 58.504 (58.504)\nEpoch: [2][100/567]\tBatch Time 3.303 (2.651)\tData Load Time 1.599 (0.785)\tLoss 4.3121 (4.2499)\tTop-5 Accuracy 60.363 (61.796)\nEpoch: [2][200/567]\tBatch Time 3.574 (2.654)\tData Load Time 1.581 (0.769)\tLoss 4.2288 (4.2372)\tTop-5 Accuracy 62.796 (61.963)\nEpoch: [2][300/567]\tBatch Time 3.265 (2.648)\tData Load Time 1.503 (0.771)\tLoss 4.3098 (4.2226)\tTop-5 Accuracy 60.953 (62.196)\nEpoch: [2][400/567]\tBatch Time 4.271 (2.661)\tData Load Time 1.850 (0.775)\tLoss 4.2165 (4.2110)\tTop-5 Accuracy 63.115 (62.346)\nEpoch: [2][500/567]\tBatch Time 4.226 (2.662)\tData Load Time 2.327 (0.776)\tLoss 4.1794 (4.2038)\tTop-5 Accuracy 63.122 (62.434)\nEpoch train time 1507.557 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.576 (6.576)\tLoss 4.0320 (4.0320)\tTop-5 Accuracy 65.155 (65.155)\t\n----- Bleu-n Scores -----\n1: 63.65782105513216\n2: 40.0353330319534\n3: 24.349745649095293\n4: 15.629234743279289\n-------------------------\n\n * LOSS - 4.035, TOP-5 ACCURACY - 66.259, BLEU-4 - 15.629234743279289\n\nEpoch validation time 65.948 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [3][0/567]\tBatch Time 6.298 (6.298)\tData Load Time 4.486 (4.486)\tLoss 3.9880 (3.9880)\tTop-5 Accuracy 64.632 (64.632)\nEpoch: [3][100/567]\tBatch Time 3.307 (2.707)\tData Load Time 1.497 (0.829)\tLoss 4.0558 (4.0829)\tTop-5 Accuracy 64.345 (63.882)\nEpoch: [3][200/567]\tBatch Time 3.160 (2.670)\tData Load Time 1.359 (0.789)\tLoss 4.1057 (4.0780)\tTop-5 Accuracy 63.534 (63.948)\nEpoch: [3][300/567]\tBatch Time 2.791 (2.660)\tData Load Time 1.137 (0.787)\tLoss 4.0586 (4.0701)\tTop-5 Accuracy 64.232 (64.061)\nEpoch: [3][400/567]\tBatch Time 4.056 (2.668)\tData Load Time 1.684 (0.790)\tLoss 4.0675 (4.0644)\tTop-5 Accuracy 63.411 (64.136)\nEpoch: [3][500/567]\tBatch Time 3.427 (2.676)\tData Load Time 1.520 (0.801)\tLoss 4.0334 (4.0579)\tTop-5 Accuracy 64.862 (64.240)\nEpoch train time 1515.639 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.750 (6.750)\tLoss 4.1430 (4.1430)\tTop-5 Accuracy 64.373 (64.373)\t\n----- Bleu-n Scores -----\n1: 64.22585143575023\n2: 40.75592724782923\n3: 25.08169786018773\n4: 16.146724401824635\n-------------------------\n\n * LOSS - 3.974, TOP-5 ACCURACY - 67.054, BLEU-4 - 16.146724401824635\n\nEpoch validation time 65.230 (epoch_time.avg:.3f)\nEpoch     4: reducing learning rate of group 0 to 4.0000e-05.\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [4][0/567]\tBatch Time 6.469 (6.469)\tData Load Time 4.476 (4.476)\tLoss 3.9640 (3.9640)\tTop-5 Accuracy 65.570 (65.570)\nEpoch: [4][100/567]\tBatch Time 3.226 (2.699)\tData Load Time 1.452 (0.841)\tLoss 3.9459 (3.9413)\tTop-5 Accuracy 65.608 (65.633)\nEpoch: [4][200/567]\tBatch Time 3.015 (2.670)\tData Load Time 1.300 (0.803)\tLoss 4.0059 (3.9378)\tTop-5 Accuracy 64.910 (65.707)\nEpoch: [4][300/567]\tBatch Time 3.312 (2.669)\tData Load Time 1.591 (0.793)\tLoss 3.9747 (3.9343)\tTop-5 Accuracy 64.770 (65.768)\nEpoch: [4][400/567]\tBatch Time 3.866 (2.675)\tData Load Time 1.981 (0.797)\tLoss 4.0465 (3.9330)\tTop-5 Accuracy 64.206 (65.805)\nEpoch: [4][500/567]\tBatch Time 3.538 (2.680)\tData Load Time 1.583 (0.798)\tLoss 3.9351 (3.9299)\tTop-5 Accuracy 65.564 (65.850)\nEpoch train time 1517.296 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.377 (6.377)\tLoss 3.8690 (3.8690)\tTop-5 Accuracy 67.054 (67.054)\t\n----- Bleu-n Scores -----\n1: 64.42688182993635\n2: 41.00510789967804\n3: 25.345213535213666\n4: 16.398637097798716\n-------------------------\n\n * LOSS - 3.925, TOP-5 ACCURACY - 67.651, BLEU-4 - 16.398637097798716\n\nEpoch validation time 65.305 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [5][0/567]\tBatch Time 6.575 (6.575)\tData Load Time 4.848 (4.848)\tLoss 3.9955 (3.9955)\tTop-5 Accuracy 65.499 (65.499)\nEpoch: [5][100/567]\tBatch Time 3.899 (2.771)\tData Load Time 2.028 (0.937)\tLoss 3.8926 (3.9016)\tTop-5 Accuracy 67.937 (66.307)\nEpoch: [5][200/567]\tBatch Time 3.625 (2.726)\tData Load Time 1.806 (0.872)\tLoss 3.9222 (3.9086)\tTop-5 Accuracy 65.483 (66.169)\nEpoch: [5][300/567]\tBatch Time 3.633 (2.715)\tData Load Time 1.693 (0.847)\tLoss 3.9440 (3.9091)\tTop-5 Accuracy 65.657 (66.153)\nEpoch: [5][400/567]\tBatch Time 3.669 (2.705)\tData Load Time 1.788 (0.836)\tLoss 3.9601 (3.9073)\tTop-5 Accuracy 65.959 (66.161)\nEpoch: [5][500/567]\tBatch Time 3.085 (2.697)\tData Load Time 1.345 (0.830)\tLoss 3.7986 (3.9065)\tTop-5 Accuracy 67.243 (66.163)\nEpoch train time 1522.870 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.810 (6.810)\tLoss 3.8151 (3.8151)\tTop-5 Accuracy 69.509 (69.509)\t\n----- Bleu-n Scores -----\n1: 64.45619561248598\n2: 41.11339711416713\n3: 25.472998441643917\n4: 16.479734561150984\n-------------------------\n\n * LOSS - 3.918, TOP-5 ACCURACY - 67.746, BLEU-4 - 16.479734561150984\n\nEpoch validation time 65.059 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [6][0/567]\tBatch Time 6.102 (6.102)\tData Load Time 4.387 (4.387)\tLoss 3.8169 (3.8169)\tTop-5 Accuracy 68.144 (68.144)\nEpoch: [6][100/567]\tBatch Time 3.430 (2.739)\tData Load Time 1.737 (0.855)\tLoss 3.8589 (3.8877)\tTop-5 Accuracy 66.907 (66.449)\nEpoch: [6][200/567]\tBatch Time 3.016 (2.706)\tData Load Time 1.356 (0.839)\tLoss 3.9429 (3.8909)\tTop-5 Accuracy 65.679 (66.450)\nEpoch: [6][300/567]\tBatch Time 3.815 (2.698)\tData Load Time 1.984 (0.829)\tLoss 3.8581 (3.8899)\tTop-5 Accuracy 66.818 (66.445)\nEpoch: [6][400/567]\tBatch Time 3.244 (2.687)\tData Load Time 1.446 (0.814)\tLoss 3.9338 (3.8921)\tTop-5 Accuracy 65.941 (66.381)\nEpoch: [6][500/567]\tBatch Time 3.189 (2.680)\tData Load Time 1.424 (0.806)\tLoss 3.8254 (3.8927)\tTop-5 Accuracy 66.431 (66.370)\nEpoch train time 1515.884 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.349 (6.349)\tLoss 3.7828 (3.7828)\tTop-5 Accuracy 69.290 (69.290)\t\n----- Bleu-n Scores -----\n1: 64.52035998953566\n2: 41.17911221122777\n3: 25.501680578711238\n4: 16.535088067078842\n-------------------------\n\n * LOSS - 3.914, TOP-5 ACCURACY - 67.807, BLEU-4 - 16.535088067078842\n\nEpoch validation time 64.734 (epoch_time.avg:.3f)\nEpoch     7: reducing learning rate of group 0 to 4.0000e-06.\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [7][0/567]\tBatch Time 6.038 (6.038)\tData Load Time 4.130 (4.130)\tLoss 3.8627 (3.8627)\tTop-5 Accuracy 66.953 (66.953)\nEpoch: [7][100/567]\tBatch Time 3.284 (2.772)\tData Load Time 1.500 (0.899)\tLoss 3.7511 (3.8762)\tTop-5 Accuracy 67.653 (66.567)\nEpoch: [7][200/567]\tBatch Time 4.004 (2.729)\tData Load Time 1.217 (0.855)\tLoss 3.9712 (3.8724)\tTop-5 Accuracy 65.751 (66.603)\nEpoch: [7][300/567]\tBatch Time 3.419 (2.726)\tData Load Time 1.283 (0.862)\tLoss 3.8897 (3.8757)\tTop-5 Accuracy 66.574 (66.571)\nEpoch: [7][400/567]\tBatch Time 3.424 (2.714)\tData Load Time 1.745 (0.852)\tLoss 3.9159 (3.8756)\tTop-5 Accuracy 65.957 (66.560)\nEpoch: [7][500/567]\tBatch Time 4.247 (2.709)\tData Load Time 2.295 (0.857)\tLoss 3.9181 (3.8759)\tTop-5 Accuracy 66.490 (66.557)\nEpoch train time 1531.558 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.654 (6.654)\tLoss 3.7990 (3.7990)\tTop-5 Accuracy 68.690 (68.690)\t\n----- Bleu-n Scores -----\n1: 64.48004014773542\n2: 41.13020541030364\n3: 25.538034034564312\n4: 16.556361457166812\n-------------------------\n\n * LOSS - 3.911, TOP-5 ACCURACY - 67.884, BLEU-4 - 16.556361457166812\n\nEpoch validation time 66.435 (epoch_time.avg:.3f)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [8][0/567]\tBatch Time 6.280 (6.280)\tData Load Time 4.654 (4.654)\tLoss 3.9313 (3.9313)\tTop-5 Accuracy 65.512 (65.512)\nEpoch: [8][100/567]\tBatch Time 4.207 (2.780)\tData Load Time 2.470 (0.940)\tLoss 3.7834 (3.8676)\tTop-5 Accuracy 67.507 (66.656)\nEpoch: [8][200/567]\tBatch Time 3.281 (2.742)\tData Load Time 1.510 (0.905)\tLoss 3.8442 (3.8725)\tTop-5 Accuracy 67.277 (66.598)\nEpoch: [8][300/567]\tBatch Time 3.765 (2.724)\tData Load Time 1.952 (0.888)\tLoss 3.9521 (3.8705)\tTop-5 Accuracy 65.371 (66.638)\nEpoch: [8][400/567]\tBatch Time 2.968 (2.709)\tData Load Time 1.215 (0.875)\tLoss 3.9937 (3.8737)\tTop-5 Accuracy 64.489 (66.591)\nEpoch: [8][500/567]\tBatch Time 3.350 (2.697)\tData Load Time 1.650 (0.854)\tLoss 3.8190 (3.8747)\tTop-5 Accuracy 67.332 (66.592)\nEpoch train time 1521.014 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.389 (6.389)\tLoss 3.8836 (3.8836)\tTop-5 Accuracy 67.888 (67.888)\t\n----- Bleu-n Scores -----\n1: 64.4782889879863\n2: 41.138444369316886\n3: 25.513302511042525\n4: 16.51915822060089\n-------------------------\n\n * LOSS - 3.910, TOP-5 ACCURACY - 67.840, BLEU-4 - 16.51915822060089\n\nEpoch validation time 64.678 (epoch_time.avg:.3f)\n\nEpochs since last improvement: (1,)\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [9][0/567]\tBatch Time 5.755 (5.755)\tData Load Time 3.972 (3.972)\tLoss 3.9065 (3.9065)\tTop-5 Accuracy 66.237 (66.237)\nEpoch: [9][100/567]\tBatch Time 3.517 (2.660)\tData Load Time 1.770 (0.787)\tLoss 3.9342 (3.8779)\tTop-5 Accuracy 66.198 (66.535)\nEpoch: [9][200/567]\tBatch Time 3.755 (2.667)\tData Load Time 1.304 (0.799)\tLoss 4.0219 (3.8779)\tTop-5 Accuracy 64.168 (66.597)\nEpoch: [9][300/567]\tBatch Time 3.454 (2.672)\tData Load Time 1.331 (0.802)\tLoss 3.8968 (3.8751)\tTop-5 Accuracy 66.498 (66.598)\nEpoch: [9][400/567]\tBatch Time 3.594 (2.665)\tData Load Time 1.907 (0.795)\tLoss 3.8428 (3.8722)\tTop-5 Accuracy 67.175 (66.643)\nEpoch: [9][500/567]\tBatch Time 3.799 (2.659)\tData Load Time 1.839 (0.786)\tLoss 3.8341 (3.8713)\tTop-5 Accuracy 66.801 (66.650)\nEpoch train time 1501.710 (epoch_time.avg:.3f)\n-------------------- Validation --------------------\nValidation: [0/20]\tBatch Time 6.584 (6.584)\tLoss 3.8499 (3.8499)\tTop-5 Accuracy 69.291 (69.291)\t\n----- Bleu-n Scores -----\n1: 64.47653668582544\n2: 41.11778549233174\n3: 25.466738769286852\n4: 16.489677594792944\n-------------------------\n\n * LOSS - 3.909, TOP-5 ACCURACY - 67.882, BLEU-4 - 16.489677594792944\n\nEpoch validation time 64.293 (epoch_time.avg:.3f)\n\nEpochs since last improvement: (2,)\nEpoch    10: reducing learning rate of group 0 to 4.0000e-07.\n__________________________________________________\n-------------------- Training --------------------\nEpoch: [10][0/567]\tBatch Time 5.893 (5.893)\tData Load Time 3.926 (3.926)\tLoss 3.9567 (3.9567)\tTop-5 Accuracy 64.626 (64.626)\nEpoch: [10][100/567]\tBatch Time 3.975 (2.673)\tData Load Time 1.708 (0.817)\tLoss 3.8628 (3.8730)\tTop-5 Accuracy 67.108 (66.622)\nEpoch: [10][200/567]\tBatch Time 3.768 (2.648)\tData Load Time 1.886 (0.799)\tLoss 3.9356 (3.8720)\tTop-5 Accuracy 65.327 (66.610)\nEpoch: [10][300/567]\tBatch Time 3.818 (2.658)\tData Load Time 2.013 (0.809)\tLoss 3.8872 (3.8713)\tTop-5 Accuracy 66.207 (66.631)\nEpoch: [10][400/567]\tBatch Time 3.773 (2.655)\tData Load Time 1.937 (0.801)\tLoss 3.9364 (3.8712)\tTop-5 Accuracy 65.344 (66.643)\nEpoch: [10][500/567]\tBatch Time 3.042 (2.653)\tData Load Time 1.115 (0.791)\tLoss 3.8481 (3.8707)\tTop-5 Accuracy 66.506 (66.655)\n","output_type":"stream"}]},{"cell_type":"code","source":"# save the model to gdrive\nfrom IPython.display import FileLink\nFileLink(\"./BEST_checkpoint_flickr30k_10k.pth.tar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href='./BEST_checkpoint_flickr30k_10k.pth.tar'>download<a>","metadata":{}},{"cell_type":"code","source":"# Model parameters\nencoder_dim = 2048 # resnet101\nemb_dim = 512  # dimension of word embeddings\nattention_dim = 512  # dimension of attention linear layers\ndecoder_dim = 512  # dimension of decoder RNN\ndropout = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\ncudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n\n# training parameters\nepochs = 15  # number of epochs to train for (if early stopping is not triggered)\nbatch_size = 32\nworkers = 4\nencoder_lr = 1e-4  # learning rate for encoder if fine-tuning\ndecoder_lr = 4e-4  # learning rate for decoder\nfine_tune_encoder = True  # fine-tune encoder?\ncheckpoint = './BEST_checkpoint_flickr30k_5_cap_per_img_2_min_word_freq_resnet101.pth.tar'  # path to checkpoint, None if none","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_params = {\n    'data_name': DATA_NAME,\n    'imgs_path': IMGS_PATH,\n    'df_path': DATA_JSON_PATH,\n    'vocab': vocab,\n    'epochs': epochs,\n    'batch_size': batch_size,\n    'workers': workers,\n    'decoder_lr': decoder_lr,\n    'encoder_lr': encoder_lr,\n    'fine_tune_encoder': fine_tune_encoder\n}\n\nm_params = {\n    'attention_dim': attention_dim,\n    'embed_dim': emb_dim,\n    'decoder_dim': decoder_dim,\n    'encoder_dim': encoder_dim,\n    'dropout': dropout\n}\n\nt_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(t_params=t_params, checkpoint=checkpoint, m_params=m_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}