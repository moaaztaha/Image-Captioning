{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flickr8-10k words",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd3470b877854d5a837422826b9db4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d43e86153094ef2be833f98a98f4636",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b14fecff2fd4f81a412f2e2aa563510",
              "IPY_MODEL_0dd82a27f1d046d6aefe5ea85abcbd3a"
            ]
          }
        },
        "1d43e86153094ef2be833f98a98f4636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b14fecff2fd4f81a412f2e2aa563510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_402439131dc042099f5628271ed8ea74",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178793939,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178793939,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41cda710599143619843bcee3b97e4d9"
          }
        },
        "0dd82a27f1d046d6aefe5ea85abcbd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c05ff7bee59f4d2892cce960aa009cba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 171M/171M [00:06&lt;00:00, 28.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_577183d850f640d8aee6b7e495fc3470"
          }
        },
        "402439131dc042099f5628271ed8ea74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41cda710599143619843bcee3b97e4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c05ff7bee59f4d2892cce960aa009cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "577183d850f640d8aee6b7e495fc3470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yF22FLldBVv",
        "outputId": "540e26cc-de3f-44bf-8c9b-e6a49e71b71d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 24 09:51:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAVbNRecdEmC"
      },
      "source": [
        "# !mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHpPT9-dPip",
        "outputId": "3a74d6fb-129f-4aa8-de13-afaa7ad92391"
      },
      "source": [
        "!pip install kaggle -q\n",
        "!kaggle datasets download -d aladdinpersson/flickr8kimagescaptions\n",
        "!unzip -q flickr8kimagescaptions.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickr8kimagescaptions.zip to /content\n",
            " 98% 1.01G/1.04G [00:06<00:00, 154MB/s]\n",
            "100% 1.04G/1.04G [00:06<00:00, 163MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rhy46y0NmxV"
      },
      "source": [
        "!rm -r Image-Captioning/"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdb4vWE0dQS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b69f289-d1ed-4146-9982-f97490a97d9d"
      },
      "source": [
        "# # get the code for kaggle\n",
        "!git clone https://github.com/moaaztaha/Image-Captioning\n",
        "py_files_path = 'Image-Captioning/'\n",
        "import sys\n",
        "sys.path.append(py_files_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image-Captioning'...\n",
            "remote: Enumerating objects: 526, done.\u001b[K\n",
            "remote: Counting objects: 100% (526/526), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 526 (delta 320), reused 491 (delta 285), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (526/526), 36.81 MiB | 23.08 MiB/s, done.\n",
            "Resolving deltas: 100% (320/320), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCupTxpafLCY"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJpGuI-eJ1aC"
      },
      "source": [
        "# !pip3 install nltk==3.6.2\n",
        "# import nltk\n",
        "# nltk.download(\"wordnet\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAUwbIDzfLCY"
      },
      "source": [
        "import time \n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from models import Encoder, DecoderWithAttention\n",
        "from dataset import *\n",
        "from utils import *\n",
        "from train import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from os import path as osp"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xao3iXYfLCZ"
      },
      "source": [
        "# Model parameters\n",
        "encoder_dim = 2048 # resnet101\n",
        "emb_dim = 512  # dimension of word embeddings\n",
        "attention_dim = 512  # dimension of attention linear layers\n",
        "decoder_dim = 512  # dimension of decoder RNN\n",
        "dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
        "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
        "\n",
        "# training parameters\n",
        "epochs = 30  # number of epochs to train for (if early stopping is not triggered)\n",
        "batch_size = 256\n",
        "workers = 2\n",
        "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
        "decoder_lr = 4e-4  # learning rate for decoder\n",
        "fine_tune_encoder = False  # fine-tune encoder?\n",
        "pretrained_embeddings = False\n",
        "fine_tune_embeddings = False\n",
        "checkpoint = None  # path to checkpoint, None if none"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjGhnGwvfLCZ"
      },
      "source": [
        "DATA_NAME = 'flickr8k_10k'\n",
        "\n",
        "# local\n",
        "# DATA_JSON_PATH = 'data.json'\n",
        "# IMGS_PATH = 'flickr/Images/'\n",
        "# kaggle paths\n",
        "# DATA_JSON_PATH = '/kaggle/working/Image-Captioning/data.json'\n",
        "# IMGS_PATH = '../input/flickr8kimagescaptions/flickr8k/images/'\n",
        "#colab\n",
        "DATA_JSON_PATH = 'Image-Captioning/data.json'\n",
        "IMGS_PATH = 'flickr8k/images/'"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohaaGjb7fLCa",
        "outputId": "f43f8647-dba3-4a92-eaf5-f08a321dacf0"
      },
      "source": [
        "# load vocab\n",
        "# vocab = build_vocab(DATA_JSON_PATH)\n",
        "top10k_words = get_10k_vocab(\"/content/Image-Captioning/10k_words.txt\")\n",
        "vocab = top10k_vocab(top10k_words)\n",
        "vocab_len = len(vocab)\n",
        "vocab_len"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 123.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6quGOJjfLCb"
      },
      "source": [
        "t_params = {\n",
        "    'data_name': DATA_NAME,\n",
        "    'imgs_path': IMGS_PATH,\n",
        "    'df_path': DATA_JSON_PATH,\n",
        "    'vocab': vocab,\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'workers': workers,\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "}\n",
        "\n",
        "m_params = {\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim,\n",
        "    'dropout': dropout\n",
        "}\n",
        "\n",
        "logger_dic = {\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "    'max_seq_length': 100,\n",
        "    'vocab_size': vocab_len,\n",
        "    'enocder': 'resnet101',\n",
        "    'dropout': dropout,\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim \n",
        "    \n",
        "}"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9hJPzJhh4v4",
        "outputId": "0609dd7b-1225-485a-f55e-574ed71e563d"
      },
      "source": [
        "t_params"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'data_name': 'flickr8k_10k',\n",
              " 'decoder_lr': 0.0004,\n",
              " 'df_path': 'Image-Captioning/data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': True,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7fd41be8fdd0>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8kS-8cKOWR"
      },
      "source": [
        "# experiment name\n",
        "name = DATA_NAME + \"_10k_words\"\n",
        "# path\n",
        "log_dir = '/content/drive/MyDrive/ImageCaptioning/flickr8/experiments'\n",
        "\n",
        "logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd3470b877854d5a837422826b9db4e5",
            "1d43e86153094ef2be833f98a98f4636",
            "6b14fecff2fd4f81a412f2e2aa563510",
            "0dd82a27f1d046d6aefe5ea85abcbd3a",
            "402439131dc042099f5628271ed8ea74",
            "41cda710599143619843bcee3b97e4d9",
            "c05ff7bee59f4d2892cce960aa009cba",
            "577183d850f640d8aee6b7e495fc3470"
          ]
        },
        "id": "uq-qHyNcIQLQ",
        "outputId": "69a8a27c-1ab7-4dce-ba79-f07882f1a1ce"
      },
      "source": [
        "# with scheduler\n",
        "fit(t_params=t_params, m_params=m_params, logger=logger)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd3470b877854d5a837422826b9db4e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=178793939.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 30000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 5000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/118]\tBatch Time 9.145 (9.145)\tData Load Time 3.795 (3.795)\tLoss 10.1185 (10.1185)\tTop-5 Accuracy 0.000 (0.000)\n",
            "Epoch: [0][100/118]\tBatch Time 2.504 (2.568)\tData Load Time 0.007 (0.042)\tLoss 5.0194 (5.6171)\tTop-5 Accuracy 51.929 (44.116)\n",
            "Epoch train time 301.370 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.024 (6.024)\tLoss 5.5496 (5.5496)\tTop-5 Accuracy 50.943 (50.943)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 60.1798427021706\n",
            "2: 35.488586163035684\n",
            "3: 18.514052756816376\n",
            "4: 9.881429249562874\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.520, TOP-5 ACCURACY - 50.609, BLEU-4 - 9.881429249562874\n",
            "\n",
            "Epoch validation time 55.042 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [1][0/118]\tBatch Time 6.455 (6.455)\tData Load Time 3.543 (3.543)\tLoss 4.7334 (4.7334)\tTop-5 Accuracy 55.526 (55.526)\n",
            "Epoch: [1][100/118]\tBatch Time 2.544 (2.581)\tData Load Time 0.012 (0.040)\tLoss 4.4389 (4.6597)\tTop-5 Accuracy 59.955 (56.536)\n",
            "Epoch train time 302.217 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.133 (6.133)\tLoss 5.4187 (5.4187)\tTop-5 Accuracy 54.218 (54.218)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 61.287161633994955\n",
            "2: 36.30616175516769\n",
            "3: 18.692260570704892\n",
            "4: 9.860127630059576\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.425, TOP-5 ACCURACY - 53.913, BLEU-4 - 9.860127630059576\n",
            "\n",
            "Epoch validation time 52.423 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [2][0/118]\tBatch Time 6.213 (6.213)\tData Load Time 3.376 (3.376)\tLoss 4.5442 (4.5442)\tTop-5 Accuracy 57.040 (57.040)\n",
            "Epoch: [2][100/118]\tBatch Time 2.525 (2.583)\tData Load Time 0.001 (0.037)\tLoss 4.3628 (4.3766)\tTop-5 Accuracy 60.130 (60.146)\n",
            "Epoch train time 302.069 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.083 (6.083)\tLoss 5.3182 (5.3182)\tTop-5 Accuracy 56.439 (56.439)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.59432600358886\n",
            "2: 39.17604053295893\n",
            "3: 22.36643308665273\n",
            "4: 12.92993394756374\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.261, TOP-5 ACCURACY - 56.638, BLEU-4 - 12.92993394756374\n",
            "\n",
            "Epoch validation time 52.186 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [3][0/118]\tBatch Time 6.256 (6.256)\tData Load Time 3.393 (3.393)\tLoss 4.3089 (4.3089)\tTop-5 Accuracy 60.514 (60.514)\n",
            "Epoch: [3][100/118]\tBatch Time 2.521 (2.582)\tData Load Time 0.008 (0.038)\tLoss 4.1624 (4.1880)\tTop-5 Accuracy 63.676 (62.553)\n",
            "Epoch train time 302.234 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.864 (5.864)\tLoss 5.3543 (5.3543)\tTop-5 Accuracy 56.161 (56.161)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.23899230345283\n",
            "2: 38.88614403579371\n",
            "3: 22.292045122777807\n",
            "4: 12.704117473845336\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.225, TOP-5 ACCURACY - 57.512, BLEU-4 - 12.704117473845336\n",
            "\n",
            "Epoch validation time 52.273 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [4][0/118]\tBatch Time 6.217 (6.217)\tData Load Time 3.386 (3.386)\tLoss 4.1563 (4.1563)\tTop-5 Accuracy 62.373 (62.373)\n",
            "Epoch: [4][100/118]\tBatch Time 2.499 (2.588)\tData Load Time 0.001 (0.038)\tLoss 4.0406 (4.0426)\tTop-5 Accuracy 64.327 (64.448)\n",
            "Epoch train time 302.458 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.143 (6.143)\tLoss 5.6275 (5.6275)\tTop-5 Accuracy 56.861 (56.861)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.36513441281948\n",
            "2: 39.95531891392487\n",
            "3: 23.39855288819612\n",
            "4: 13.859944552411365\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.203, TOP-5 ACCURACY - 58.546, BLEU-4 - 13.859944552411365\n",
            "\n",
            "Epoch validation time 52.426 (epoch_time.avg:.3f)\n",
            "Epoch     5: reducing learning rate of group 0 to 4.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [5][0/118]\tBatch Time 6.249 (6.249)\tData Load Time 3.396 (3.396)\tLoss 3.9731 (3.9731)\tTop-5 Accuracy 64.925 (64.925)\n",
            "Epoch: [5][100/118]\tBatch Time 2.496 (2.586)\tData Load Time 0.004 (0.038)\tLoss 3.8861 (3.9127)\tTop-5 Accuracy 66.947 (66.098)\n",
            "Epoch train time 302.556 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.043 (6.043)\tLoss 4.9487 (4.9487)\tTop-5 Accuracy 60.420 (60.420)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.08191983497687\n",
            "2: 42.0134139352928\n",
            "3: 24.979529799745116\n",
            "4: 14.951476028643487\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.147, TOP-5 ACCURACY - 59.719, BLEU-4 - 14.951476028643487\n",
            "\n",
            "Epoch validation time 52.068 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [6][0/118]\tBatch Time 6.262 (6.262)\tData Load Time 3.355 (3.355)\tLoss 3.8282 (3.8282)\tTop-5 Accuracy 67.611 (67.611)\n",
            "Epoch: [6][100/118]\tBatch Time 2.495 (2.590)\tData Load Time 0.001 (0.038)\tLoss 3.8610 (3.8860)\tTop-5 Accuracy 67.576 (66.476)\n",
            "Epoch train time 302.793 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.926 (5.926)\tLoss 4.9663 (4.9663)\tTop-5 Accuracy 61.603 (61.603)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.02156134706054\n",
            "2: 42.06938860888741\n",
            "3: 25.024029733834496\n",
            "4: 14.945800525069403\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.146, TOP-5 ACCURACY - 59.845, BLEU-4 - 14.945800525069403\n",
            "\n",
            "Epoch validation time 51.918 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [7][0/118]\tBatch Time 6.285 (6.285)\tData Load Time 3.405 (3.405)\tLoss 3.8936 (3.8936)\tTop-5 Accuracy 66.272 (66.272)\n",
            "Epoch: [7][100/118]\tBatch Time 2.594 (2.591)\tData Load Time 0.009 (0.038)\tLoss 3.7434 (3.8633)\tTop-5 Accuracy 68.561 (66.720)\n",
            "Epoch train time 303.034 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.068 (6.068)\tLoss 4.9725 (4.9725)\tTop-5 Accuracy 59.759 (59.759)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.99010717168665\n",
            "2: 41.97361873658687\n",
            "3: 24.963298819781297\n",
            "4: 14.850600842196778\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.137, TOP-5 ACCURACY - 60.008, BLEU-4 - 14.850600842196778\n",
            "\n",
            "Epoch validation time 52.044 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch     8: reducing learning rate of group 0 to 4.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [8][0/118]\tBatch Time 6.369 (6.369)\tData Load Time 3.302 (3.302)\tLoss 3.8153 (3.8153)\tTop-5 Accuracy 67.069 (67.069)\n",
            "Epoch: [8][100/118]\tBatch Time 2.487 (2.587)\tData Load Time 0.001 (0.037)\tLoss 3.8927 (3.8502)\tTop-5 Accuracy 66.347 (66.955)\n",
            "Epoch train time 302.431 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.050 (6.050)\tLoss 5.1200 (5.1200)\tTop-5 Accuracy 59.400 (59.400)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.06420072772018\n",
            "2: 42.125837353273674\n",
            "3: 25.06125884969414\n",
            "4: 14.898538403312426\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.140, TOP-5 ACCURACY - 59.992, BLEU-4 - 14.898538403312426\n",
            "\n",
            "Epoch validation time 51.751 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [9][0/118]\tBatch Time 6.476 (6.476)\tData Load Time 3.426 (3.426)\tLoss 3.9736 (3.9736)\tTop-5 Accuracy 65.645 (65.645)\n",
            "Epoch: [9][100/118]\tBatch Time 2.510 (2.588)\tData Load Time 0.008 (0.039)\tLoss 3.8845 (3.8470)\tTop-5 Accuracy 66.148 (66.953)\n",
            "Epoch train time 303.003 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.223 (6.223)\tLoss 4.9066 (4.9066)\tTop-5 Accuracy 61.400 (61.400)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.04019328248533\n",
            "2: 42.03161279512154\n",
            "3: 24.9834043128582\n",
            "4: 14.864079534577826\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.141, TOP-5 ACCURACY - 60.025, BLEU-4 - 14.864079534577826\n",
            "\n",
            "Epoch validation time 51.663 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [10][0/118]\tBatch Time 6.338 (6.338)\tData Load Time 3.298 (3.298)\tLoss 3.7988 (3.7988)\tTop-5 Accuracy 66.540 (66.540)\n",
            "Epoch: [10][100/118]\tBatch Time 2.508 (2.583)\tData Load Time 0.001 (0.037)\tLoss 3.8310 (3.8470)\tTop-5 Accuracy 67.235 (66.952)\n",
            "Epoch train time 302.400 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.004 (6.004)\tLoss 5.1052 (5.1052)\tTop-5 Accuracy 59.333 (59.333)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.0005004556202\n",
            "2: 42.123214823685764\n",
            "3: 25.121205023873994\n",
            "4: 15.01433469286676\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.145, TOP-5 ACCURACY - 60.010, BLEU-4 - 15.01433469286676\n",
            "\n",
            "Epoch validation time 52.920 (epoch_time.avg:.3f)\n",
            "Epoch    11: reducing learning rate of group 0 to 4.0000e-07.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/118]\tBatch Time 6.393 (6.393)\tData Load Time 3.440 (3.440)\tLoss 3.8473 (3.8473)\tTop-5 Accuracy 67.009 (67.009)\n",
            "Epoch: [11][100/118]\tBatch Time 2.506 (2.589)\tData Load Time 0.001 (0.039)\tLoss 3.7905 (3.8420)\tTop-5 Accuracy 68.395 (66.991)\n",
            "Epoch train time 302.598 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.009 (6.009)\tLoss 5.2243 (5.2243)\tTop-5 Accuracy 58.855 (58.855)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.11131557749341\n",
            "2: 42.12905360872821\n",
            "3: 25.082584484213193\n",
            "4: 14.95797589304783\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.147, TOP-5 ACCURACY - 60.000, BLEU-4 - 14.95797589304783\n",
            "\n",
            "Epoch validation time 51.977 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/118]\tBatch Time 6.364 (6.364)\tData Load Time 3.430 (3.430)\tLoss 3.7688 (3.7688)\tTop-5 Accuracy 67.585 (67.585)\n",
            "Epoch: [12][100/118]\tBatch Time 2.569 (2.590)\tData Load Time 0.008 (0.039)\tLoss 3.7709 (3.8400)\tTop-5 Accuracy 67.658 (67.067)\n",
            "Epoch train time 302.583 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.965 (5.965)\tLoss 5.0925 (5.0925)\tTop-5 Accuracy 61.375 (61.375)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.02226807479872\n",
            "2: 42.10366455543928\n",
            "3: 25.08280282279004\n",
            "4: 15.002578059753773\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.145, TOP-5 ACCURACY - 60.017, BLEU-4 - 15.002578059753773\n",
            "\n",
            "Epoch validation time 52.141 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [13][0/118]\tBatch Time 6.370 (6.370)\tData Load Time 3.380 (3.380)\tLoss 3.8277 (3.8277)\tTop-5 Accuracy 66.917 (66.917)\n",
            "Epoch: [13][100/118]\tBatch Time 2.482 (2.590)\tData Load Time 0.007 (0.038)\tLoss 3.8916 (3.8427)\tTop-5 Accuracy 65.768 (67.044)\n",
            "Epoch train time 302.716 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.043 (6.043)\tLoss 5.0631 (5.0631)\tTop-5 Accuracy 60.438 (60.438)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.0452376278377\n",
            "2: 42.1135107031518\n",
            "3: 25.02798174806512\n",
            "4: 14.890429301846172\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.145, TOP-5 ACCURACY - 60.017, BLEU-4 - 14.890429301846172\n",
            "\n",
            "Epoch validation time 52.940 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "Epoch    14: reducing learning rate of group 0 to 4.0000e-08.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [14][0/118]\tBatch Time 6.651 (6.651)\tData Load Time 3.591 (3.591)\tLoss 3.8403 (3.8403)\tTop-5 Accuracy 66.992 (66.992)\n",
            "Epoch: [14][100/118]\tBatch Time 2.613 (2.587)\tData Load Time 0.009 (0.041)\tLoss 3.8832 (3.8405)\tTop-5 Accuracy 66.186 (67.080)\n",
            "Epoch train time 303.139 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.925 (5.925)\tLoss 5.1934 (5.1934)\tTop-5 Accuracy 59.340 (59.340)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.00616522501048\n",
            "2: 42.0771971543842\n",
            "3: 25.060640377366216\n",
            "4: 14.944784587342925\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.146, TOP-5 ACCURACY - 60.027, BLEU-4 - 14.944784587342925\n",
            "\n",
            "Epoch validation time 53.172 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/118]\tBatch Time 6.383 (6.383)\tData Load Time 3.535 (3.535)\tLoss 3.6702 (3.6702)\tTop-5 Accuracy 70.209 (70.209)\n",
            "Epoch: [15][100/118]\tBatch Time 2.501 (2.590)\tData Load Time 0.001 (0.039)\tLoss 3.8114 (3.8380)\tTop-5 Accuracy 68.651 (67.025)\n",
            "Epoch train time 302.912 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 6.030 (6.030)\tLoss 5.2061 (5.2061)\tTop-5 Accuracy 59.863 (59.863)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.0067937130398\n",
            "2: 42.0424221054443\n",
            "3: 24.973457481733767\n",
            "4: 14.842557415692283\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.146, TOP-5 ACCURACY - 60.025, BLEU-4 - 14.842557415692283\n",
            "\n",
            "Epoch validation time 52.135 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnuK-b4pPd1",
        "outputId": "c00b6631-7519-433b-ff12-3b1594acd095"
      },
      "source": [
        "batch_size = 64\n",
        "fine_tune_encoder = True\n",
        "checkpoint = '/content/BEST_checkpoint_flickr8k_10k.pth.tar'\n",
        "# epochs = 30\n",
        "\n",
        "t_params['batch_size'] = batch_size\n",
        "t_params['data_name'] = t_params['data_name'] + \"_finetune\" \n",
        "t_params['fine_tune_encoder'] = True\n",
        "t_params['decoder_lr'] = t_params['decoder_lr'] / 10\n",
        "# t_params['epochs'] = epochs\n",
        "t_params"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'data_name': 'flickr8k_10k_finetune',\n",
              " 'decoder_lr': 4e-05,\n",
              " 'df_path': 'Image-Captioning/data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': True,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7fd41be8fdd0>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAZcDNwS1Ckw",
        "outputId": "f60a410e-6daa-4b16-cbfa-c4e3432affca"
      },
      "source": [
        "m = load_checkpoint(checkpoint)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 10\n",
            "Best Bleu-4: 15.01433469286676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptOGGuc8pWY1",
        "outputId": "d0942560-d390-417a-850c-1c602c46b668"
      },
      "source": [
        "fit(t_params, checkpoint=checkpoint, m_params=m_params, logger=logger)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Starting Epoch: 11\n",
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 30000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 5000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/469]\tBatch Time 4.717 (4.717)\tData Load Time 0.994 (0.994)\tLoss 4.0034 (4.0034)\tTop-5 Accuracy 65.419 (65.419)\n",
            "Epoch: [11][100/469]\tBatch Time 1.339 (1.393)\tData Load Time 0.001 (0.011)\tLoss 3.8959 (3.9596)\tTop-5 Accuracy 67.725 (65.133)\n",
            "Epoch: [11][200/469]\tBatch Time 1.379 (1.372)\tData Load Time 0.001 (0.006)\tLoss 3.8045 (3.9352)\tTop-5 Accuracy 66.024 (65.701)\n",
            "Epoch: [11][300/469]\tBatch Time 1.323 (1.366)\tData Load Time 0.002 (0.005)\tLoss 3.6938 (3.9122)\tTop-5 Accuracy 69.464 (66.075)\n",
            "Epoch: [11][400/469]\tBatch Time 1.345 (1.363)\tData Load Time 0.001 (0.004)\tLoss 3.7101 (3.8970)\tTop-5 Accuracy 68.865 (66.297)\n",
            "Epoch train time 639.134 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.659 (1.659)\tLoss 5.0372 (5.0372)\tTop-5 Accuracy 59.253 (59.253)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.64733597357313\n",
            "2: 42.789826059713754\n",
            "3: 25.725927912814363\n",
            "4: 15.591898806714797\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.134, TOP-5 ACCURACY - 60.365, BLEU-4 - 15.591898806714797\n",
            "\n",
            "Epoch validation time 50.232 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/469]\tBatch Time 2.629 (2.629)\tData Load Time 1.038 (1.038)\tLoss 3.8148 (3.8148)\tTop-5 Accuracy 67.506 (67.506)\n",
            "Epoch: [12][100/469]\tBatch Time 1.356 (1.366)\tData Load Time 0.001 (0.012)\tLoss 3.6991 (3.7624)\tTop-5 Accuracy 70.189 (68.454)\n",
            "Epoch: [12][200/469]\tBatch Time 1.351 (1.358)\tData Load Time 0.001 (0.006)\tLoss 3.6921 (3.7649)\tTop-5 Accuracy 68.813 (68.467)\n",
            "Epoch: [12][300/469]\tBatch Time 1.327 (1.355)\tData Load Time 0.001 (0.005)\tLoss 3.9311 (3.7685)\tTop-5 Accuracy 66.122 (68.368)\n",
            "Epoch: [12][400/469]\tBatch Time 1.420 (1.355)\tData Load Time 0.003 (0.004)\tLoss 3.7700 (3.7734)\tTop-5 Accuracy 68.382 (68.333)\n",
            "Epoch train time 634.466 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.583 (1.583)\tLoss 5.1237 (5.1237)\tTop-5 Accuracy 58.151 (58.151)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.34985861579617\n",
            "2: 42.44825478739755\n",
            "3: 25.523984626879994\n",
            "4: 15.381888031485508\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.137, TOP-5 ACCURACY - 60.411, BLEU-4 - 15.381888031485508\n",
            "\n",
            "Epoch validation time 50.689 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [13][0/469]\tBatch Time 2.416 (2.416)\tData Load Time 0.979 (0.979)\tLoss 3.6356 (3.6356)\tTop-5 Accuracy 70.872 (70.872)\n",
            "Epoch: [13][100/469]\tBatch Time 1.338 (1.364)\tData Load Time 0.001 (0.011)\tLoss 3.6742 (3.7156)\tTop-5 Accuracy 70.668 (69.285)\n",
            "Epoch: [13][200/469]\tBatch Time 1.362 (1.356)\tData Load Time 0.001 (0.006)\tLoss 3.7075 (3.7102)\tTop-5 Accuracy 69.057 (69.396)\n",
            "Epoch: [13][300/469]\tBatch Time 1.348 (1.354)\tData Load Time 0.003 (0.004)\tLoss 3.6017 (3.7084)\tTop-5 Accuracy 72.959 (69.412)\n",
            "Epoch: [13][400/469]\tBatch Time 1.354 (1.354)\tData Load Time 0.001 (0.004)\tLoss 3.7368 (3.7171)\tTop-5 Accuracy 68.707 (69.298)\n",
            "Epoch train time 634.394 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.519 (1.519)\tLoss 5.4898 (5.4898)\tTop-5 Accuracy 57.586 (57.586)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.38934338759567\n",
            "2: 42.569609664157824\n",
            "3: 25.624410392209175\n",
            "4: 15.511989081823327\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.124, TOP-5 ACCURACY - 60.497, BLEU-4 - 15.511989081823327\n",
            "\n",
            "Epoch validation time 50.149 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [14][0/469]\tBatch Time 2.411 (2.411)\tData Load Time 0.937 (0.937)\tLoss 3.6884 (3.6884)\tTop-5 Accuracy 68.264 (68.264)\n",
            "Epoch: [14][100/469]\tBatch Time 1.343 (1.363)\tData Load Time 0.001 (0.011)\tLoss 3.5964 (3.6452)\tTop-5 Accuracy 70.204 (70.442)\n",
            "Epoch: [14][200/469]\tBatch Time 1.381 (1.355)\tData Load Time 0.001 (0.006)\tLoss 3.5033 (3.6584)\tTop-5 Accuracy 73.496 (70.135)\n",
            "Epoch: [14][300/469]\tBatch Time 1.375 (1.354)\tData Load Time 0.001 (0.004)\tLoss 3.5907 (3.6619)\tTop-5 Accuracy 70.054 (70.149)\n",
            "Epoch: [14][400/469]\tBatch Time 1.321 (1.353)\tData Load Time 0.000 (0.003)\tLoss 3.7807 (3.6701)\tTop-5 Accuracy 68.817 (70.037)\n",
            "Epoch train time 634.022 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.584 (1.584)\tLoss 5.3947 (5.3947)\tTop-5 Accuracy 60.095 (60.095)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.78878952791322\n",
            "2: 42.99791153296206\n",
            "3: 25.899305614880657\n",
            "4: 15.544865920661637\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.118, TOP-5 ACCURACY - 60.526, BLEU-4 - 15.544865920661637\n",
            "\n",
            "Epoch validation time 49.298 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/469]\tBatch Time 2.449 (2.449)\tData Load Time 1.005 (1.005)\tLoss 3.7035 (3.7035)\tTop-5 Accuracy 70.977 (70.977)\n",
            "Epoch: [15][100/469]\tBatch Time 1.380 (1.362)\tData Load Time 0.001 (0.011)\tLoss 3.5042 (3.6189)\tTop-5 Accuracy 72.871 (70.752)\n",
            "Epoch: [15][200/469]\tBatch Time 1.336 (1.354)\tData Load Time 0.001 (0.006)\tLoss 3.5654 (3.6214)\tTop-5 Accuracy 70.926 (70.805)\n",
            "Epoch: [15][300/469]\tBatch Time 1.375 (1.352)\tData Load Time 0.001 (0.004)\tLoss 3.6325 (3.6281)\tTop-5 Accuracy 69.868 (70.705)\n",
            "Epoch: [15][400/469]\tBatch Time 1.361 (1.353)\tData Load Time 0.001 (0.004)\tLoss 3.7548 (3.6314)\tTop-5 Accuracy 68.662 (70.638)\n",
            "Epoch train time 633.811 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.537 (1.537)\tLoss 4.7095 (4.7095)\tTop-5 Accuracy 62.314 (62.314)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.32032482232393\n",
            "2: 42.36197834418804\n",
            "3: 25.360392815661815\n",
            "4: 15.215032854197421\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.128, TOP-5 ACCURACY - 60.396, BLEU-4 - 15.215032854197421\n",
            "\n",
            "Epoch validation time 49.187 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [16][0/469]\tBatch Time 2.427 (2.427)\tData Load Time 0.951 (0.951)\tLoss 3.5060 (3.5060)\tTop-5 Accuracy 70.839 (70.839)\n",
            "Epoch: [16][100/469]\tBatch Time 1.368 (1.365)\tData Load Time 0.002 (0.011)\tLoss 3.5747 (3.5856)\tTop-5 Accuracy 72.375 (71.383)\n",
            "Epoch: [16][200/469]\tBatch Time 1.351 (1.354)\tData Load Time 0.002 (0.006)\tLoss 3.5501 (3.5974)\tTop-5 Accuracy 72.846 (71.221)\n",
            "Epoch: [16][300/469]\tBatch Time 1.333 (1.352)\tData Load Time 0.002 (0.004)\tLoss 3.5307 (3.5990)\tTop-5 Accuracy 71.294 (71.194)\n",
            "Epoch: [16][400/469]\tBatch Time 1.340 (1.352)\tData Load Time 0.003 (0.004)\tLoss 3.5838 (3.6021)\tTop-5 Accuracy 70.839 (71.148)\n",
            "Epoch train time 633.531 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.577 (1.577)\tLoss 5.3317 (5.3317)\tTop-5 Accuracy 58.305 (58.305)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.26950607960987\n",
            "2: 42.34521298129909\n",
            "3: 25.561820671065483\n",
            "4: 15.355684336672129\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.132, TOP-5 ACCURACY - 60.537, BLEU-4 - 15.355684336672129\n",
            "\n",
            "Epoch validation time 49.322 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKFBHm66Guzh"
      },
      "source": [
        "!cp BEST_checkpoint_flickr8k_10k_finetune.pth.tar /content/drive/MyDrive/ImageCaptioning/flickr8 "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccZ5fIHKG_is",
        "outputId": "6f5e9fa9-22ef-4a43-ee28-0a19400fa440"
      },
      "source": [
        "checkpoint = load_checkpoint(\"BEST_checkpoint_flickr8k_10k_finetune.pth.tar\")\n",
        "decoder = checkpoint['decoder']\n",
        "decoder = decoder.to(device)\n",
        "decoder.eval()\n",
        "encoder = checkpoint['encoder']\n",
        "encoder = encoder.to(device)\n",
        "encoder.eval();"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 11\n",
            "Best Bleu-4: 15.591898806714797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mry15OR5HFrL",
        "outputId": "730d5840-6c14-4cdb-8276-c5ef788074ea"
      },
      "source": [
        "from eval import test_score\n",
        "\n",
        "test_dict = {}\n",
        "\n",
        "for i in [1, 3, 5]:\n",
        "    \n",
        "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)\n",
        "    if i == 3:\n",
        "        test_dict['b1'] = b1\n",
        "        test_dict['b2'] = b2\n",
        "        test_dict['b3'] = b3\n",
        "    \n",
        "    test_dict[f'b4-b{i}'] = b4"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 1:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "EVALUATING AT BEAM SIZE 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [02:56<00:00, 28.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 58.17601701675087\n",
            "2: 41.224822354462354\n",
            "3: 28.000938478839238\n",
            "4: 18.72495762865639\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 3:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [03:30<00:00, 23.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 61.8241965973535\n",
            "2: 44.249082940660614\n",
            "3: 30.579058561977185\n",
            "4: 20.87097692129813\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 5:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [04:01<00:00, 20.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 63.51175587793897\n",
            "2: 45.608191049287484\n",
            "3: 31.757167505838897\n",
            "4: 21.785908024986437\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}