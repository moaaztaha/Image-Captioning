{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb6773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b30e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os import path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b2b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from train import *\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8ff6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "encoder_dim = 2048 # resnet101\n",
    "emb_dim = 1000  # dimension of word embeddings\n",
    "attention_dim = 1000  # dimension of attention linear layers\n",
    "decoder_dim = 1000  # dimension of decoder RNN\n",
    "dropout = 0.3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# training parameters\n",
    "epochs = 2  # number of epochs to train for (if early stopping is not triggered)\n",
    "batch_size = 64\n",
    "workers = 4\n",
    "encoder_lr = 3e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 2e-4  # learning rate for decoder\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7650aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = 'testing_experiemnts_process'\n",
    "\n",
    "# local\n",
    "# DATA_JSON_PATH = 'data.json'\n",
    "# IMGS_PATH = 'flickr/Images/'\n",
    "# kaggle paths\n",
    "DATA_JSON_PATH = 'data.json'\n",
    "IMGS_PATH = 'flickr/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb139f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 372487.64it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(DATA_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c65a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5089"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(vocab); vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8604837",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_params = {\n",
    "    'data_name': DATA_NAME,\n",
    "    'imgs_path': IMGS_PATH,\n",
    "    'df_path': DATA_JSON_PATH,\n",
    "    'vocab': vocab,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'workers': workers,\n",
    "    'decoder_lr': decoder_lr,\n",
    "    'encoder_lr': encoder_lr,\n",
    "    'fine_tune_encoder': fine_tune_encoder\n",
    "}\n",
    "\n",
    "m_params = {\n",
    "    'dropout': dropout,\n",
    "    'attention_dim': attention_dim,\n",
    "    'embed_dim': emb_dim,\n",
    "    'decoder_dim': decoder_dim,\n",
    "    'encoder_dim': encoder_dim\n",
    "}\n",
    "\n",
    "logger_dic = {\n",
    "    'decoder_lr': decoder_lr,\n",
    "    'encoder_lr': encoder_lr,\n",
    "    'fine_tune_encoder': fine_tune_encoder,\n",
    "    'max_seq_length': 100,\n",
    "    'vocab_size': vocab_len,\n",
    "    'enocder': 'resnet101',\n",
    "    'dropout': dropout,\n",
    "    'attention_dim': attention_dim,\n",
    "    'embed_dim': emb_dim,\n",
    "    'decoder_dim': decoder_dim,\n",
    "    'encoder_dim': encoder_dim \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43a14aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment name\n",
    "name = DATA_NAME\n",
    "# path\n",
    "log_dir = 'experiments'\n",
    "\n",
    "logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ae3cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'testing_experiemnts_process',\n",
       " 'imgs_path': 'flickr/Images/',\n",
       " 'df_path': 'data.json',\n",
       " 'vocab': <dataset.Vocabulary at 0x7f3612dfbe90>,\n",
       " 'epochs': 2,\n",
       " 'batch_size': 64,\n",
       " 'workers': 4,\n",
       " 'decoder_lr': 0.0002,\n",
       " 'encoder_lr': 0.0003,\n",
       " 'fine_tune_encoder': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60edca93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Dataset split: train\n",
      "Unique images: 6000\n",
      "Total size: 30000\n",
      "Dataset split: val\n",
      "Unique images: 1000\n",
      "Total size: 5000\n",
      "__________________________________________________\n",
      "-------------------- Fitting --------------------\n",
      "__________________________________________________\n",
      "-------------------- Training --------------------\n",
      "Epoch: [0][0/469]\tBatch Time 3.944 (3.944)\tData Load Time 1.068 (1.068)\tLoss 9.4606 (9.4606)\tTop-5 Accuracy 0.000 (0.000)\n",
      "Epoch: [0][100/469]\tBatch Time 1.359 (1.377)\tData Load Time 0.001 (0.011)\tLoss 5.2761 (5.7068)\tTop-5 Accuracy 49.596 (42.486)\n",
      "Epoch: [0][200/469]\tBatch Time 1.419 (1.373)\tData Load Time 0.000 (0.006)\tLoss 4.7461 (5.3222)\tTop-5 Accuracy 55.707 (47.879)\n",
      "Epoch: [0][300/469]\tBatch Time 1.375 (1.375)\tData Load Time 0.000 (0.004)\tLoss 4.6615 (5.1015)\tTop-5 Accuracy 56.899 (50.902)\n",
      "Epoch: [0][400/469]\tBatch Time 1.351 (1.376)\tData Load Time 0.001 (0.003)\tLoss 4.3963 (4.9499)\tTop-5 Accuracy 60.680 (52.956)\n",
      "Epoch train time 646.779 (epoch_time.avg:.3f)\n",
      "-------------------- Validation --------------------\n",
      "Validation: [0/79]\tBatch Time 1.933 (1.933)\tLoss 5.3221 (5.3221)\tTop-5 Accuracy 55.573 (55.573)\t\n",
      "----- Bleu-n Scores -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 63.47428594160521\n",
      "2: 39.58047964932961\n",
      "3: 22.91363011374662\n",
      "4: 13.473099968356847\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:11<00:00, 424.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.30135740038171277\n",
      "\n",
      " * LOSS - 5.119, TOP-5 ACCURACY - 56.367, BLEU-4 - 13.473099968356847\n",
      "\n",
      "Epoch validation time 83.919 (epoch_time.avg:.3f)\n",
      "__________________________________________________\n",
      "-------------------- Training --------------------\n",
      "Epoch: [1][0/469]\tBatch Time 7.735 (7.735)\tData Load Time 6.334 (6.334)\tLoss 4.1532 (4.1532)\tTop-5 Accuracy 64.238 (64.238)\n",
      "Epoch: [1][100/469]\tBatch Time 1.390 (1.441)\tData Load Time 0.000 (0.063)\tLoss 4.2258 (4.2656)\tTop-5 Accuracy 62.549 (61.710)\n",
      "Epoch: [1][200/469]\tBatch Time 1.390 (1.419)\tData Load Time 0.000 (0.032)\tLoss 4.0724 (4.2202)\tTop-5 Accuracy 62.963 (62.309)\n",
      "Epoch: [1][300/469]\tBatch Time 1.423 (1.410)\tData Load Time 0.000 (0.022)\tLoss 4.0619 (4.1855)\tTop-5 Accuracy 63.787 (62.759)\n",
      "Epoch: [1][400/469]\tBatch Time 1.408 (1.405)\tData Load Time 0.000 (0.016)\tLoss 4.1961 (4.1520)\tTop-5 Accuracy 63.373 (63.268)\n",
      "Epoch train time 657.862 (epoch_time.avg:.3f)\n",
      "-------------------- Validation --------------------\n",
      "Validation: [0/79]\tBatch Time 2.036 (2.036)\tLoss 4.8819 (4.8819)\tTop-5 Accuracy 62.459 (62.459)\t\n",
      "----- Bleu-n Scores -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 45/5000 [00:00<00:11, 449.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 64.3503053678497\n",
      "2: 40.45690149367875\n",
      "3: 23.787402299442828\n",
      "4: 13.934173482196025\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:12<00:00, 412.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.32407175136920063\n",
      "\n",
      " * LOSS - 5.114, TOP-5 ACCURACY - 58.813, BLEU-4 - 13.934173482196025\n",
      "\n",
      "Epoch validation time 84.101 (epoch_time.avg:.3f)\n"
     ]
    }
   ],
   "source": [
    "fit(t_params=t_params, m_params=m_params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa01682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpoint!!\n",
      "Last Epoch: 1\n",
      "Best Bleu-4: 13.934173482196025\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint \n",
    "# Load model\n",
    "CHECKPOINT_PATH = 'BEST_checkpoint_testing_experiemnts_process.pth.tar'\n",
    "\n",
    "checkpoint = load_checkpoint(CHECKPOINT_PATH)\n",
    "decoder = checkpoint['decoder']\n",
    "decoder = decoder.to(device)\n",
    "decoder.eval()\n",
    "encoder = checkpoint['encoder']\n",
    "encoder = encoder.to(device)\n",
    "encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8ebbe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "EVALUATING AT BEAM SIZE 1:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 1: 100%|██████████| 5000/5000 [03:14<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 56.115238267802134\n",
      "2: 38.15185584589656\n",
      "3: 24.771081427232787\n",
      "4: 16.003448564877804\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [00:16<00:00, 311.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.3778662442990078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eval import test_score\n",
    "\n",
    "b1, b2, b3, b4, m = test_score(1, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d366aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8416a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "EVALUATING AT BEAM SIZE 1:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 1: 100%|██████████| 5000/5000 [03:31<00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 56.115238267802134\n",
      "2: 38.15185584589656\n",
      "3: 24.771081427232787\n",
      "4: 16.003448564877804\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [00:14<00:00, 352.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.3778662442990085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "EVALUATING AT BEAM SIZE 3:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 3: 100%|██████████| 5000/5000 [04:25<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 59.96753576138785\n",
      "2: 41.09254161374708\n",
      "3: 27.484138401378967\n",
      "4: 18.16994793899022\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:13<00:00, 376.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.3853924658437256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "EVALUATING AT BEAM SIZE 5:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 5: 100%|██████████| 5000/5000 [05:56<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 60.933232891919374\n",
      "2: 41.813695672017104\n",
      "3: 27.99716154984623\n",
      "4: 18.335074227709068\n",
      "-------------------------\n",
      "----- METEOR Score -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:13<00:00, 379.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0.379726242907985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 3, 5]:\n",
    "    \n",
    "    b1, b2, b3, b4, m = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)\n",
    "    if i == 3:\n",
    "        test_dict['b1'] = b1\n",
    "        test_dict['b2'] = b2\n",
    "        test_dict['b3'] = b3\n",
    "    \n",
    "    test_dict[f'b4-b{i}'] = b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c9b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b4-b1': 16.003448564877804,\n",
       " 'b1': 59.96753576138785,\n",
       " 'b2': 41.09254161374708,\n",
       " 'b3': 27.484138401378967,\n",
       " 'b4-b3': 18.16994793899022,\n",
       " 'b4-b5': 18.335074227709068}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d759de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results -> different from training and validation scalars\n",
    "results_dic =  {\n",
    "    # train & valid\n",
    "    'total_epochs': 2,\n",
    "    'top5acc/valid/1': 58.8,\n",
    "    'b-1/test': test_dict['b1'],\n",
    "    'b-2/test': test_dict['b2'],\n",
    "    'b-3/test': test_dict['b3'],\n",
    "    'b-4/b3': test_dict['b4-b3'],\n",
    "    'b-4/b1': test_dict['b4-b1'],\n",
    "    'b-4/b5': test_dict['b4-b5']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a2d57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.add_hparams(logger_dic, results_dic, run_name='finetune')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
