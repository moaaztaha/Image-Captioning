{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flickr8 LR SCHED",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yF22FLldBVv",
        "outputId": "4b5dd0b1-033d-40c0-ef57-cbcd4f04b9aa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 24 13:15:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   4772MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAVbNRecdEmC"
      },
      "source": [
        "# !mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FHpPT9-dPip",
        "outputId": "3a74d6fb-129f-4aa8-de13-afaa7ad92391"
      },
      "source": [
        "!pip install kaggle -q\n",
        "!kaggle datasets download -d aladdinpersson/flickr8kimagescaptions\n",
        "!unzip -q flickr8kimagescaptions.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickr8kimagescaptions.zip to /content\n",
            " 98% 1.01G/1.04G [00:06<00:00, 154MB/s]\n",
            "100% 1.04G/1.04G [00:06<00:00, 163MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rhy46y0NmxV"
      },
      "source": [
        "!rm -r Image-Captioning/"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdb4vWE0dQS6"
      },
      "source": [
        "# # get the code for kaggle\n",
        "# !git clone https://github.com/moaaztaha/Image-Captioning\n",
        "py_files_path = 'Image-Captioning/'\n",
        "import sys\n",
        "sys.path.append(py_files_path)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCupTxpafLCY"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJpGuI-eJ1aC"
      },
      "source": [
        "# !pip3 install nltk==3.6.2\n",
        "# import nltk\n",
        "# nltk.download(\"wordnet\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAUwbIDzfLCY"
      },
      "source": [
        "import time \n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from models import Encoder, DecoderWithAttention\n",
        "from dataset import *\n",
        "from utils import *\n",
        "from train import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from os import path as osp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xao3iXYfLCZ"
      },
      "source": [
        "# Model parameters\n",
        "encoder_dim = 2048 # resnet101\n",
        "emb_dim = 512  # dimension of word embeddings\n",
        "attention_dim = 512  # dimension of attention linear layers\n",
        "decoder_dim = 512  # dimension of decoder RNN\n",
        "dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
        "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
        "\n",
        "# training parameters\n",
        "epochs = 30  # number of epochs to train for (if early stopping is not triggered)\n",
        "batch_size = 256\n",
        "workers = 2\n",
        "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
        "decoder_lr = 4e-4  # learning rate for decoder\n",
        "fine_tune_encoder = False  # fine-tune encoder?\n",
        "pretrained_embeddings = False\n",
        "fine_tune_embeddings = False\n",
        "checkpoint = None  # path to checkpoint, None if none"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjGhnGwvfLCZ"
      },
      "source": [
        "DATA_NAME = 'flickr8k'\n",
        "\n",
        "# local\n",
        "# DATA_JSON_PATH = 'data.json'\n",
        "# IMGS_PATH = 'flickr/Images/'\n",
        "# kaggle paths\n",
        "# DATA_JSON_PATH = '/kaggle/working/Image-Captioning/data.json'\n",
        "# IMGS_PATH = '../input/flickr8kimagescaptions/flickr8k/images/'\n",
        "#colab\n",
        "DATA_JSON_PATH = 'Image-Captioning/data.json'\n",
        "IMGS_PATH = 'flickr8k/images/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohaaGjb7fLCa",
        "outputId": "9a8aeacd-ea15-4e0a-9792-796a49179be1"
      },
      "source": [
        "# load vocab\n",
        "vocab = build_vocab(DATA_JSON_PATH)\n",
        "# top10k_words = get_10k_vocab(\"/content/Image-Captioning/10k_words.txt\")\n",
        "# vocab = top10k_vocab(top10k_words)\n",
        "vocab_len = len(vocab)\n",
        "vocab_len"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [00:00<00:00, 278697.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5089"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6quGOJjfLCb"
      },
      "source": [
        "t_params = {\n",
        "    'data_name': DATA_NAME,\n",
        "    'imgs_path': IMGS_PATH,\n",
        "    'df_path': DATA_JSON_PATH,\n",
        "    'vocab': vocab,\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'workers': workers,\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "}\n",
        "\n",
        "m_params = {\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim,\n",
        "    'dropout': dropout\n",
        "}\n",
        "\n",
        "logger_dic = {\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "    'max_seq_length': 100,\n",
        "    'vocab_size': vocab_len,\n",
        "    'enocder': 'resnet101',\n",
        "    'dropout': dropout,\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim \n",
        "    \n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9hJPzJhh4v4",
        "outputId": "47411e4c-98ff-493f-a7c4-1c127f3a5927"
      },
      "source": [
        "t_params"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 256,\n",
              " 'data_name': 'flickr8k',\n",
              " 'decoder_lr': 0.0004,\n",
              " 'df_path': 'Image-Captioning/data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': False,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f851678a590>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8kS-8cKOWR"
      },
      "source": [
        "# experiment name\n",
        "name = DATA_NAME + \"\"\n",
        "# path\n",
        "log_dir = '/content/drive/MyDrive/ImageCaptioning/flickr8/experiments_vanilla'\n",
        "\n",
        "logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq-qHyNcIQLQ",
        "outputId": "b83727f3-67ce-4276-9367-04e500c0cd46"
      },
      "source": [
        "# with scheduler\n",
        "fit(t_params=t_params, m_params=m_params, logger=logger)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 30000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 5000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [0][0/118]\tBatch Time 6.178 (6.178)\tData Load Time 3.764 (3.764)\tLoss 9.4634 (9.4634)\tTop-5 Accuracy 0.066 (0.066)\n",
            "Epoch: [0][100/118]\tBatch Time 2.468 (2.495)\tData Load Time 0.008 (0.041)\tLoss 4.8366 (5.5073)\tTop-5 Accuracy 53.386 (44.615)\n",
            "Epoch train time 291.381 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.966 (5.966)\tLoss 5.5111 (5.5111)\tTop-5 Accuracy 51.320 (51.320)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 59.34414293382591\n",
            "2: 34.05497832528091\n",
            "3: 17.225916095691\n",
            "4: 8.844724455255006\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.426, TOP-5 ACCURACY - 50.979, BLEU-4 - 8.844724455255006\n",
            "\n",
            "Epoch validation time 52.314 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [1][0/118]\tBatch Time 6.322 (6.322)\tData Load Time 3.524 (3.524)\tLoss 4.7736 (4.7736)\tTop-5 Accuracy 54.417 (54.417)\n",
            "Epoch: [1][100/118]\tBatch Time 2.437 (2.478)\tData Load Time 0.001 (0.039)\tLoss 4.4358 (4.6102)\tTop-5 Accuracy 59.942 (56.790)\n",
            "Epoch train time 289.900 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.978 (5.978)\tLoss 5.1876 (5.1876)\tTop-5 Accuracy 54.404 (54.404)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 62.236482495695924\n",
            "2: 37.71244850539998\n",
            "3: 20.771190456189302\n",
            "4: 11.902523091954059\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.186, TOP-5 ACCURACY - 54.934, BLEU-4 - 11.902523091954059\n",
            "\n",
            "Epoch validation time 51.934 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [2][0/118]\tBatch Time 6.296 (6.296)\tData Load Time 3.457 (3.457)\tLoss 4.4823 (4.4823)\tTop-5 Accuracy 57.622 (57.622)\n",
            "Epoch: [2][100/118]\tBatch Time 2.421 (2.482)\tData Load Time 0.001 (0.039)\tLoss 4.3308 (4.3406)\tTop-5 Accuracy 60.052 (60.348)\n",
            "Epoch train time 290.023 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.828 (5.828)\tLoss 5.2848 (5.2848)\tTop-5 Accuracy 55.947 (55.947)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.21726666405028\n",
            "2: 37.3479756962004\n",
            "3: 20.594059392572532\n",
            "4: 11.334097347685525\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.147, TOP-5 ACCURACY - 56.174, BLEU-4 - 11.334097347685525\n",
            "\n",
            "Epoch validation time 51.536 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [3][0/118]\tBatch Time 5.876 (5.876)\tData Load Time 3.329 (3.329)\tLoss 4.1463 (4.1463)\tTop-5 Accuracy 63.321 (63.321)\n",
            "Epoch: [3][100/118]\tBatch Time 2.420 (2.479)\tData Load Time 0.001 (0.037)\tLoss 4.1543 (4.1546)\tTop-5 Accuracy 63.080 (62.680)\n",
            "Epoch train time 289.829 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.878 (5.878)\tLoss 5.1385 (5.1385)\tTop-5 Accuracy 57.154 (57.154)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.81457143850051\n",
            "2: 38.89686935502718\n",
            "3: 21.622933715563804\n",
            "4: 12.25493211271718\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.063, TOP-5 ACCURACY - 57.772, BLEU-4 - 12.25493211271718\n",
            "\n",
            "Epoch validation time 51.552 (epoch_time.avg:.3f)\n",
            "Epoch     4: reducing learning rate of group 0 to 4.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [4][0/118]\tBatch Time 6.051 (6.051)\tData Load Time 3.382 (3.382)\tLoss 4.1112 (4.1112)\tTop-5 Accuracy 63.611 (63.611)\n",
            "Epoch: [4][100/118]\tBatch Time 2.473 (2.473)\tData Load Time 0.001 (0.038)\tLoss 4.0156 (4.0125)\tTop-5 Accuracy 64.526 (64.462)\n",
            "Epoch train time 289.334 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.648 (5.648)\tLoss 4.8878 (4.8878)\tTop-5 Accuracy 59.019 (59.019)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.30663223774492\n",
            "2: 41.43801564690688\n",
            "3: 24.52604488095261\n",
            "4: 14.597341491195264\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.015, TOP-5 ACCURACY - 58.945, BLEU-4 - 14.597341491195264\n",
            "\n",
            "Epoch validation time 51.036 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [5][0/118]\tBatch Time 6.063 (6.063)\tData Load Time 3.448 (3.448)\tLoss 4.0494 (4.0494)\tTop-5 Accuracy 64.772 (64.772)\n",
            "Epoch: [5][100/118]\tBatch Time 2.395 (2.474)\tData Load Time 0.001 (0.038)\tLoss 3.8830 (3.9766)\tTop-5 Accuracy 67.314 (65.112)\n",
            "Epoch train time 289.289 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.863 (5.863)\tLoss 4.7524 (4.7524)\tTop-5 Accuracy 61.948 (61.948)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.30565194967834\n",
            "2: 41.470071479569704\n",
            "3: 24.524932131464766\n",
            "4: 14.621289710870041\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.018, TOP-5 ACCURACY - 59.134, BLEU-4 - 14.621289710870041\n",
            "\n",
            "Epoch validation time 51.180 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [6][0/118]\tBatch Time 5.944 (5.944)\tData Load Time 3.253 (3.253)\tLoss 4.0194 (4.0194)\tTop-5 Accuracy 64.272 (64.272)\n",
            "Epoch: [6][100/118]\tBatch Time 2.391 (2.473)\tData Load Time 0.001 (0.037)\tLoss 3.9624 (3.9582)\tTop-5 Accuracy 65.057 (65.301)\n",
            "Epoch train time 289.416 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.760 (5.760)\tLoss 5.2515 (5.2515)\tTop-5 Accuracy 57.878 (57.878)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.67169104541091\n",
            "2: 41.738399195630855\n",
            "3: 24.674317437457553\n",
            "4: 14.687291351633384\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.031, TOP-5 ACCURACY - 59.266, BLEU-4 - 14.687291351633384\n",
            "\n",
            "Epoch validation time 50.922 (epoch_time.avg:.3f)\n",
            "Epoch     7: reducing learning rate of group 0 to 4.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [7][0/118]\tBatch Time 5.964 (5.964)\tData Load Time 3.250 (3.250)\tLoss 3.9869 (3.9869)\tTop-5 Accuracy 63.743 (63.743)\n",
            "Epoch: [7][100/118]\tBatch Time 2.430 (2.474)\tData Load Time 0.009 (0.036)\tLoss 4.0407 (3.9427)\tTop-5 Accuracy 64.356 (65.507)\n",
            "Epoch train time 289.321 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.809 (5.809)\tLoss 5.1459 (5.1459)\tTop-5 Accuracy 58.394 (58.394)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.54021546573847\n",
            "2: 41.64434081334137\n",
            "3: 24.665909470180143\n",
            "4: 14.73513812809891\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.030, TOP-5 ACCURACY - 59.312, BLEU-4 - 14.73513812809891\n",
            "\n",
            "Epoch validation time 51.320 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [8][0/118]\tBatch Time 5.911 (5.911)\tData Load Time 3.378 (3.378)\tLoss 4.0359 (4.0359)\tTop-5 Accuracy 64.295 (64.295)\n",
            "Epoch: [8][100/118]\tBatch Time 2.461 (2.479)\tData Load Time 0.007 (0.038)\tLoss 4.0058 (3.9408)\tTop-5 Accuracy 64.518 (65.506)\n",
            "Epoch train time 289.716 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.852 (5.852)\tLoss 4.9995 (4.9995)\tTop-5 Accuracy 59.226 (59.226)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.56420997973356\n",
            "2: 41.61611288536394\n",
            "3: 24.61795569489676\n",
            "4: 14.695485842209111\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.032, TOP-5 ACCURACY - 59.312, BLEU-4 - 14.695485842209111\n",
            "\n",
            "Epoch validation time 51.028 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [9][0/118]\tBatch Time 5.958 (5.958)\tData Load Time 3.308 (3.308)\tLoss 3.8655 (3.8655)\tTop-5 Accuracy 66.303 (66.303)\n",
            "Epoch: [9][100/118]\tBatch Time 2.424 (2.474)\tData Load Time 0.009 (0.036)\tLoss 3.9649 (3.9370)\tTop-5 Accuracy 64.876 (65.612)\n",
            "Epoch train time 289.251 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.760 (5.760)\tLoss 5.4676 (5.4676)\tTop-5 Accuracy 55.108 (55.108)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.58079370548413\n",
            "2: 41.67574011996424\n",
            "3: 24.646120643830088\n",
            "4: 14.679773638277632\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.033, TOP-5 ACCURACY - 59.333, BLEU-4 - 14.679773638277632\n",
            "\n",
            "Epoch validation time 51.232 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch    10: reducing learning rate of group 0 to 4.0000e-07.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [10][0/118]\tBatch Time 5.950 (5.950)\tData Load Time 3.237 (3.237)\tLoss 3.9745 (3.9745)\tTop-5 Accuracy 65.196 (65.196)\n",
            "Epoch: [10][100/118]\tBatch Time 2.414 (2.473)\tData Load Time 0.001 (0.036)\tLoss 4.0046 (3.9375)\tTop-5 Accuracy 65.361 (65.656)\n",
            "Epoch train time 289.341 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.770 (5.770)\tLoss 5.0581 (5.0581)\tTop-5 Accuracy 58.893 (58.893)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.54191514191669\n",
            "2: 41.625271622150514\n",
            "3: 24.612582388992543\n",
            "4: 14.69047751194493\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.031, TOP-5 ACCURACY - 59.346, BLEU-4 - 14.69047751194493\n",
            "\n",
            "Epoch validation time 51.443 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/118]\tBatch Time 5.928 (5.928)\tData Load Time 3.237 (3.237)\tLoss 3.9556 (3.9556)\tTop-5 Accuracy 64.772 (64.772)\n",
            "Epoch: [11][100/118]\tBatch Time 2.428 (2.473)\tData Load Time 0.001 (0.037)\tLoss 3.8414 (3.9344)\tTop-5 Accuracy 66.382 (65.680)\n",
            "Epoch train time 289.321 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.867 (5.867)\tLoss 5.2838 (5.2838)\tTop-5 Accuracy 56.785 (56.785)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.58013076140313\n",
            "2: 41.640389430343866\n",
            "3: 24.625624255855676\n",
            "4: 14.709801012153061\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.032, TOP-5 ACCURACY - 59.310, BLEU-4 - 14.709801012153061\n",
            "\n",
            "Epoch validation time 51.284 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/118]\tBatch Time 5.971 (5.971)\tData Load Time 3.305 (3.305)\tLoss 3.8652 (3.8652)\tTop-5 Accuracy 67.088 (67.088)\n",
            "Epoch: [12][100/118]\tBatch Time 2.414 (2.477)\tData Load Time 0.007 (0.038)\tLoss 3.9704 (3.9358)\tTop-5 Accuracy 65.295 (65.554)\n",
            "Epoch train time 289.708 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/20]\tBatch Time 5.735 (5.735)\tLoss 5.1818 (5.1818)\tTop-5 Accuracy 58.938 (58.938)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 65.54386570769772\n",
            "2: 41.60331706258696\n",
            "3: 24.570616975462347\n",
            "4: 14.658272097955221\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.033, TOP-5 ACCURACY - 59.329, BLEU-4 - 14.658272097955221\n",
            "\n",
            "Epoch validation time 51.061 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH9cPBNndS_p"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHCF3XLMdzHj"
      },
      "source": [
        "!cp /content/BEST_checkpoint_flickr8k.pth.tar /content/drive/MyDrive/ImageCaptioning/flickr8"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnuK-b4pPd1",
        "outputId": "6b45d005-5cbb-4dbe-b123-f986e602e001"
      },
      "source": [
        "batch_size = 64\n",
        "fine_tune_encoder = True\n",
        "checkpoint = '/content/BEST_checkpoint_flickr8k.pth.tar'\n",
        "# epochs = 30\n",
        "\n",
        "t_params['batch_size'] = batch_size\n",
        "t_params['data_name'] = t_params['data_name'] + \"_finetune\" \n",
        "t_params['fine_tune_encoder'] = True\n",
        "t_params['decoder_lr'] = t_params['decoder_lr'] / 10\n",
        "# t_params['epochs'] = epochs\n",
        "t_params"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'data_name': 'flickr8k_finetune',\n",
              " 'decoder_lr': 4e-05,\n",
              " 'df_path': 'Image-Captioning/data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': True,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f851678a590>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptOGGuc8pWY1",
        "outputId": "26933195-3019-4076-b394-26debe201fe6"
      },
      "source": [
        "fit(t_params, checkpoint=checkpoint, m_params=m_params, logger=logger)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Starting Epoch: 8\n",
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 30000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 5000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [8][0/469]\tBatch Time 4.394 (4.394)\tData Load Time 1.075 (1.075)\tLoss 3.9341 (3.9341)\tTop-5 Accuracy 65.668 (65.668)\n",
            "Epoch: [8][100/469]\tBatch Time 1.355 (1.366)\tData Load Time 0.001 (0.012)\tLoss 4.0626 (4.0607)\tTop-5 Accuracy 63.625 (63.763)\n",
            "Epoch: [8][200/469]\tBatch Time 1.341 (1.348)\tData Load Time 0.001 (0.007)\tLoss 4.0942 (4.0225)\tTop-5 Accuracy 64.295 (64.396)\n",
            "Epoch: [8][300/469]\tBatch Time 1.316 (1.341)\tData Load Time 0.002 (0.005)\tLoss 3.9342 (3.9926)\tTop-5 Accuracy 64.673 (64.900)\n",
            "Epoch: [8][400/469]\tBatch Time 1.315 (1.337)\tData Load Time 0.003 (0.004)\tLoss 3.8777 (3.9742)\tTop-5 Accuracy 65.847 (65.196)\n",
            "Epoch train time 627.633 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.560 (1.560)\tLoss 5.0039 (5.0039)\tTop-5 Accuracy 59.468 (59.468)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.23301406134856\n",
            "2: 42.47408427762649\n",
            "3: 25.16285785882184\n",
            "4: 14.916057098634305\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.018, TOP-5 ACCURACY - 59.748, BLEU-4 - 14.916057098634305\n",
            "\n",
            "Epoch validation time 50.588 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [9][0/469]\tBatch Time 2.329 (2.329)\tData Load Time 0.951 (0.951)\tLoss 3.7394 (3.7394)\tTop-5 Accuracy 68.428 (68.428)\n",
            "Epoch: [9][100/469]\tBatch Time 1.357 (1.340)\tData Load Time 0.001 (0.011)\tLoss 3.9807 (3.8516)\tTop-5 Accuracy 65.063 (67.060)\n",
            "Epoch: [9][200/469]\tBatch Time 1.313 (1.334)\tData Load Time 0.001 (0.006)\tLoss 3.8290 (3.8498)\tTop-5 Accuracy 65.642 (67.118)\n",
            "Epoch: [9][300/469]\tBatch Time 1.303 (1.331)\tData Load Time 0.001 (0.004)\tLoss 3.8501 (3.8521)\tTop-5 Accuracy 66.575 (67.170)\n",
            "Epoch: [9][400/469]\tBatch Time 1.326 (1.330)\tData Load Time 0.001 (0.004)\tLoss 3.7103 (3.8525)\tTop-5 Accuracy 67.417 (67.167)\n",
            "Epoch train time 623.200 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.540 (1.540)\tLoss 4.3999 (4.3999)\tTop-5 Accuracy 64.332 (64.332)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.44794920925365\n",
            "2: 42.79142229064723\n",
            "3: 25.803808191174948\n",
            "4: 15.557990983698245\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.038, TOP-5 ACCURACY - 59.878, BLEU-4 - 15.557990983698245\n",
            "\n",
            "Epoch validation time 49.972 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [10][0/469]\tBatch Time 2.370 (2.370)\tData Load Time 1.041 (1.041)\tLoss 3.8393 (3.8393)\tTop-5 Accuracy 67.524 (67.524)\n",
            "Epoch: [10][100/469]\tBatch Time 1.313 (1.341)\tData Load Time 0.003 (0.012)\tLoss 3.8622 (3.7873)\tTop-5 Accuracy 66.076 (68.161)\n",
            "Epoch: [10][200/469]\tBatch Time 1.318 (1.332)\tData Load Time 0.001 (0.006)\tLoss 3.6351 (3.7874)\tTop-5 Accuracy 71.625 (68.223)\n",
            "Epoch: [10][300/469]\tBatch Time 1.373 (1.330)\tData Load Time 0.006 (0.005)\tLoss 3.7065 (3.7953)\tTop-5 Accuracy 70.013 (68.115)\n",
            "Epoch: [10][400/469]\tBatch Time 1.315 (1.330)\tData Load Time 0.001 (0.004)\tLoss 3.7921 (3.7925)\tTop-5 Accuracy 67.364 (68.191)\n",
            "Epoch train time 623.719 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.553 (1.553)\tLoss 4.9405 (4.9405)\tTop-5 Accuracy 60.465 (60.465)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.57633233621682\n",
            "2: 43.07040628227546\n",
            "3: 25.806302988006614\n",
            "4: 15.509064058452694\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.027, TOP-5 ACCURACY - 59.845, BLEU-4 - 15.509064058452694\n",
            "\n",
            "Epoch validation time 50.918 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/469]\tBatch Time 2.486 (2.486)\tData Load Time 1.083 (1.083)\tLoss 3.6755 (3.6755)\tTop-5 Accuracy 69.841 (69.841)\n",
            "Epoch: [11][100/469]\tBatch Time 1.350 (1.340)\tData Load Time 0.001 (0.012)\tLoss 3.7382 (3.7234)\tTop-5 Accuracy 69.634 (69.314)\n",
            "Epoch: [11][200/469]\tBatch Time 1.359 (1.335)\tData Load Time 0.001 (0.006)\tLoss 3.6809 (3.7175)\tTop-5 Accuracy 70.302 (69.401)\n",
            "Epoch: [11][300/469]\tBatch Time 1.339 (1.333)\tData Load Time 0.001 (0.005)\tLoss 3.8142 (3.7247)\tTop-5 Accuracy 67.730 (69.263)\n",
            "Epoch: [11][400/469]\tBatch Time 1.339 (1.332)\tData Load Time 0.002 (0.004)\tLoss 3.8458 (3.7340)\tTop-5 Accuracy 66.711 (69.135)\n",
            "Epoch train time 624.106 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.577 (1.577)\tLoss 4.7524 (4.7524)\tTop-5 Accuracy 59.931 (59.931)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.29707306640692\n",
            "2: 42.61452959426138\n",
            "3: 25.449390571403104\n",
            "4: 15.122853067114454\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.045, TOP-5 ACCURACY - 59.853, BLEU-4 - 15.122853067114454\n",
            "\n",
            "Epoch validation time 51.405 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch     4: reducing learning rate of group 0 to 4.0000e-07.\n",
            "Epoch     4: reducing learning rate of group 0 to 1.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/469]\tBatch Time 2.406 (2.406)\tData Load Time 1.062 (1.062)\tLoss 3.7634 (3.7634)\tTop-5 Accuracy 68.057 (68.057)\n",
            "Epoch: [12][100/469]\tBatch Time 1.399 (1.342)\tData Load Time 0.001 (0.012)\tLoss 3.7365 (3.6744)\tTop-5 Accuracy 69.325 (70.085)\n",
            "Epoch: [12][200/469]\tBatch Time 1.312 (1.333)\tData Load Time 0.001 (0.006)\tLoss 3.4198 (3.6510)\tTop-5 Accuracy 74.163 (70.354)\n",
            "Epoch: [12][300/469]\tBatch Time 1.373 (1.332)\tData Load Time 0.002 (0.005)\tLoss 3.8541 (3.6540)\tTop-5 Accuracy 68.014 (70.342)\n",
            "Epoch: [12][400/469]\tBatch Time 1.332 (1.331)\tData Load Time 0.001 (0.004)\tLoss 3.7346 (3.6521)\tTop-5 Accuracy 69.075 (70.298)\n",
            "Epoch train time 623.383 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.506 (1.506)\tLoss 4.8771 (4.8771)\tTop-5 Accuracy 62.336 (62.336)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 67.20284011118902\n",
            "2: 43.71065688812782\n",
            "3: 26.46750064479076\n",
            "4: 15.97917426288958\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.030, TOP-5 ACCURACY - 60.197, BLEU-4 - 15.97917426288958\n",
            "\n",
            "Epoch validation time 50.154 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [13][0/469]\tBatch Time 2.300 (2.300)\tData Load Time 0.954 (0.954)\tLoss 3.7988 (3.7988)\tTop-5 Accuracy 69.947 (69.947)\n",
            "Epoch: [13][100/469]\tBatch Time 1.295 (1.340)\tData Load Time 0.001 (0.011)\tLoss 3.5134 (3.6146)\tTop-5 Accuracy 72.269 (70.937)\n",
            "Epoch: [13][200/469]\tBatch Time 1.332 (1.333)\tData Load Time 0.001 (0.006)\tLoss 3.5739 (3.6181)\tTop-5 Accuracy 71.247 (70.923)\n",
            "Epoch: [13][300/469]\tBatch Time 1.289 (1.332)\tData Load Time 0.001 (0.004)\tLoss 3.5923 (3.6173)\tTop-5 Accuracy 71.915 (70.930)\n",
            "Epoch: [13][400/469]\tBatch Time 1.356 (1.331)\tData Load Time 0.003 (0.004)\tLoss 3.6312 (3.6161)\tTop-5 Accuracy 71.447 (70.984)\n",
            "Epoch train time 623.662 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.529 (1.529)\tLoss 5.0293 (5.0293)\tTop-5 Accuracy 60.611 (60.611)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.88797347630371\n",
            "2: 43.418003853965985\n",
            "3: 26.223370353074465\n",
            "4: 15.773598232159818\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.032, TOP-5 ACCURACY - 60.162, BLEU-4 - 15.773598232159818\n",
            "\n",
            "Epoch validation time 50.144 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [14][0/469]\tBatch Time 2.391 (2.391)\tData Load Time 0.991 (0.991)\tLoss 3.7027 (3.7027)\tTop-5 Accuracy 69.053 (69.053)\n",
            "Epoch: [14][100/469]\tBatch Time 1.321 (1.338)\tData Load Time 0.001 (0.011)\tLoss 3.4813 (3.5927)\tTop-5 Accuracy 74.652 (71.170)\n",
            "Epoch: [14][200/469]\tBatch Time 1.291 (1.333)\tData Load Time 0.002 (0.006)\tLoss 3.5093 (3.5976)\tTop-5 Accuracy 72.276 (71.129)\n",
            "Epoch: [14][300/469]\tBatch Time 1.313 (1.332)\tData Load Time 0.001 (0.004)\tLoss 3.5434 (3.5931)\tTop-5 Accuracy 72.164 (71.216)\n",
            "Epoch: [14][400/469]\tBatch Time 1.320 (1.331)\tData Load Time 0.001 (0.004)\tLoss 3.5559 (3.5961)\tTop-5 Accuracy 71.447 (71.185)\n",
            "Epoch train time 623.500 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.545 (1.545)\tLoss 4.9935 (4.9935)\tTop-5 Accuracy 61.785 (61.785)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.845120175261\n",
            "2: 43.35242912935408\n",
            "3: 26.265218876600677\n",
            "4: 15.83176889275867\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.034, TOP-5 ACCURACY - 60.138, BLEU-4 - 15.83176889275867\n",
            "\n",
            "Epoch validation time 51.006 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch     7: reducing learning rate of group 0 to 4.0000e-08.\n",
            "Epoch     7: reducing learning rate of group 0 to 1.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/469]\tBatch Time 2.343 (2.343)\tData Load Time 1.022 (1.022)\tLoss 3.5722 (3.5722)\tTop-5 Accuracy 70.756 (70.756)\n",
            "Epoch: [15][100/469]\tBatch Time 1.301 (1.337)\tData Load Time 0.003 (0.011)\tLoss 3.6060 (3.5715)\tTop-5 Accuracy 69.068 (71.454)\n",
            "Epoch: [15][200/469]\tBatch Time 1.317 (1.332)\tData Load Time 0.001 (0.006)\tLoss 3.6625 (3.5823)\tTop-5 Accuracy 69.922 (71.372)\n",
            "Epoch: [15][300/469]\tBatch Time 1.337 (1.331)\tData Load Time 0.001 (0.005)\tLoss 3.3948 (3.5765)\tTop-5 Accuracy 75.000 (71.455)\n",
            "Epoch: [15][400/469]\tBatch Time 1.342 (1.330)\tData Load Time 0.001 (0.004)\tLoss 3.4821 (3.5773)\tTop-5 Accuracy 73.333 (71.452)\n",
            "Epoch train time 622.960 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.473 (1.473)\tLoss 4.7883 (4.7883)\tTop-5 Accuracy 62.827 (62.827)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.85442738956179\n",
            "2: 43.34370098823459\n",
            "3: 26.206316228989092\n",
            "4: 15.817692089086691\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.037, TOP-5 ACCURACY - 60.151, BLEU-4 - 15.817692089086691\n",
            "\n",
            "Epoch validation time 49.740 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [16][0/469]\tBatch Time 2.354 (2.354)\tData Load Time 1.003 (1.003)\tLoss 3.5677 (3.5677)\tTop-5 Accuracy 70.904 (70.904)\n",
            "Epoch: [16][100/469]\tBatch Time 1.315 (1.342)\tData Load Time 0.001 (0.011)\tLoss 3.4816 (3.5741)\tTop-5 Accuracy 72.585 (71.415)\n",
            "Epoch: [16][200/469]\tBatch Time 1.345 (1.331)\tData Load Time 0.001 (0.006)\tLoss 3.4902 (3.5701)\tTop-5 Accuracy 72.902 (71.540)\n",
            "Epoch: [16][300/469]\tBatch Time 1.328 (1.330)\tData Load Time 0.003 (0.004)\tLoss 3.5857 (3.5749)\tTop-5 Accuracy 72.133 (71.514)\n",
            "Epoch: [16][400/469]\tBatch Time 1.284 (1.329)\tData Load Time 0.001 (0.004)\tLoss 3.5836 (3.5762)\tTop-5 Accuracy 71.004 (71.481)\n",
            "Epoch train time 622.547 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.530 (1.530)\tLoss 5.2973 (5.2973)\tTop-5 Accuracy 56.221 (56.221)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.89320986479596\n",
            "2: 43.383729444067335\n",
            "3: 26.267804429612944\n",
            "4: 15.846892240119107\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.038, TOP-5 ACCURACY - 60.105, BLEU-4 - 15.846892240119107\n",
            "\n",
            "Epoch validation time 49.936 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [17][0/469]\tBatch Time 2.401 (2.401)\tData Load Time 1.026 (1.026)\tLoss 3.7200 (3.7200)\tTop-5 Accuracy 69.279 (69.279)\n",
            "Epoch: [17][100/469]\tBatch Time 1.341 (1.339)\tData Load Time 0.001 (0.011)\tLoss 3.6624 (3.5731)\tTop-5 Accuracy 71.013 (71.513)\n",
            "Epoch: [17][200/469]\tBatch Time 1.340 (1.331)\tData Load Time 0.001 (0.006)\tLoss 3.6621 (3.5640)\tTop-5 Accuracy 68.381 (71.617)\n",
            "Epoch: [17][300/469]\tBatch Time 1.317 (1.328)\tData Load Time 0.001 (0.005)\tLoss 3.5844 (3.5674)\tTop-5 Accuracy 71.126 (71.556)\n",
            "Epoch: [17][400/469]\tBatch Time 1.338 (1.328)\tData Load Time 0.003 (0.004)\tLoss 3.4798 (3.5685)\tTop-5 Accuracy 73.052 (71.555)\n",
            "Epoch train time 622.644 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/79]\tBatch Time 1.541 (1.541)\tLoss 5.4032 (5.4032)\tTop-5 Accuracy 57.095 (57.095)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 66.89597706231332\n",
            "2: 43.395337889329895\n",
            "3: 26.261893595490577\n",
            "4: 15.885416575783124\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.038, TOP-5 ACCURACY - 60.101, BLEU-4 - 15.885416575783124\n",
            "\n",
            "Epoch validation time 50.404 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKFBHm66Guzh"
      },
      "source": [
        "!cp BEST_checkpoint_flickr8k_finetune.pth.tar /content/drive/MyDrive/ImageCaptioning/flickr8 "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccZ5fIHKG_is",
        "outputId": "f9166aeb-e227-49ee-c3da-8eecd6d9c737"
      },
      "source": [
        "checkpoint = load_checkpoint(\"BEST_checkpoint_flickr8k_finetune.pth.tar\")\n",
        "decoder = checkpoint['decoder']\n",
        "decoder = decoder.to(device)\n",
        "decoder.eval()\n",
        "encoder = checkpoint['encoder']\n",
        "encoder = encoder.to(device)\n",
        "encoder.eval();"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 12\n",
            "Best Bleu-4: 15.97917426288958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mry15OR5HFrL",
        "outputId": "a96c894e-db9c-4b58-cffc-5cf3d30c260b"
      },
      "source": [
        "from eval import test_score\n",
        "\n",
        "test_dict = {}\n",
        "\n",
        "for i in [1, 3, 5]:\n",
        "    \n",
        "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)\n",
        "    if i == 3:\n",
        "        test_dict['b1'] = b1\n",
        "        test_dict['b2'] = b2\n",
        "        test_dict['b3'] = b3\n",
        "    \n",
        "    test_dict[f'b4-b{i}'] = b4"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 1:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "EVALUATING AT BEAM SIZE 1: 100%|██████████| 5000/5000 [02:50<00:00, 29.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 60.22812266267764\n",
            "2: 43.382614808552674\n",
            "3: 29.616014800242358\n",
            "4: 19.937961468711514\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 3:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 3: 100%|██████████| 5000/5000 [03:13<00:00, 25.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 64.08114558472555\n",
            "2: 46.50725094600124\n",
            "3: 32.63582641164054\n",
            "4: 22.48417748427286\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 5:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 5: 100%|██████████| 5000/5000 [03:40<00:00, 22.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 65.32056619483764\n",
            "2: 47.5853480841862\n",
            "3: 33.54273081013491\n",
            "4: 23.093440505233385\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}