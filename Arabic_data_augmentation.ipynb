{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Arabic - data augmentation",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AmLihjzYLns",
        "outputId": "d08517fc-272b-48de-8418-90ee962cb4e4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "7AmLihjzYLns",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  1 15:29:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlaI1FrTYRx2",
        "outputId": "c5c0a55e-0283-4dee-bf4e-beed14f7ea8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "LlaI1FrTYRx2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujXdcntcYVtb"
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "id": "ujXdcntcYVtb",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJjId046YcBy",
        "outputId": "61983126-dc00-43b7-ffb7-eaaee29a8f69"
      },
      "source": [
        "!pip install kaggle -q\n",
        "!kaggle datasets download -d aladdinpersson/flickr8kimagescaptions\n",
        "!unzip -q flickr8kimagescaptions.zip"
      ],
      "id": "IJjId046YcBy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickr8kimagescaptions.zip to /content\n",
            "100% 1.04G/1.04G [00:26<00:00, 60.7MB/s]\n",
            "100% 1.04G/1.04G [00:26<00:00, 41.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCxFJ5wQYehR",
        "outputId": "50fedb11-82c5-404d-8ab9-c5aa93766a6b"
      },
      "source": [
        "# get the code form github\n",
        "!git clone https://github.com/moaaztaha/Image-Captioning\n",
        "py_files_path = 'Image-Captioning/'\n",
        "import sys\n",
        "sys.path.append(py_files_path)"
      ],
      "id": "vCxFJ5wQYehR",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image-Captioning'...\n",
            "remote: Enumerating objects: 611, done.\u001b[K\n",
            "remote: Counting objects: 100% (611/611), done.\u001b[K\n",
            "remote: Compressing objects: 100% (293/293), done.\u001b[K\n",
            "remote: Total 611 (delta 367), reused 551 (delta 307), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (611/611), 38.47 MiB | 18.04 MiB/s, done.\n",
            "Resolving deltas: 100% (367/367), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4366e4d"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "id": "b4366e4d",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4034c69e"
      },
      "source": [
        "import time \n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from models import Encoder, DecoderWithAttention\n",
        "from dataset import *\n",
        "from utils import *\n",
        "from train import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from os import path as osp"
      ],
      "id": "4034c69e",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ce76f9"
      },
      "source": [
        "# Model parameters\n",
        "encoder_dim = 2048 # resnet101\n",
        "emb_dim = 512  # dimension of word embeddings\n",
        "attention_dim = 512  # dimension of attention linear layers\n",
        "decoder_dim = 512  # dimension of decoder RNN\n",
        "dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
        "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
        "\n",
        "# training parameters\n",
        "epochs = 30  # number of epochs to train for (if early stopping is not triggered)\n",
        "batch_size = 256\n",
        "workers = 2\n",
        "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
        "decoder_lr = 4e-4  # learning rate for decoder\n",
        "fine_tune_encoder = False  # fine-tune encoder?\n",
        "pretrained_embeddings = False\n",
        "fine_tune_embeddings = False\n",
        "checkpoint = None  # path to checkpoint, None if none\n"
      ],
      "id": "b8ce76f9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7a302e3"
      },
      "source": [
        "DATA_NAME = 'flickr8k_ar_aug'\n",
        "\n",
        "# local\n",
        "# DATA_JSON_PATH = 'ar_data.json'\n",
        "# IMGS_PATH = 'flickr/Images/'\n",
        "# kaggle paths\n",
        "# DATA_JSON_PATH = '/kaggle/working/Image-Captioning/data.json'\n",
        "# IMGS_PATH = '../input/flickr8kimagescaptions/flickr8k/images/'\n",
        "#colab\n",
        "DATA_JSON_PATH = 'Image-Captioning/ar_data.json'\n",
        "IMGS_PATH = 'flickr8k/images/'"
      ],
      "id": "d7a302e3",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b1a677",
        "outputId": "06ee5bb6-465a-474c-f722-e6ae8f2b080d"
      },
      "source": [
        "max_seq = 30\n",
        "vocab = build_vocab(DATA_JSON_PATH, max_seq=max_seq)\n",
        "vocab_len = len(vocab); vocab_len"
      ],
      "id": "a4b1a677",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24000/24000 [00:00<00:00, 283147.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6df2d0",
        "outputId": "df384b9b-9e11-4a6d-b152-c1daa11609fd"
      },
      "source": [
        "list(vocab.itos.keys())[:10], list(vocab.itos.values())[:10]"
      ],
      "id": "ff6df2d0",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
              " ['<pad>',\n",
              "  '<sos>',\n",
              "  '<eos>',\n",
              "  '<unk>',\n",
              "  'طفلة',\n",
              "  'صغيرة',\n",
              "  'تتسلق',\n",
              "  'إلى',\n",
              "  'كلب',\n",
              "  'أسود'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fb11e8e"
      },
      "source": [
        "t_params = {\n",
        "    'data_name': DATA_NAME,\n",
        "    'imgs_path': IMGS_PATH,\n",
        "    'df_path': DATA_JSON_PATH,\n",
        "    'vocab': vocab,\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'workers': workers,\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "}\n",
        "\n",
        "m_params = {\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim,\n",
        "    'dropout': dropout\n",
        "}\n",
        "\n",
        "logger_dic = {\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "    'max_seq_length': max_seq,\n",
        "    'vocab_size': vocab_len,\n",
        "    'enocder': 'resnet101',\n",
        "    'dropout': dropout,\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim \n",
        "    \n",
        "}"
      ],
      "id": "6fb11e8e",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97209564",
        "outputId": "01c19fb6-4ac3-4af8-ea6f-608269fcb6b1"
      },
      "source": [
        "t_params"
      ],
      "id": "97209564",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 256,\n",
              " 'data_name': 'flickr8k_ar',\n",
              " 'decoder_lr': 0.0004,\n",
              " 'df_path': 'Image-Captioning/ar_data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': False,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f730290b510>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d8e8ebf"
      },
      "source": [
        "# experiment name\n",
        "name = DATA_NAME + \"_data_augmentation\"\n",
        "# path\n",
        "log_dir = '/content/drive/MyDrive/ImageCaptioning/flickr8_ar/experiments'\n",
        "\n",
        "logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
      ],
      "id": "8d8e8ebf",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJAvh4vN4vEf"
      },
      "source": [
        "def get_loaders(bs, images_path, df_path, transform, vocab, test=False, n_workers=0):\n",
        "    #pad_idx = vocab.stoi['<pad>']\n",
        "\n",
        "    if test:\n",
        "        test_loader = DataLoader(\n",
        "            dataset=CaptionDataset(images_path, df_path,\n",
        "                                    transforms=transform, vocab=vocab, split='test'),\n",
        "            batch_size=bs,\n",
        "            num_workers=n_workers,\n",
        "            shuffle=True,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ColorJitter(.4,.4,.4),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ])\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=CaptionDataset(images_path, df_path,\n",
        "                              transforms=train_transforms, vocab=vocab, split='train'),\n",
        "        batch_size=bs,\n",
        "        num_workers=n_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        dataset=CaptionDataset(images_path, df_path,\n",
        "                              transforms=transform, vocab=vocab, split='val'),\n",
        "        batch_size=bs,\n",
        "        num_workers=n_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "id": "DJAvh4vN4vEf",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4rDbbxErixI"
      },
      "source": [
        "def fit(t_params, checkpoint=None, m_params=None, logger=None):\n",
        "\n",
        "    # info\n",
        "    data_name = t_params['data_name']\n",
        "    imgs_path = t_params['imgs_path']\n",
        "    df_path = t_params['df_path']\n",
        "    vocab = t_params['vocab']\n",
        "\n",
        "    start_epoch = 0\n",
        "    epochs_since_improvement = 0\n",
        "    best_bleu4 = 0\n",
        "    epochs = t_params['epochs']\n",
        "    batch_size = t_params['batch_size']\n",
        "    workers = t_params['workers']\n",
        "    encoder_lr = t_params['encoder_lr']\n",
        "    decoder_lr = t_params['decoder_lr']\n",
        "    fine_tune_encoder = t_params['fine_tune_encoder']\n",
        "\n",
        "    # pretrained word embeddings\n",
        "    pretrained_embeddings = t_params['pretrained_embeddings']\n",
        "    if pretrained_embeddings:\n",
        "        fine_tune_embeddings = t_params['fine_tune_embeddings']\n",
        "        embeddings_matrix = m_params['embeddings_matrix']\n",
        "\n",
        "\n",
        "\n",
        "    # init / load checkpoint\n",
        "    if checkpoint is None:\n",
        "\n",
        "        # getting hyperparameters\n",
        "        attention_dim = m_params['attention_dim']\n",
        "        embed_dim = m_params['embed_dim']\n",
        "        decoder_dim = m_params['decoder_dim']\n",
        "        encoder_dim = m_params['encoder_dim']\n",
        "        dropout = m_params['dropout']\n",
        "\n",
        "        decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
        "                                      embed_dim=embed_dim,\n",
        "                                      decoder_dim=decoder_dim,\n",
        "                                      encoder_dim=encoder_dim,\n",
        "                                      vocab_size=len(vocab),\n",
        "                                      dropout=dropout)\n",
        "        \n",
        "        if pretrained_embeddings:\n",
        "            decoder.load_pretrained_embeddings(torch.tensor(embeddings_matrix, dtype=torch.float32))\n",
        "            decoder.fine_tune_embeddings(fine_tune=fine_tune_embeddings)\n",
        "        \n",
        "        decoder_optimizer = torch.optim.RMSprop(params=filter(lambda p:p.requires_grad, decoder.parameters()),\n",
        "                                            lr=decoder_lr)\n",
        "        \n",
        "\n",
        "\n",
        "        encoder=Encoder()\n",
        "        encoder.fine_tune(fine_tune_encoder)\n",
        "        encoder_optimizer = torch.optim.RMSprop(params=filter(lambda p:p.requires_grad, encoder.parameters()),\n",
        "                                            lr=encoder_lr) if fine_tune_encoder else None\n",
        "\n",
        "        \n",
        "    # load checkpoint\n",
        "    else:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        print('Loaded Checkpoint!!')\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f\"Starting Epoch: {start_epoch}\")\n",
        "        epochs_since_improvement = checkpoint['epochs_since_imrovment']\n",
        "        best_bleu4 = checkpoint['bleu-4']\n",
        "        decoder = checkpoint['decoder']\n",
        "        decoder_optimizer = checkpoint['deocder_optimizer']\n",
        "        encoder = checkpoint['encoder']\n",
        "        encoder_optimizer = checkpoint['encoder_optimizer']\n",
        "        if fine_tune_encoder is True and encoder_optimizer is None:\n",
        "            encoder.fine_tune(fine_tune_encoder)\n",
        "            encoder_optimizer = torch.optim.RMSprop(params=filter(lambda p:p.requires_grad, encoder.parameters()),\n",
        "                                                lr=encoder_lr)\n",
        "    \n",
        "    # Schedulers\n",
        "    decoder_scheduler = ReduceLROnPlateau(decoder_optimizer, patience=2, verbose=True)\n",
        "    if fine_tune_encoder:\n",
        "        encoder_scheduler = ReduceLROnPlateau(encoder_optimizer, patience=2, verbose=True)\n",
        "\n",
        "\n",
        "    # move to gpu, if available\n",
        "    decoder = decoder.to(device)\n",
        "    encoder = encoder.to(device)\n",
        "    \n",
        "    # loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    \n",
        "    # dataloaders\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    print('Loading Data')\n",
        "    train_loader, val_loader = get_loaders(batch_size, imgs_path, df_path, transform, vocab, False ,workers)\n",
        "    print('_'*50)\n",
        "\n",
        "    print('-'*20, 'Fitting', '-'*20)\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "\n",
        "        # if epochs_since_improvement > 0 and epochs_since_improvement % 2 == 0:\n",
        "        #     adjust_learning_rate(decoder_optimizer, 0.8)\n",
        "        #     if fine_tune_encoder:\n",
        "        #         adjust_learning_rate(encoder_optimizer, 0.8)\n",
        "        \n",
        "        print('_'*50)\n",
        "        print('-'*20, 'Training', '-'*20)\n",
        "        # one epoch of training\n",
        "        epoch_time = AverageMeter()\n",
        "        start_time = time.time()\n",
        "        train(train_loader=train_loader,\n",
        "            encoder=encoder,\n",
        "            decoder=decoder,\n",
        "            criterion=criterion,\n",
        "            encoder_optimizer=encoder_optimizer,\n",
        "            decoder_optimizer=decoder_optimizer,\n",
        "            epoch=epoch,\n",
        "            logger=logger)\n",
        "        epoch_time.update(time.time() - start_time)\n",
        "        print(f\"Epoch train time {epoch_time.val:.3f} (epoch_time.avg:.3f)\")\n",
        "\n",
        "        # one epoch of validation\n",
        "        epoch_time = AverageMeter()\n",
        "        start_time = time.time()\n",
        "        print('-'*20, 'Validation', '-'*20)\n",
        "        b1, b2, b3, recent_bleu4 = validate(val_loader=val_loader,\n",
        "            encoder=encoder,\n",
        "            decoder=decoder,\n",
        "            criterion=criterion,\n",
        "            vocab=vocab,\n",
        "            epoch=epoch,\n",
        "            logger=logger)\n",
        "        epoch_time.update(time.time() - start_time)\n",
        "        # tensorboard \n",
        "        logger.add_scalar(f'b-1/valid', b1, epoch)\n",
        "        logger.add_scalar(f'b-2/valid', b2, epoch)\n",
        "        logger.add_scalar(f'b-3/valid', b3, epoch)\n",
        "        logger.add_scalar(f'b-4/valid', recent_bleu4, epoch)\n",
        "        # logger.add_scalar(f'Meteor/valid', m, epoch)\n",
        "        print(f\"Epoch validation time {epoch_time.val:.3f} (epoch_time.avg:.3f)\")\n",
        "\n",
        "        \n",
        "        # check for improvement\n",
        "        is_best = recent_bleu4 > best_bleu4\n",
        "        best_bleu4 = max(recent_bleu4, best_bleu4)\n",
        "        if not is_best:\n",
        "            epochs_since_improvement += 1\n",
        "            print(f'\\nEpochs since last improvement: {epochs_since_improvement,}')\n",
        "        else:\n",
        "            # reset\n",
        "            epochs_since_improvement = 0\n",
        "        \n",
        "\n",
        "        # stop training if no improvement for 5 epochs\n",
        "        if epochs_since_improvement == 5:\n",
        "            print('No improvement for 5 consecutive epochs, terminating...')\n",
        "            break\n",
        "        \n",
        "        # learning rate schedular\n",
        "        decoder_scheduler.step(recent_bleu4)\n",
        "        if fine_tune_encoder:\n",
        "            encoder_scheduler.step(recent_bleu4)\n",
        "\n",
        "        save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
        "            decoder_optimizer, recent_bleu4, is_best)"
      ],
      "id": "x4rDbbxErixI",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DIOlt7gxZAbd",
        "outputId": "bfd9d0a6-0e62-45e3-8f30-e4e73d919d53"
      },
      "source": [
        "fit(t_params=t_params, m_params=m_params, logger=logger)"
      ],
      "id": "DIOlt7gxZAbd",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 18000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 3000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [0][0/71]\tBatch Time 9.397 (9.397)\tData Load Time 4.751 (4.751)\tLoss 9.5748 (9.5748)\tTop-5 Accuracy 0.046 (0.046)\n",
            "Epoch train time 318.961 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 8.024 (8.024)\tLoss 6.6170 (6.6170)\tTop-5 Accuracy 34.222 (34.222)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 35.848565748702256\n",
            "2: 15.35303305671232\n",
            "3: 5.461182625395057\n",
            "4: 2.1937256568031542\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 6.443, TOP-5 ACCURACY - 35.963, BLEU-4 - 2.1937256568031542\n",
            "\n",
            "Epoch validation time 47.199 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [1][0/71]\tBatch Time 9.337 (9.337)\tData Load Time 4.625 (4.625)\tLoss 6.0081 (6.0081)\tTop-5 Accuracy 39.552 (39.552)\n",
            "Epoch train time 318.933 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 8.291 (8.291)\tLoss 5.9445 (5.9445)\tTop-5 Accuracy 42.822 (42.822)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 38.1022837400469\n",
            "2: 17.5658502813152\n",
            "3: 7.770671628274699\n",
            "4: 3.159178067810226\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 6.063, TOP-5 ACCURACY - 41.291, BLEU-4 - 3.159178067810226\n",
            "\n",
            "Epoch validation time 46.867 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [2][0/71]\tBatch Time 9.595 (9.595)\tData Load Time 4.969 (4.969)\tLoss 5.4395 (5.4395)\tTop-5 Accuracy 47.897 (47.897)\n",
            "Epoch train time 318.955 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 8.259 (8.259)\tLoss 5.9579 (5.9579)\tTop-5 Accuracy 43.317 (43.317)\t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8017a40ca13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-30673d40e991>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(t_params, checkpoint, m_params, logger)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             logger=logger)\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mepoch_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Image-Captioning/train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, encoder, decoder, criterion, vocab, epoch, logger)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaplens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaps_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Image-Captioning/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_out, encoded_captions, captions_lengths)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch size, decoder dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mdecode_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcaption_lengths\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgtlSQWzjNwz",
        "outputId": "9df0886b-4b65-4a7b-d4bc-36b41f0c9e49"
      },
      "source": [
        "m = load_checkpoint(\"/content/BEST_checkpoint_flickr8k_ar.pth.tar\")"
      ],
      "id": "cgtlSQWzjNwz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 8\n",
            "Best Bleu-4: 5.715176451490768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJAelDR8ZDsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2481356c-e943-460c-b469-81ebd04b8d0d"
      },
      "source": [
        "batch_size = 64\n",
        "fine_tune_encoder = True\n",
        "checkpoint = '/content/BEST_checkpoint_flickr8k_ar.pth.tar'\n",
        "# epochs = 30\n",
        "\n",
        "t_params['batch_size'] = batch_size\n",
        "t_params['data_name'] = t_params['data_name'] + \"_finetune\" \n",
        "t_params['fine_tune_encoder'] = True\n",
        "t_params['decoder_lr'] = t_params['decoder_lr'] / 10\n",
        "# t_params['epochs'] = epochs\n",
        "t_params"
      ],
      "id": "NJAelDR8ZDsk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'data_name': 'flickr8k_ar_finetune',\n",
              " 'decoder_lr': 4e-05,\n",
              " 'df_path': 'Image-Captioning/ar_data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_encoder': True,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': False,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f7e18aaefd0>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYhbvtifjXD6",
        "outputId": "f9b64c2c-6000-4397-f0ec-a2bea5317a28"
      },
      "source": [
        "fit(t_params, checkpoint=checkpoint, m_params=m_params, logger=logger)"
      ],
      "id": "uYhbvtifjXD6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Starting Epoch: 9\n",
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 18000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 3000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [9][0/282]\tBatch Time 4.199 (4.199)\tData Load Time 0.960 (0.960)\tLoss 4.9865 (4.9865)\tTop-5 Accuracy 52.319 (52.319)\n",
            "Epoch: [9][100/282]\tBatch Time 1.235 (1.233)\tData Load Time 0.001 (0.010)\tLoss 5.1665 (4.9120)\tTop-5 Accuracy 49.912 (52.423)\n",
            "Epoch: [9][200/282]\tBatch Time 1.229 (1.217)\tData Load Time 0.001 (0.006)\tLoss 4.8351 (4.8706)\tTop-5 Accuracy 53.012 (53.206)\n",
            "Epoch train time 341.644 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.474 (1.474)\tLoss 5.5957 (5.5957)\tTop-5 Accuracy 45.269 (45.269)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 43.30506294300831\n",
            "2: 22.758277354606076\n",
            "3: 11.500573254391245\n",
            "4: 5.944498679194787\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.673, TOP-5 ACCURACY - 48.142, BLEU-4 - 5.944498679194787\n",
            "\n",
            "Epoch validation time 28.506 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [10][0/282]\tBatch Time 2.223 (2.223)\tData Load Time 0.964 (0.964)\tLoss 4.7377 (4.7377)\tTop-5 Accuracy 55.979 (55.979)\n",
            "Epoch: [10][100/282]\tBatch Time 1.182 (1.211)\tData Load Time 0.001 (0.011)\tLoss 4.8153 (4.7155)\tTop-5 Accuracy 54.887 (55.573)\n",
            "Epoch: [10][200/282]\tBatch Time 1.220 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.5277 (4.7151)\tTop-5 Accuracy 56.618 (55.515)\n",
            "Epoch train time 337.989 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.491 (1.491)\tLoss 5.6328 (5.6328)\tTop-5 Accuracy 51.889 (51.889)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 43.93385127480546\n",
            "2: 23.30900328578608\n",
            "3: 12.065313535030805\n",
            "4: 6.548837359956475\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.659, TOP-5 ACCURACY - 48.742, BLEU-4 - 6.548837359956475\n",
            "\n",
            "Epoch validation time 27.744 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/282]\tBatch Time 2.156 (2.156)\tData Load Time 0.914 (0.914)\tLoss 4.5571 (4.5571)\tTop-5 Accuracy 56.283 (56.283)\n",
            "Epoch: [11][100/282]\tBatch Time 1.191 (1.211)\tData Load Time 0.001 (0.010)\tLoss 4.4649 (4.6241)\tTop-5 Accuracy 58.382 (57.004)\n",
            "Epoch: [11][200/282]\tBatch Time 1.198 (1.204)\tData Load Time 0.002 (0.006)\tLoss 4.8600 (4.6273)\tTop-5 Accuracy 56.425 (56.936)\n",
            "Epoch train time 338.219 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.420 (1.420)\tLoss 5.7171 (5.7171)\tTop-5 Accuracy 46.959 (46.959)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 43.95227377709844\n",
            "2: 23.501618430063786\n",
            "3: 12.150551788760072\n",
            "4: 6.279030731015584\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.680, TOP-5 ACCURACY - 48.560, BLEU-4 - 6.279030731015584\n",
            "\n",
            "Epoch validation time 27.724 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/282]\tBatch Time 2.217 (2.217)\tData Load Time 0.989 (0.989)\tLoss 4.5592 (4.5592)\tTop-5 Accuracy 58.835 (58.835)\n",
            "Epoch: [12][100/282]\tBatch Time 1.190 (1.210)\tData Load Time 0.006 (0.011)\tLoss 4.6393 (4.5495)\tTop-5 Accuracy 57.864 (58.024)\n",
            "Epoch: [12][200/282]\tBatch Time 1.181 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.6528 (4.5691)\tTop-5 Accuracy 56.309 (57.740)\n",
            "Epoch train time 337.672 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.437 (1.437)\tLoss 5.5651 (5.5651)\tTop-5 Accuracy 50.118 (50.118)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.09576613691824\n",
            "2: 23.527054543897506\n",
            "3: 12.071378734897028\n",
            "4: 5.993335447047885\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.665, TOP-5 ACCURACY - 48.815, BLEU-4 - 5.993335447047885\n",
            "\n",
            "Epoch validation time 27.588 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch     4: reducing learning rate of group 0 to 4.0000e-07.\n",
            "Epoch     4: reducing learning rate of group 0 to 1.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [13][0/282]\tBatch Time 2.217 (2.217)\tData Load Time 0.953 (0.953)\tLoss 4.4901 (4.4901)\tTop-5 Accuracy 58.696 (58.696)\n",
            "Epoch: [13][100/282]\tBatch Time 1.202 (1.207)\tData Load Time 0.004 (0.010)\tLoss 4.5141 (4.4567)\tTop-5 Accuracy 56.401 (59.407)\n",
            "Epoch: [13][200/282]\tBatch Time 1.195 (1.204)\tData Load Time 0.001 (0.006)\tLoss 4.4724 (4.4538)\tTop-5 Accuracy 59.083 (59.486)\n",
            "Epoch train time 338.298 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.427 (1.427)\tLoss 5.9123 (5.9123)\tTop-5 Accuracy 45.926 (45.926)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.84804603022567\n",
            "2: 24.209545682634737\n",
            "3: 12.527182122463854\n",
            "4: 6.565714423841207\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.643, TOP-5 ACCURACY - 49.301, BLEU-4 - 6.565714423841207\n",
            "\n",
            "Epoch validation time 27.916 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [14][0/282]\tBatch Time 2.246 (2.246)\tData Load Time 0.970 (0.970)\tLoss 4.6406 (4.6406)\tTop-5 Accuracy 57.241 (57.241)\n",
            "Epoch: [14][100/282]\tBatch Time 1.194 (1.207)\tData Load Time 0.001 (0.011)\tLoss 4.6145 (4.4401)\tTop-5 Accuracy 58.712 (59.606)\n",
            "Epoch: [14][200/282]\tBatch Time 1.184 (1.204)\tData Load Time 0.001 (0.006)\tLoss 4.1887 (4.4163)\tTop-5 Accuracy 62.823 (59.974)\n",
            "Epoch train time 338.339 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.426 (1.426)\tLoss 5.6393 (5.6393)\tTop-5 Accuracy 48.434 (48.434)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.868307290612115\n",
            "2: 24.22371406264588\n",
            "3: 12.60321181580523\n",
            "4: 6.539334600451053\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.646, TOP-5 ACCURACY - 49.134, BLEU-4 - 6.539334600451053\n",
            "\n",
            "Epoch validation time 27.976 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/282]\tBatch Time 2.180 (2.180)\tData Load Time 0.930 (0.930)\tLoss 4.4729 (4.4729)\tTop-5 Accuracy 60.662 (60.662)\n",
            "Epoch: [15][100/282]\tBatch Time 1.186 (1.210)\tData Load Time 0.003 (0.010)\tLoss 4.2848 (4.4001)\tTop-5 Accuracy 61.100 (60.474)\n",
            "Epoch: [15][200/282]\tBatch Time 1.217 (1.204)\tData Load Time 0.001 (0.006)\tLoss 4.4612 (4.3946)\tTop-5 Accuracy 57.741 (60.527)\n",
            "Epoch train time 337.991 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.448 (1.448)\tLoss 5.4057 (5.4057)\tTop-5 Accuracy 50.860 (50.860)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.895994388100526\n",
            "2: 24.276251003102484\n",
            "3: 12.727723367045407\n",
            "4: 6.835326770837444\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.647, TOP-5 ACCURACY - 49.191, BLEU-4 - 6.835326770837444\n",
            "\n",
            "Epoch validation time 27.812 (epoch_time.avg:.3f)\n",
            "Epoch     7: reducing learning rate of group 0 to 4.0000e-08.\n",
            "Epoch     7: reducing learning rate of group 0 to 1.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [16][0/282]\tBatch Time 2.157 (2.157)\tData Load Time 0.944 (0.944)\tLoss 4.4307 (4.4307)\tTop-5 Accuracy 59.363 (59.363)\n",
            "Epoch: [16][100/282]\tBatch Time 1.188 (1.209)\tData Load Time 0.001 (0.010)\tLoss 4.1747 (4.3831)\tTop-5 Accuracy 62.477 (60.415)\n",
            "Epoch: [16][200/282]\tBatch Time 1.234 (1.204)\tData Load Time 0.001 (0.006)\tLoss 4.2995 (4.3711)\tTop-5 Accuracy 61.765 (60.646)\n",
            "Epoch train time 338.134 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.458 (1.458)\tLoss 5.8836 (5.8836)\tTop-5 Accuracy 46.959 (46.959)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.768914522064826\n",
            "2: 24.127058174169225\n",
            "3: 12.64113774552623\n",
            "4: 6.7471346786492665\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.650, TOP-5 ACCURACY - 49.149, BLEU-4 - 6.7471346786492665\n",
            "\n",
            "Epoch validation time 27.353 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [17][0/282]\tBatch Time 2.180 (2.180)\tData Load Time 0.933 (0.933)\tLoss 4.4191 (4.4191)\tTop-5 Accuracy 60.522 (60.522)\n",
            "Epoch: [17][100/282]\tBatch Time 1.172 (1.206)\tData Load Time 0.001 (0.010)\tLoss 4.4357 (4.3711)\tTop-5 Accuracy 58.790 (60.718)\n",
            "Epoch: [17][200/282]\tBatch Time 1.210 (1.202)\tData Load Time 0.001 (0.006)\tLoss 4.2698 (4.3674)\tTop-5 Accuracy 62.271 (60.752)\n",
            "Epoch train time 337.814 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.403 (1.403)\tLoss 5.9920 (5.9920)\tTop-5 Accuracy 45.985 (45.985)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.7754216493221\n",
            "2: 24.149272000272557\n",
            "3: 12.7099465141428\n",
            "4: 6.844132409051729\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.653, TOP-5 ACCURACY - 49.170, BLEU-4 - 6.844132409051729\n",
            "\n",
            "Epoch validation time 27.177 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [18][0/282]\tBatch Time 2.213 (2.213)\tData Load Time 0.937 (0.937)\tLoss 4.2270 (4.2270)\tTop-5 Accuracy 62.546 (62.546)\n",
            "Epoch: [18][100/282]\tBatch Time 1.202 (1.209)\tData Load Time 0.001 (0.010)\tLoss 4.2152 (4.3566)\tTop-5 Accuracy 63.873 (60.900)\n",
            "Epoch: [18][200/282]\tBatch Time 1.200 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.4310 (4.3506)\tTop-5 Accuracy 59.279 (61.102)\n",
            "Epoch train time 338.036 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.478 (1.478)\tLoss 5.2504 (5.2504)\tTop-5 Accuracy 52.344 (52.344)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.6458348095694\n",
            "2: 24.117560853207035\n",
            "3: 12.704989070264238\n",
            "4: 6.813854707234168\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.653, TOP-5 ACCURACY - 49.280, BLEU-4 - 6.813854707234168\n",
            "\n",
            "Epoch validation time 27.496 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "Epoch    10: reducing learning rate of group 0 to 4.0000e-09.\n",
            "Epoch    10: reducing learning rate of group 0 to 1.0000e-07.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [19][0/282]\tBatch Time 2.255 (2.255)\tData Load Time 1.029 (1.029)\tLoss 4.0657 (4.0657)\tTop-5 Accuracy 66.539 (66.539)\n",
            "Epoch: [19][100/282]\tBatch Time 1.202 (1.212)\tData Load Time 0.001 (0.011)\tLoss 4.2044 (4.3776)\tTop-5 Accuracy 63.121 (60.482)\n",
            "Epoch: [19][200/282]\tBatch Time 1.194 (1.205)\tData Load Time 0.001 (0.006)\tLoss 4.0944 (4.3600)\tTop-5 Accuracy 63.109 (60.743)\n",
            "Epoch train time 338.167 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.417 (1.417)\tLoss 5.7161 (5.7161)\tTop-5 Accuracy 48.586 (48.586)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.787180336018345\n",
            "2: 24.238548843932517\n",
            "3: 12.804109232369083\n",
            "4: 6.862300456763069\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.651, TOP-5 ACCURACY - 49.196, BLEU-4 - 6.862300456763069\n",
            "\n",
            "Epoch validation time 27.159 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [20][0/282]\tBatch Time 2.280 (2.280)\tData Load Time 1.011 (1.011)\tLoss 4.4788 (4.4788)\tTop-5 Accuracy 60.221 (60.221)\n",
            "Epoch: [20][100/282]\tBatch Time 1.212 (1.210)\tData Load Time 0.001 (0.011)\tLoss 4.3401 (4.3683)\tTop-5 Accuracy 61.174 (60.753)\n",
            "Epoch: [20][200/282]\tBatch Time 1.184 (1.202)\tData Load Time 0.001 (0.006)\tLoss 4.2914 (4.3634)\tTop-5 Accuracy 63.810 (60.812)\n",
            "Epoch train time 338.123 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.464 (1.464)\tLoss 5.6230 (5.6230)\tTop-5 Accuracy 51.325 (51.325)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.707412794035186\n",
            "2: 24.22180696406201\n",
            "3: 12.72703405592358\n",
            "4: 6.753699836656701\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.652, TOP-5 ACCURACY - 49.207, BLEU-4 - 6.753699836656701\n",
            "\n",
            "Epoch validation time 27.177 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [21][0/282]\tBatch Time 2.143 (2.143)\tData Load Time 0.913 (0.913)\tLoss 4.2466 (4.2466)\tTop-5 Accuracy 62.840 (62.840)\n",
            "Epoch: [21][100/282]\tBatch Time 1.178 (1.207)\tData Load Time 0.001 (0.010)\tLoss 4.2649 (4.3564)\tTop-5 Accuracy 64.008 (60.929)\n",
            "Epoch: [21][200/282]\tBatch Time 1.189 (1.202)\tData Load Time 0.001 (0.006)\tLoss 4.3272 (4.3573)\tTop-5 Accuracy 60.566 (60.868)\n",
            "Epoch train time 337.976 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.474 (1.474)\tLoss 5.5625 (5.5625)\tTop-5 Accuracy 50.120 (50.120)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.58985527254057\n",
            "2: 24.116316217634136\n",
            "3: 12.68338394803169\n",
            "4: 6.738267158981621\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.650, TOP-5 ACCURACY - 49.181, BLEU-4 - 6.738267158981621\n",
            "\n",
            "Epoch validation time 27.264 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch    13: reducing learning rate of group 0 to 1.0000e-08.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [22][0/282]\tBatch Time 2.168 (2.168)\tData Load Time 0.941 (0.941)\tLoss 4.5648 (4.5648)\tTop-5 Accuracy 56.806 (56.806)\n",
            "Epoch: [22][100/282]\tBatch Time 1.172 (1.209)\tData Load Time 0.003 (0.010)\tLoss 4.3715 (4.3607)\tTop-5 Accuracy 59.959 (60.771)\n",
            "Epoch: [22][200/282]\tBatch Time 1.212 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.6162 (4.3626)\tTop-5 Accuracy 57.374 (60.848)\n",
            "Epoch train time 338.029 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.402 (1.402)\tLoss 5.4947 (5.4947)\tTop-5 Accuracy 50.378 (50.378)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.721671903262965\n",
            "2: 24.11645415671106\n",
            "3: 12.525851059791151\n",
            "4: 6.611119173359686\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.652, TOP-5 ACCURACY - 49.202, BLEU-4 - 6.611119173359686\n",
            "\n",
            "Epoch validation time 27.253 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [23][0/282]\tBatch Time 2.165 (2.165)\tData Load Time 0.917 (0.917)\tLoss 4.2614 (4.2614)\tTop-5 Accuracy 61.922 (61.922)\n",
            "Epoch: [23][100/282]\tBatch Time 1.200 (1.209)\tData Load Time 0.003 (0.010)\tLoss 4.5093 (4.3591)\tTop-5 Accuracy 59.375 (60.787)\n",
            "Epoch: [23][200/282]\tBatch Time 1.194 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.3041 (4.3656)\tTop-5 Accuracy 62.991 (60.772)\n",
            "Epoch train time 338.130 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.432 (1.432)\tLoss 5.8433 (5.8433)\tTop-5 Accuracy 47.532 (47.532)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.74809780069365\n",
            "2: 24.200440344746973\n",
            "3: 12.677243654232505\n",
            "4: 6.754605133782575\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.652, TOP-5 ACCURACY - 49.191, BLEU-4 - 6.754605133782575\n",
            "\n",
            "Epoch validation time 27.579 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [24][0/282]\tBatch Time 2.162 (2.162)\tData Load Time 0.911 (0.911)\tLoss 4.4468 (4.4468)\tTop-5 Accuracy 61.111 (61.111)\n",
            "Epoch: [24][100/282]\tBatch Time 1.196 (1.208)\tData Load Time 0.001 (0.010)\tLoss 4.2793 (4.3528)\tTop-5 Accuracy 60.949 (61.010)\n",
            "Epoch: [24][200/282]\tBatch Time 1.196 (1.203)\tData Load Time 0.001 (0.006)\tLoss 4.2618 (4.3617)\tTop-5 Accuracy 62.004 (60.832)\n",
            "Epoch train time 338.163 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.399 (1.399)\tLoss 5.9218 (5.9218)\tTop-5 Accuracy 45.682 (45.682)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 44.78705926163313\n",
            "2: 24.262523421724623\n",
            "3: 12.714692018373016\n",
            "4: 6.765237356682744\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.653, TOP-5 ACCURACY - 49.249, BLEU-4 - 6.765237356682744\n",
            "\n",
            "Epoch validation time 27.493 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4akCez3Z6UNp"
      },
      "source": [
        "!cp BEST_checkpoint_flickr8k_ar_finetune.pth.tar /content/drive/MyDrive/ImageCaptioning/flickr8_ar"
      ],
      "id": "4akCez3Z6UNp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knnG-VzB6gu7",
        "outputId": "335350b2-dc51-4b19-f005-5c08e56ab4a9"
      },
      "source": [
        "checkpoint = load_checkpoint(\"BEST_checkpoint_flickr8k_ar_finetune.pth.tar\")\n",
        "decoder = checkpoint['decoder']\n",
        "decoder = decoder.to(device)\n",
        "decoder.eval()\n",
        "encoder = checkpoint['encoder']\n",
        "encoder = encoder.to(device)\n",
        "encoder.eval();"
      ],
      "id": "knnG-VzB6gu7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 19\n",
            "Best Bleu-4: 6.862300456763069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reIYwZ6O6ncg",
        "outputId": "56059b76-ff0b-4176-eef8-67e938da89d4"
      },
      "source": [
        "from eval import test_score\n",
        "\n",
        "test_dict = {}\n",
        "\n",
        "for i in [1, 3, 5]:\n",
        "    \n",
        "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)\n",
        "    if i == 3:\n",
        "        test_dict['b1'] = b1\n",
        "        test_dict['b2'] = b2\n",
        "        test_dict['b3'] = b3\n",
        "    \n",
        "    test_dict[f'b4-b{i}'] = b4"
      ],
      "id": "reIYwZ6O6ncg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 1:   0%|          | 0/3000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "EVALUATING AT BEAM SIZE 1: 100%|██████████| 3000/3000 [01:26<00:00, 34.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 39.95516959427624\n",
            "2: 25.77931292578018\n",
            "3: 15.10781606368901\n",
            "4: 8.64667118061901\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 3:   0%|          | 0/3000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 3: 100%|██████████| 3000/3000 [01:34<00:00, 31.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\rEVALUATING AT BEAM SIZE 5:   0%|          | 0/3000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1: 40.373911854332825\n",
            "2: 26.615634981477243\n",
            "3: 16.09711443584611\n",
            "4: 9.384744789396482\n",
            "-------------------------\n",
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATING AT BEAM SIZE 5: 100%|██████████| 3000/3000 [01:43<00:00, 28.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 39.84779810028518\n",
            "2: 26.47471808239697\n",
            "3: 15.929967050767372\n",
            "4: 9.330062157193685\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzgkO1EF6p_R",
        "outputId": "e698ff4a-1ffc-4d42-cd78-ac892c644849"
      },
      "source": [
        "test_dict"
      ],
      "id": "ZzgkO1EF6p_R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b1': 40.373911854332825,\n",
              " 'b2': 26.615634981477243,\n",
              " 'b3': 16.09711443584611,\n",
              " 'b4-b1': 8.64667118061901,\n",
              " 'b4-b3': 9.384744789396482,\n",
              " 'b4-b5': 9.330062157193685}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i5rSOU78FlS"
      },
      "source": [
        "# final results -> different from training and validation scalars\n",
        "results_dic =  {\n",
        "    # train & valid\n",
        "    'total_epochs': 5.653,\n",
        "    'b-1/test': test_dict['b1'],\n",
        "    'b-2/test': test_dict['b2'],\n",
        "    'b-3/test': test_dict['b3'],\n",
        "    'b-4/b3': test_dict['b4-b3'],\n",
        "    'b-4/b1': test_dict['b4-b1'],\n",
        "    'b-4/b5': test_dict['b4-b5']\n",
        "}"
      ],
      "id": "_i5rSOU78FlS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mStUSnYm8fPC"
      },
      "source": [
        "logger.add_hparams(logger_dic, results_dic, run_name='Arabic_30maxlen')"
      ],
      "id": "mStUSnYm8fPC",
      "execution_count": null,
      "outputs": []
    }
  ]
}