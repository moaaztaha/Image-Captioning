{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moaaztaha/Image-Captioning/blob/main/skipgram_Ar_pretrained_with_Arabert_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:08:40.785208Z",
          "iopub.status.busy": "2021-07-02T08:08:40.784744Z",
          "iopub.status.idle": "2021-07-02T08:08:41.472198Z",
          "shell.execute_reply": "2021-07-02T08:08:41.471085Z",
          "shell.execute_reply.started": "2021-07-02T08:08:40.785118Z"
        },
        "id": "7AmLihjzYLns",
        "outputId": "cd6b221e-68e1-4b16-c920-5b14ccc59e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jul 17 13:20:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V6nYIdcluzJ",
        "outputId": "4d6ac712-839a-485a-9568-39347df7a2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpqIAlbHmLZV",
        "outputId": "43b95799-f06e-47ac-eaa2-f624f3ad8cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading flickr8kimagescaptions.zip to /content\n",
            " 98% 1.02G/1.04G [00:27<00:00, 42.2MB/s]\n",
            "100% 1.04G/1.04G [00:27<00:00, 40.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# setting up kaggle json\n",
        "!mkdir /root/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# downloading dataset from kaggle\n",
        "!pip install kaggle -q\n",
        "!kaggle datasets download -d aladdinpersson/flickr8kimagescaptions\n",
        "!unzip -q flickr8kimagescaptions.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:08:42.111882Z",
          "iopub.status.busy": "2021-07-02T08:08:42.111492Z",
          "iopub.status.idle": "2021-07-02T08:08:47.713294Z",
          "shell.execute_reply": "2021-07-02T08:08:47.712289Z",
          "shell.execute_reply.started": "2021-07-02T08:08:42.111845Z"
        },
        "id": "vCxFJ5wQYehR",
        "outputId": "fa7dd799-721b-482b-bc4e-ce307ad436d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Image-Captioning'...\n",
            "remote: Enumerating objects: 782, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 782 (delta 0), reused 3 (delta 0), pack-reused 778\u001b[K\n",
            "Receiving objects: 100% (782/782), 62.41 MiB | 16.66 MiB/s, done.\n",
            "Resolving deltas: 100% (471/471), done.\n",
            "Checking out files: 100% (142/142), done.\n"
          ]
        }
      ],
      "source": [
        "# get the code form github\n",
        "!git clone https://github.com/moaaztaha/Image-Captioning\n",
        "py_files_path = 'Image-Captioning/'\n",
        "import sys\n",
        "sys.path.append(py_files_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:08:47.715119Z",
          "iopub.status.busy": "2021-07-02T08:08:47.714804Z",
          "iopub.status.idle": "2021-07-02T08:08:47.759010Z",
          "shell.execute_reply": "2021-07-02T08:08:47.758232Z",
          "shell.execute_reply.started": "2021-07-02T08:08:47.715085Z"
        },
        "id": "b4366e4d"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:08:47.760937Z",
          "iopub.status.busy": "2021-07-02T08:08:47.760609Z",
          "iopub.status.idle": "2021-07-02T08:08:50.957077Z",
          "shell.execute_reply": "2021-07-02T08:08:50.956238Z",
          "shell.execute_reply.started": "2021-07-02T08:08:47.760902Z"
        },
        "id": "4034c69e"
      },
      "outputs": [],
      "source": [
        "import time \n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from models import Encoder, DecoderWithAttention\n",
        "from dataset import *\n",
        "from utils import *\n",
        "from train import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from os import path as osp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:32.509464Z",
          "iopub.status.busy": "2021-07-02T08:15:32.509089Z",
          "iopub.status.idle": "2021-07-02T08:15:32.575815Z",
          "shell.execute_reply": "2021-07-02T08:15:32.574892Z",
          "shell.execute_reply.started": "2021-07-02T08:15:32.509427Z"
        },
        "id": "b8ce76f9"
      },
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "encoder_dim = 2048 # resnet101\n",
        "emb_dim = 300  # dimension of word embeddings\n",
        "attention_dim = 300  # dimension of attention linear layers\n",
        "decoder_dim = 300  # dimension of decoder RNN\n",
        "dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
        "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
        "\n",
        "# training parameters\n",
        "epochs = 30  # number of epochs to train for (if early stopping is not triggered)\n",
        "batch_size = 256\n",
        "workers = 2\n",
        "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
        "decoder_lr = 4e-4  # learning rate for decoder\n",
        "fine_tune_encoder = False  # fine-tune encoder?\n",
        "pretrained_embeddings = True\n",
        "fine_tune_embeddings = True\n",
        "checkpoint = None  # path to checkpoint, None if none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:35.354151Z",
          "iopub.status.busy": "2021-07-02T08:15:35.353793Z",
          "iopub.status.idle": "2021-07-02T08:15:35.418158Z",
          "shell.execute_reply": "2021-07-02T08:15:35.417368Z",
          "shell.execute_reply.started": "2021-07-02T08:15:35.354120Z"
        },
        "id": "d7a302e3"
      },
      "outputs": [],
      "source": [
        "DATA_NAME = 'flickr8k_skipgram_ar_arabert_pretrained'\n",
        "\n",
        "# local\n",
        "# DATA_JSON_PATH = 'ar_data.json'\n",
        "# IMGS_PATH = 'flickr/Images/'\n",
        "# kaggle paths\n",
        "# DATA_JSON_PATH = '/kaggle/working/Image-Captioning/data.json'\n",
        "# IMGS_PATH = '../input/flickr8kimagescaptions/flickr8k/images/'\n",
        "#colab\n",
        "DATA_JSON_PATH = '/content/Image-Captioning/notebooks/ar_data.json'\n",
        "IMGS_PATH = 'flickr8k/images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:35.714173Z",
          "iopub.status.busy": "2021-07-02T08:15:35.713846Z",
          "iopub.status.idle": "2021-07-02T08:15:36.283325Z",
          "shell.execute_reply": "2021-07-02T08:15:36.282393Z",
          "shell.execute_reply.started": "2021-07-02T08:15:35.714136Z"
        },
        "id": "a4b1a677",
        "outputId": "7a6f90b3-b656-44be-c475-b9bb52883d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24000/24000 [00:00<00:00, 213023.27it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3309"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "max_seq = 65\n",
        "vocab = build_vocab(DATA_JSON_PATH, max_seq=max_seq)\n",
        "vocab_len = len(vocab); vocab_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:08:54.944397Z",
          "iopub.status.busy": "2021-07-02T08:08:54.943953Z",
          "iopub.status.idle": "2021-07-02T08:08:54.991849Z",
          "shell.execute_reply": "2021-07-02T08:08:54.990814Z",
          "shell.execute_reply.started": "2021-07-02T08:08:54.944344Z"
        },
        "id": "ff6df2d0",
        "outputId": "1ddced3a-5153-4163-e54d-1572072381eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
              " ['<pad>', '<sos>', '<eos>', '<unk>', '+', 'ة', 'طفل', 'صغير', 'تتسلق', 'إلى'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "list(vocab.itos.keys())[:10], list(vocab.itos.values())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCmeibRBTIsx"
      },
      "source": [
        "### Pre-trained Arabic Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:09:06.578734Z",
          "iopub.status.busy": "2021-07-02T08:09:06.578331Z",
          "iopub.status.idle": "2021-07-02T08:09:58.217824Z",
          "shell.execute_reply": "2021-07-02T08:09:58.216636Z",
          "shell.execute_reply.started": "2021-07-02T08:09:06.578703Z"
        },
        "id": "Chu2ZhbITIsx"
      },
      "outputs": [],
      "source": [
        "# downloading arabic skipgrams pretrained word embedings\n",
        "! wget https://bakrianoo.ewr1.vultrobjects.com/aravec/full_grams_sg_300_wiki.zip\n",
        "! unzip -q full_grams_sg_300_wiki.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:09:58.220009Z",
          "iopub.status.busy": "2021-07-02T08:09:58.219669Z",
          "iopub.status.idle": "2021-07-02T08:10:21.606181Z",
          "shell.execute_reply": "2021-07-02T08:10:21.605224Z",
          "shell.execute_reply.started": "2021-07-02T08:09:58.219970Z"
        },
        "id": "qqgnuOdjTIsy"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "model = gensim.models.Word2Vec.load(\"./full_grams_sg_300_wiki.mdl\")\n",
        "model.wv.save_word2vec_format(\"aravec.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:12:59.760849Z",
          "iopub.status.busy": "2021-07-02T08:12:59.760345Z",
          "iopub.status.idle": "2021-07-02T08:12:59.829858Z",
          "shell.execute_reply": "2021-07-02T08:12:59.828999Z",
          "shell.execute_reply.started": "2021-07-02T08:12:59.760810Z"
        },
        "id": "v4s40HCRTIsz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def get_weights(embedding_path):\n",
        "    embeddings_index = {}\n",
        "    with open(embedding_path) as f:\n",
        "        for line in f:\n",
        "            word, coefs = line.split(maxsplit=1)\n",
        "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "            embeddings_index[word] = coefs\n",
        "    print(\"Found %s word vectors.\" % len(dict(embeddings_index)))\n",
        "    \n",
        "    num_tokens = len(vocab)\n",
        "    embedding_dim = 300\n",
        "    hits = 0\n",
        "    misses = 0\n",
        "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "    for word, index in tqdm(vocab.stoi.items()):\n",
        "        if word in embeddings_index:\n",
        "            embedding_matrix[index] = embeddings_index[word]\n",
        "            hits+=1\n",
        "        else:\n",
        "            misses+=1\n",
        "            embedding_matrix[index] = np.random.uniform(-.1, .1, size=embedding_dim)\n",
        "    print(\"Hist:\", hits, \" | Misses:\", misses)\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:12:59.831555Z",
          "iopub.status.busy": "2021-07-02T08:12:59.831186Z",
          "iopub.status.idle": "2021-07-02T08:14:06.350237Z",
          "shell.execute_reply": "2021-07-02T08:14:06.349371Z",
          "shell.execute_reply.started": "2021-07-02T08:12:59.831520Z"
        },
        "id": "dfybi4X2TIsz",
        "outputId": "37c95d28-eea7-49a8-a1a4-71ec91468e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 662110 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3309/3309 [00:00<00:00, 238020.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hist: 2723  | Misses: 586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = get_weights(\"./aravec.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:14:06.352355Z",
          "iopub.status.busy": "2021-07-02T08:14:06.351704Z",
          "iopub.status.idle": "2021-07-02T08:14:06.394518Z",
          "shell.execute_reply": "2021-07-02T08:14:06.393269Z",
          "shell.execute_reply.started": "2021-07-02T08:14:06.352315Z"
        },
        "id": "DiYr4Kk_TIs0",
        "outputId": "6b27278a-21c7-45f1-bd76-c0549b32f765"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3309, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:14:06.397532Z",
          "iopub.status.busy": "2021-07-02T08:14:06.397087Z",
          "iopub.status.idle": "2021-07-02T08:14:06.440650Z",
          "shell.execute_reply": "2021-07-02T08:14:06.439760Z",
          "shell.execute_reply.started": "2021-07-02T08:14:06.397490Z"
        },
        "id": "Cu0DsLMpTIs0",
        "outputId": "93923b08-fafb-4dac-d9f1-ef0476e1bfa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3309"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(vocab.itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:39.426932Z",
          "iopub.status.busy": "2021-07-02T08:15:39.426587Z",
          "iopub.status.idle": "2021-07-02T08:15:39.505800Z",
          "shell.execute_reply": "2021-07-02T08:15:39.504856Z",
          "shell.execute_reply.started": "2021-07-02T08:15:39.426904Z"
        },
        "id": "6fb11e8e",
        "outputId": "4bb926e7-0dc6-4835-8619-635057d11cb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 256,\n",
              " 'data_name': 'flickr8k_skipgram_ar_arabert_pretrained',\n",
              " 'decoder_lr': 0.0004,\n",
              " 'df_path': '/content/Image-Captioning/notebooks/ar_data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_embeddings': True,\n",
              " 'fine_tune_encoder': False,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': True,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f2df4637fd0>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "t_params = {\n",
        "    'data_name': DATA_NAME,\n",
        "    'imgs_path': IMGS_PATH,\n",
        "    'df_path': DATA_JSON_PATH,\n",
        "    'vocab': vocab,\n",
        "    'epochs': epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'workers': workers,\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "    'fine_tune_embeddings': fine_tune_embeddings,\n",
        "}\n",
        "\n",
        "m_params = {\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim,\n",
        "    'dropout': dropout,\n",
        "    'embeddings_matrix': embedding_matrix\n",
        "}\n",
        "\n",
        "logger_dic = {\n",
        "    'decoder_lr': decoder_lr,\n",
        "    'encoder_lr': encoder_lr,\n",
        "    'fine_tune_encoder': fine_tune_encoder,\n",
        "    'pretrained_embeddings': pretrained_embeddings,\n",
        "    'max_seq_length': max_seq,\n",
        "    'vocab_size': vocab_len,\n",
        "    'enocder': 'resnet101',\n",
        "    'dropout': dropout,\n",
        "    'attention_dim': attention_dim,\n",
        "    'embed_dim': emb_dim,\n",
        "    'decoder_dim': decoder_dim,\n",
        "    'encoder_dim': encoder_dim \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "t_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:40.200687Z",
          "iopub.status.busy": "2021-07-02T08:15:40.200341Z",
          "iopub.status.idle": "2021-07-02T08:15:40.266679Z",
          "shell.execute_reply": "2021-07-02T08:15:40.265764Z",
          "shell.execute_reply.started": "2021-07-02T08:15:40.200657Z"
        },
        "id": "8d8e8ebf"
      },
      "outputs": [],
      "source": [
        "# experiment name\n",
        "name = DATA_NAME + \"pretrained\"\n",
        "# path\n",
        "log_dir = 'experiments'\n",
        "\n",
        "logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T08:15:41.100810Z",
          "iopub.status.busy": "2021-07-02T08:15:41.100495Z",
          "iopub.status.idle": "2021-07-02T08:47:52.200137Z",
          "shell.execute_reply": "2021-07-02T08:47:52.199139Z",
          "shell.execute_reply.started": "2021-07-02T08:15:41.100783Z"
        },
        "id": "DIOlt7gxZAbd",
        "outputId": "dbec70d5-cbc9-4bdb-f453-5bebcd9b8a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 18000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 3000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [0][0/71]\tBatch Time 11.189 (11.189)\tData Load Time 4.409 (4.409)\tLoss 8.9688 (8.9688)\tTop-5 Accuracy 0.124 (0.124)\n",
            "Epoch train time 184.974 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.161 (6.161)\tLoss 5.0141 (5.0141)\tTop-5 Accuracy 53.330 (53.330)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 61.150\n",
            "2: 43.565\n",
            "3: 21.524\n",
            "4: 10.850\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 5.085, TOP-5 ACCURACY - 53.280, BLEU-4 - 10.85\n",
            "\n",
            "Epoch validation time 35.935 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [1][0/71]\tBatch Time 6.175 (6.175)\tData Load Time 3.606 (3.606)\tLoss 4.2504 (4.2504)\tTop-5 Accuracy 59.332 (59.332)\n",
            "Epoch train time 180.298 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.150 (6.150)\tLoss 5.0769 (5.0769)\tTop-5 Accuracy 55.540 (55.540)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 63.786\n",
            "2: 44.530\n",
            "3: 26.314\n",
            "4: 15.611\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.884, TOP-5 ACCURACY - 56.872, BLEU-4 - 15.611\n",
            "\n",
            "Epoch validation time 33.502 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [2][0/71]\tBatch Time 6.161 (6.161)\tData Load Time 3.545 (3.545)\tLoss 3.9420 (3.9420)\tTop-5 Accuracy 63.278 (63.278)\n",
            "Epoch train time 179.979 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.036 (6.036)\tLoss 4.8948 (4.8948)\tTop-5 Accuracy 58.468 (58.468)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 68.667\n",
            "2: 49.217\n",
            "3: 30.965\n",
            "4: 19.195\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.789, TOP-5 ACCURACY - 58.834, BLEU-4 - 19.195\n",
            "\n",
            "Epoch validation time 32.710 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [3][0/71]\tBatch Time 6.314 (6.314)\tData Load Time 3.605 (3.605)\tLoss 3.7764 (3.7764)\tTop-5 Accuracy 65.347 (65.347)\n",
            "Epoch train time 180.248 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.081 (6.081)\tLoss 4.5438 (4.5438)\tTop-5 Accuracy 62.692 (62.692)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 67.816\n",
            "2: 49.074\n",
            "3: 31.310\n",
            "4: 20.248\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.662, TOP-5 ACCURACY - 60.939, BLEU-4 - 20.248\n",
            "\n",
            "Epoch validation time 32.770 (epoch_time.avg:.3f)\n",
            "Epoch 00004: reducing learning rate of group 0 to 4.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [4][0/71]\tBatch Time 6.038 (6.038)\tData Load Time 3.417 (3.417)\tLoss 3.6263 (3.6263)\tTop-5 Accuracy 67.994 (67.994)\n",
            "Epoch train time 180.351 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.171 (6.171)\tLoss 4.4678 (4.4678)\tTop-5 Accuracy 62.998 (62.998)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 69.643\n",
            "2: 50.732\n",
            "3: 32.750\n",
            "4: 21.436\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.662, TOP-5 ACCURACY - 61.188, BLEU-4 - 21.436\n",
            "\n",
            "Epoch validation time 32.855 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [5][0/71]\tBatch Time 6.055 (6.055)\tData Load Time 3.546 (3.546)\tLoss 3.6380 (3.6380)\tTop-5 Accuracy 66.942 (66.942)\n",
            "Epoch train time 180.263 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.032 (6.032)\tLoss 4.6671 (4.6671)\tTop-5 Accuracy 61.863 (61.863)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 69.971\n",
            "2: 51.145\n",
            "3: 33.159\n",
            "4: 21.762\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.360, BLEU-4 - 21.762\n",
            "\n",
            "Epoch validation time 32.584 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [6][0/71]\tBatch Time 6.225 (6.225)\tData Load Time 3.597 (3.597)\tLoss 3.4605 (3.4605)\tTop-5 Accuracy 69.460 (69.460)\n",
            "Epoch train time 180.668 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.032 (6.032)\tLoss 4.6634 (4.6634)\tTop-5 Accuracy 61.233 (61.233)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.019\n",
            "2: 51.064\n",
            "3: 33.098\n",
            "4: 21.711\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.655, TOP-5 ACCURACY - 61.497, BLEU-4 - 21.711\n",
            "\n",
            "Epoch validation time 33.124 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "Epoch 00007: reducing learning rate of group 0 to 4.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [7][0/71]\tBatch Time 6.104 (6.104)\tData Load Time 3.501 (3.501)\tLoss 3.5281 (3.5281)\tTop-5 Accuracy 69.908 (69.908)\n",
            "Epoch train time 180.546 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.155 (6.155)\tLoss 4.5702 (4.5702)\tTop-5 Accuracy 62.111 (62.111)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.159\n",
            "2: 51.232\n",
            "3: 33.190\n",
            "4: 21.762\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.657, TOP-5 ACCURACY - 61.483, BLEU-4 - 21.762\n",
            "\n",
            "Epoch validation time 32.816 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [8][0/71]\tBatch Time 6.237 (6.237)\tData Load Time 3.456 (3.456)\tLoss 3.5135 (3.5135)\tTop-5 Accuracy 69.215 (69.215)\n",
            "Epoch train time 180.133 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.116 (6.116)\tLoss 4.3700 (4.3700)\tTop-5 Accuracy 63.213 (63.213)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.200\n",
            "2: 51.294\n",
            "3: 33.279\n",
            "4: 21.817\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.658, TOP-5 ACCURACY - 61.504, BLEU-4 - 21.817\n",
            "\n",
            "Epoch validation time 32.991 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [9][0/71]\tBatch Time 6.264 (6.264)\tData Load Time 3.589 (3.589)\tLoss 3.4766 (3.4766)\tTop-5 Accuracy 69.735 (69.735)\n",
            "Epoch train time 180.159 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.078 (6.078)\tLoss 4.6554 (4.6554)\tTop-5 Accuracy 62.121 (62.121)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.208\n",
            "2: 51.283\n",
            "3: 33.236\n",
            "4: 21.807\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.657, TOP-5 ACCURACY - 61.535, BLEU-4 - 21.807\n",
            "\n",
            "Epoch validation time 32.873 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "Epoch 00010: reducing learning rate of group 0 to 4.0000e-07.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [10][0/71]\tBatch Time 6.105 (6.105)\tData Load Time 3.367 (3.367)\tLoss 3.5041 (3.5041)\tTop-5 Accuracy 69.027 (69.027)\n",
            "Epoch train time 180.010 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.171 (6.171)\tLoss 4.7563 (4.7563)\tTop-5 Accuracy 61.169 (61.169)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.187\n",
            "2: 51.277\n",
            "3: 33.243\n",
            "4: 21.820\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.658, TOP-5 ACCURACY - 61.518, BLEU-4 - 21.82\n",
            "\n",
            "Epoch validation time 32.852 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [11][0/71]\tBatch Time 6.106 (6.106)\tData Load Time 3.436 (3.436)\tLoss 3.4435 (3.4435)\tTop-5 Accuracy 69.992 (69.992)\n",
            "Epoch train time 180.131 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.136 (6.136)\tLoss 4.5961 (4.5961)\tTop-5 Accuracy 62.986 (62.986)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.199\n",
            "2: 51.305\n",
            "3: 33.275\n",
            "4: 21.840\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.542, BLEU-4 - 21.84\n",
            "\n",
            "Epoch validation time 32.991 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [12][0/71]\tBatch Time 6.283 (6.283)\tData Load Time 3.576 (3.576)\tLoss 3.5578 (3.5578)\tTop-5 Accuracy 68.281 (68.281)\n",
            "Epoch train time 180.098 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.136 (6.136)\tLoss 4.8352 (4.8352)\tTop-5 Accuracy 59.825 (59.825)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.225\n",
            "2: 51.334\n",
            "3: 33.271\n",
            "4: 21.828\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.528, BLEU-4 - 21.828\n",
            "\n",
            "Epoch validation time 33.031 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "Epoch 00013: reducing learning rate of group 0 to 4.0000e-08.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [13][0/71]\tBatch Time 6.159 (6.159)\tData Load Time 3.524 (3.524)\tLoss 3.4789 (3.4789)\tTop-5 Accuracy 70.062 (70.062)\n",
            "Epoch train time 180.227 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 5.998 (5.998)\tLoss 4.5114 (4.5114)\tTop-5 Accuracy 62.580 (62.580)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.212\n",
            "2: 51.297\n",
            "3: 33.256\n",
            "4: 21.815\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.523, BLEU-4 - 21.815\n",
            "\n",
            "Epoch validation time 32.941 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [14][0/71]\tBatch Time 6.260 (6.260)\tData Load Time 3.581 (3.581)\tLoss 3.5932 (3.5932)\tTop-5 Accuracy 67.828 (67.828)\n",
            "Epoch train time 180.398 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 5.953 (5.953)\tLoss 4.6151 (4.6151)\tTop-5 Accuracy 61.516 (61.516)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.243\n",
            "2: 51.335\n",
            "3: 33.298\n",
            "4: 21.851\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.537, BLEU-4 - 21.851\n",
            "\n",
            "Epoch validation time 32.599 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/71]\tBatch Time 6.556 (6.556)\tData Load Time 3.815 (3.815)\tLoss 3.4645 (3.4645)\tTop-5 Accuracy 69.630 (69.630)\n",
            "Epoch train time 180.184 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 5.968 (5.968)\tLoss 4.7353 (4.7353)\tTop-5 Accuracy 60.987 (60.987)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.204\n",
            "2: 51.304\n",
            "3: 33.271\n",
            "4: 21.851\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.509, BLEU-4 - 21.851\n",
            "\n",
            "Epoch validation time 33.121 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "Epoch 00016: reducing learning rate of group 0 to 4.0000e-09.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [16][0/71]\tBatch Time 6.184 (6.184)\tData Load Time 3.430 (3.430)\tLoss 3.4491 (3.4491)\tTop-5 Accuracy 70.456 (70.456)\n",
            "Epoch train time 180.258 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.258 (6.258)\tLoss 4.5693 (4.5693)\tTop-5 Accuracy 61.838 (61.838)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.267\n",
            "2: 51.350\n",
            "3: 33.304\n",
            "4: 21.843\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.525, BLEU-4 - 21.843\n",
            "\n",
            "Epoch validation time 33.279 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [17][0/71]\tBatch Time 6.233 (6.233)\tData Load Time 3.487 (3.487)\tLoss 3.4838 (3.4838)\tTop-5 Accuracy 69.239 (69.239)\n",
            "Epoch train time 180.551 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 5.986 (5.986)\tLoss 4.6768 (4.6768)\tTop-5 Accuracy 60.569 (60.569)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.218\n",
            "2: 51.289\n",
            "3: 33.265\n",
            "4: 21.823\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.658, TOP-5 ACCURACY - 61.537, BLEU-4 - 21.823\n",
            "\n",
            "Epoch validation time 32.678 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [18][0/71]\tBatch Time 6.184 (6.184)\tData Load Time 3.456 (3.456)\tLoss 3.4775 (3.4775)\tTop-5 Accuracy 69.541 (69.541)\n",
            "Epoch train time 179.976 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 5.889 (5.889)\tLoss 4.3623 (4.3623)\tTop-5 Accuracy 63.391 (63.391)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.274\n",
            "2: 51.337\n",
            "3: 33.285\n",
            "4: 21.827\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.660, TOP-5 ACCURACY - 61.516, BLEU-4 - 21.827\n",
            "\n",
            "Epoch validation time 33.080 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [19][0/71]\tBatch Time 6.183 (6.183)\tData Load Time 3.427 (3.427)\tLoss 3.5180 (3.5180)\tTop-5 Accuracy 68.546 (68.546)\n",
            "Epoch train time 180.290 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/12]\tBatch Time 6.214 (6.214)\tLoss 4.7074 (4.7074)\tTop-5 Accuracy 61.073 (61.073)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.282\n",
            "2: 51.367\n",
            "3: 33.300\n",
            "4: 21.848\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.659, TOP-5 ACCURACY - 61.511, BLEU-4 - 21.848\n",
            "\n",
            "Epoch validation time 32.907 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ]
        }
      ],
      "source": [
        "fit(t_params=t_params, m_params=m_params, logger=logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:07:59.798068Z",
          "iopub.status.busy": "2021-07-02T09:07:59.797661Z",
          "iopub.status.idle": "2021-07-02T09:08:00.766078Z",
          "shell.execute_reply": "2021-07-02T09:08:00.765167Z",
          "shell.execute_reply.started": "2021-07-02T09:07:59.798032Z"
        },
        "id": "k_MBtdppTIs2",
        "outputId": "71a72504-ce17-4e5a-bd20-d93c70222f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aravec.txt\n",
            "BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar\n",
            "checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar\n",
            "drive\n",
            "experiments\n",
            "flickr8k\n",
            "flickr8kimagescaptions.zip\n",
            "full_grams_sg_300_wiki.mdl\n",
            "full_grams_sg_300_wiki.mdl.trainables.syn1neg.npy\n",
            "full_grams_sg_300_wiki.mdl.wv.vectors.npy\n",
            "full_grams_sg_300_wiki.zip\n",
            "Image-Captioning\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:08:22.120013Z",
          "iopub.status.busy": "2021-07-02T09:08:22.119697Z",
          "iopub.status.idle": "2021-07-02T09:08:22.495609Z",
          "shell.execute_reply": "2021-07-02T09:08:22.494672Z",
          "shell.execute_reply.started": "2021-07-02T09:08:22.119986Z"
        },
        "id": "cgtlSQWzjNwz",
        "outputId": "1c129e38-b225-4810-c542-13143fff3007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 14\n",
            "Best Bleu-4: 21.851\n"
          ]
        }
      ],
      "source": [
        "m = load_checkpoint(\"BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:08:43.083173Z",
          "iopub.status.busy": "2021-07-02T09:08:43.082843Z",
          "iopub.status.idle": "2021-07-02T09:08:43.153713Z",
          "shell.execute_reply": "2021-07-02T09:08:43.152656Z",
          "shell.execute_reply.started": "2021-07-02T09:08:43.083143Z"
        },
        "id": "NJAelDR8ZDsk",
        "outputId": "8a82c809-06f8-4fe3-a00b-f740e0ff0ef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'data_name': 'flickr8k_skipgram_ar_arabert_pretrained_finetune_finetune',\n",
              " 'decoder_lr': 4.000000000000001e-06,\n",
              " 'df_path': '/content/Image-Captioning/notebooks/ar_data.json',\n",
              " 'encoder_lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'fine_tune_embeddings': True,\n",
              " 'fine_tune_encoder': True,\n",
              " 'imgs_path': 'flickr8k/images/',\n",
              " 'pretrained_embeddings': True,\n",
              " 'vocab': <dataset.Vocabulary at 0x7f2df4637fd0>,\n",
              " 'workers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "batch_size = 64\n",
        "fine_tune_encoder = True\n",
        "checkpoint = 'BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar'\n",
        "# epochs = 30\n",
        "\n",
        "t_params['batch_size'] = batch_size\n",
        "t_params['data_name'] = t_params['data_name'] + \"_finetune\" \n",
        "t_params['fine_tune_encoder'] = True\n",
        "t_params['decoder_lr'] = t_params['decoder_lr'] / 10\n",
        "# t_params['epochs'] = epochs\n",
        "t_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:08:46.126466Z",
          "iopub.status.busy": "2021-07-02T09:08:46.126090Z",
          "iopub.status.idle": "2021-07-02T09:34:21.399955Z",
          "shell.execute_reply": "2021-07-02T09:34:21.398331Z",
          "shell.execute_reply.started": "2021-07-02T09:08:46.126433Z"
        },
        "id": "uYhbvtifjXD6",
        "outputId": "c42ad3c3-0532-4685-9393-2a694efe6b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Checkpoint!!\n",
            "Starting Epoch: 15\n",
            "Loading Data\n",
            "Dataset split: train\n",
            "Unique images: 6000\n",
            "Total size: 18000\n",
            "Dataset split: val\n",
            "Unique images: 1000\n",
            "Total size: 3000\n",
            "__________________________________________________\n",
            "-------------------- Fitting --------------------\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [15][0/282]\tBatch Time 4.890 (4.890)\tData Load Time 1.007 (1.007)\tLoss 3.3775 (3.3775)\tTop-5 Accuracy 69.990 (69.990)\n",
            "Epoch: [15][100/282]\tBatch Time 1.361 (1.423)\tData Load Time 0.001 (0.011)\tLoss 3.5779 (3.5443)\tTop-5 Accuracy 67.683 (68.539)\n",
            "Epoch: [15][200/282]\tBatch Time 1.380 (1.404)\tData Load Time 0.001 (0.006)\tLoss 3.5456 (3.5254)\tTop-5 Accuracy 68.004 (68.880)\n",
            "Epoch train time 394.899 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.633 (1.633)\tLoss 4.3821 (4.3821)\tTop-5 Accuracy 64.925 (64.925)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 69.392\n",
            "2: 50.768\n",
            "3: 32.939\n",
            "4: 21.535\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.700, TOP-5 ACCURACY - 60.841, BLEU-4 - 21.535\n",
            "\n",
            "Epoch validation time 31.490 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [16][0/282]\tBatch Time 2.520 (2.520)\tData Load Time 1.060 (1.060)\tLoss 3.4629 (3.4629)\tTop-5 Accuracy 71.028 (71.028)\n",
            "Epoch: [16][100/282]\tBatch Time 1.339 (1.398)\tData Load Time 0.001 (0.011)\tLoss 3.4435 (3.4319)\tTop-5 Accuracy 69.828 (70.344)\n",
            "Epoch: [16][200/282]\tBatch Time 1.362 (1.394)\tData Load Time 0.001 (0.006)\tLoss 3.3708 (3.4402)\tTop-5 Accuracy 72.387 (70.236)\n",
            "Epoch train time 391.508 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.579 (1.579)\tLoss 4.9692 (4.9692)\tTop-5 Accuracy 59.140 (59.140)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.099\n",
            "2: 52.556\n",
            "3: 34.877\n",
            "4: 23.424\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.626, TOP-5 ACCURACY - 61.963, BLEU-4 - 23.424\n",
            "\n",
            "Epoch validation time 30.371 (epoch_time.avg:.3f)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [17][0/282]\tBatch Time 2.560 (2.560)\tData Load Time 0.990 (0.990)\tLoss 3.4474 (3.4474)\tTop-5 Accuracy 70.047 (70.047)\n",
            "Epoch: [17][100/282]\tBatch Time 1.402 (1.404)\tData Load Time 0.000 (0.011)\tLoss 3.3567 (3.3959)\tTop-5 Accuracy 72.011 (71.032)\n",
            "Epoch: [17][200/282]\tBatch Time 1.423 (1.396)\tData Load Time 0.001 (0.006)\tLoss 3.4689 (3.4066)\tTop-5 Accuracy 70.385 (70.788)\n",
            "Epoch train time 391.551 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.830 (1.830)\tLoss 4.9382 (4.9382)\tTop-5 Accuracy 61.440 (61.440)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.255\n",
            "2: 51.930\n",
            "3: 34.334\n",
            "4: 22.927\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.633, TOP-5 ACCURACY - 61.946, BLEU-4 - 22.927\n",
            "\n",
            "Epoch validation time 31.208 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [18][0/282]\tBatch Time 2.428 (2.428)\tData Load Time 1.035 (1.035)\tLoss 3.5749 (3.5749)\tTop-5 Accuracy 69.420 (69.420)\n",
            "Epoch: [18][100/282]\tBatch Time 1.426 (1.401)\tData Load Time 0.001 (0.011)\tLoss 3.4779 (3.3829)\tTop-5 Accuracy 68.943 (71.297)\n",
            "Epoch: [18][200/282]\tBatch Time 1.435 (1.394)\tData Load Time 0.000 (0.006)\tLoss 3.4919 (3.3807)\tTop-5 Accuracy 70.238 (71.281)\n",
            "Epoch train time 391.518 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.674 (1.674)\tLoss 4.5906 (4.5906)\tTop-5 Accuracy 61.638 (61.638)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 70.975\n",
            "2: 52.243\n",
            "3: 34.310\n",
            "4: 22.830\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.637, TOP-5 ACCURACY - 61.853, BLEU-4 - 22.83\n",
            "\n",
            "Epoch validation time 31.228 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "Epoch 00004: reducing learning rate of group 0 to 4.0000e-09.\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-05.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [19][0/282]\tBatch Time 2.598 (2.598)\tData Load Time 1.055 (1.055)\tLoss 3.2127 (3.2127)\tTop-5 Accuracy 73.370 (73.370)\n",
            "Epoch: [19][100/282]\tBatch Time 1.380 (1.397)\tData Load Time 0.001 (0.011)\tLoss 3.4009 (3.3354)\tTop-5 Accuracy 71.900 (71.953)\n",
            "Epoch: [19][200/282]\tBatch Time 1.359 (1.394)\tData Load Time 0.001 (0.006)\tLoss 3.3106 (3.3350)\tTop-5 Accuracy 72.906 (71.926)\n",
            "Epoch train time 391.078 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.617 (1.617)\tLoss 4.7278 (4.7278)\tTop-5 Accuracy 60.457 (60.457)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.051\n",
            "2: 52.492\n",
            "3: 34.898\n",
            "4: 23.356\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.625, TOP-5 ACCURACY - 62.188, BLEU-4 - 23.356\n",
            "\n",
            "Epoch validation time 30.320 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [20][0/282]\tBatch Time 2.490 (2.490)\tData Load Time 1.048 (1.048)\tLoss 3.3105 (3.3105)\tTop-5 Accuracy 72.873 (72.873)\n",
            "Epoch: [20][100/282]\tBatch Time 1.375 (1.398)\tData Load Time 0.001 (0.011)\tLoss 3.3200 (3.3156)\tTop-5 Accuracy 71.853 (72.264)\n",
            "Epoch: [20][200/282]\tBatch Time 1.513 (1.392)\tData Load Time 0.001 (0.006)\tLoss 3.2403 (3.3143)\tTop-5 Accuracy 72.031 (72.223)\n",
            "Epoch train time 391.458 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.636 (1.636)\tLoss 4.4266 (4.4266)\tTop-5 Accuracy 63.940 (63.940)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.054\n",
            "2: 52.434\n",
            "3: 34.869\n",
            "4: 23.337\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.623, TOP-5 ACCURACY - 62.205, BLEU-4 - 23.337\n",
            "\n",
            "Epoch validation time 30.644 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [21][0/282]\tBatch Time 2.539 (2.539)\tData Load Time 1.080 (1.080)\tLoss 3.4761 (3.4761)\tTop-5 Accuracy 69.415 (69.415)\n",
            "Epoch: [21][100/282]\tBatch Time 1.390 (1.398)\tData Load Time 0.001 (0.012)\tLoss 3.3383 (3.3031)\tTop-5 Accuracy 71.599 (72.378)\n",
            "Epoch: [21][200/282]\tBatch Time 1.409 (1.392)\tData Load Time 0.001 (0.006)\tLoss 3.1944 (3.3029)\tTop-5 Accuracy 73.603 (72.364)\n",
            "Epoch train time 391.652 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.672 (1.672)\tLoss 4.3501 (4.3501)\tTop-5 Accuracy 61.991 (61.991)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.294\n",
            "2: 52.681\n",
            "3: 35.106\n",
            "4: 23.536\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.624, TOP-5 ACCURACY - 62.214, BLEU-4 - 23.536\n",
            "\n",
            "Epoch validation time 30.151 (epoch_time.avg:.3f)\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-06.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [22][0/282]\tBatch Time 2.381 (2.381)\tData Load Time 0.983 (0.983)\tLoss 3.4290 (3.4290)\tTop-5 Accuracy 70.438 (70.438)\n",
            "Epoch: [22][100/282]\tBatch Time 1.397 (1.404)\tData Load Time 0.001 (0.011)\tLoss 3.2130 (3.2989)\tTop-5 Accuracy 72.991 (72.492)\n",
            "Epoch: [22][200/282]\tBatch Time 1.409 (1.397)\tData Load Time 0.003 (0.006)\tLoss 3.2923 (3.2969)\tTop-5 Accuracy 70.464 (72.447)\n",
            "Epoch train time 392.290 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.641 (1.641)\tLoss 4.6963 (4.6963)\tTop-5 Accuracy 61.462 (61.462)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.173\n",
            "2: 52.605\n",
            "3: 35.066\n",
            "4: 23.526\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.629, TOP-5 ACCURACY - 62.251, BLEU-4 - 23.526\n",
            "\n",
            "Epoch validation time 29.840 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (1,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [23][0/282]\tBatch Time 2.414 (2.414)\tData Load Time 1.010 (1.010)\tLoss 3.2422 (3.2422)\tTop-5 Accuracy 73.193 (73.193)\n",
            "Epoch: [23][100/282]\tBatch Time 1.355 (1.396)\tData Load Time 0.001 (0.011)\tLoss 3.2595 (3.2806)\tTop-5 Accuracy 72.204 (72.718)\n",
            "Epoch: [23][200/282]\tBatch Time 1.374 (1.389)\tData Load Time 0.001 (0.006)\tLoss 3.3879 (3.2887)\tTop-5 Accuracy 71.608 (72.593)\n",
            "Epoch train time 390.822 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.593 (1.593)\tLoss 4.4229 (4.4229)\tTop-5 Accuracy 64.293 (64.293)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.086\n",
            "2: 52.430\n",
            "3: 34.887\n",
            "4: 23.339\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.625, TOP-5 ACCURACY - 62.225, BLEU-4 - 23.339\n",
            "\n",
            "Epoch validation time 30.590 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (2,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [24][0/282]\tBatch Time 2.604 (2.604)\tData Load Time 1.014 (1.014)\tLoss 3.3712 (3.3712)\tTop-5 Accuracy 71.516 (71.516)\n",
            "Epoch: [24][100/282]\tBatch Time 1.345 (1.402)\tData Load Time 0.001 (0.011)\tLoss 3.3821 (3.2974)\tTop-5 Accuracy 71.459 (72.436)\n",
            "Epoch: [24][200/282]\tBatch Time 1.344 (1.392)\tData Load Time 0.001 (0.006)\tLoss 3.3291 (3.2946)\tTop-5 Accuracy 72.029 (72.520)\n",
            "Epoch train time 391.607 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.583 (1.583)\tLoss 3.9770 (3.9770)\tTop-5 Accuracy 66.390 (66.390)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.324\n",
            "2: 52.635\n",
            "3: 35.011\n",
            "4: 23.496\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.622, TOP-5 ACCURACY - 62.230, BLEU-4 - 23.496\n",
            "\n",
            "Epoch validation time 30.393 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (3,)\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-07.\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [25][0/282]\tBatch Time 2.451 (2.451)\tData Load Time 1.051 (1.051)\tLoss 3.2266 (3.2266)\tTop-5 Accuracy 73.523 (73.523)\n",
            "Epoch: [25][100/282]\tBatch Time 1.388 (1.399)\tData Load Time 0.001 (0.012)\tLoss 3.1891 (3.2799)\tTop-5 Accuracy 74.517 (72.738)\n",
            "Epoch: [25][200/282]\tBatch Time 1.345 (1.393)\tData Load Time 0.001 (0.006)\tLoss 3.2624 (3.2917)\tTop-5 Accuracy 73.651 (72.517)\n",
            "Epoch train time 391.115 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.617 (1.617)\tLoss 4.3451 (4.3451)\tTop-5 Accuracy 64.176 (64.176)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.180\n",
            "2: 52.543\n",
            "3: 34.960\n",
            "4: 23.440\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.624, TOP-5 ACCURACY - 62.181, BLEU-4 - 23.44\n",
            "\n",
            "Epoch validation time 30.186 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (4,)\n",
            "__________________________________________________\n",
            "-------------------- Training --------------------\n",
            "Epoch: [26][0/282]\tBatch Time 2.480 (2.480)\tData Load Time 1.017 (1.017)\tLoss 3.2532 (3.2532)\tTop-5 Accuracy 72.451 (72.451)\n",
            "Epoch: [26][100/282]\tBatch Time 1.363 (1.400)\tData Load Time 0.001 (0.011)\tLoss 3.2755 (3.2958)\tTop-5 Accuracy 71.273 (72.472)\n",
            "Epoch: [26][200/282]\tBatch Time 1.411 (1.392)\tData Load Time 0.001 (0.006)\tLoss 3.3552 (3.2970)\tTop-5 Accuracy 70.890 (72.467)\n",
            "Epoch train time 391.794 (epoch_time.avg:.3f)\n",
            "-------------------- Validation --------------------\n",
            "Validation: [0/47]\tBatch Time 1.618 (1.618)\tLoss 4.1674 (4.1674)\tTop-5 Accuracy 66.667 (66.667)\t\n",
            "----- Bleu-n Scores -----\n",
            "1: 71.120\n",
            "2: 52.493\n",
            "3: 34.926\n",
            "4: 23.355\n",
            "-------------------------\n",
            "\n",
            " * LOSS - 4.628, TOP-5 ACCURACY - 62.191, BLEU-4 - 23.355\n",
            "\n",
            "Epoch validation time 29.925 (epoch_time.avg:.3f)\n",
            "\n",
            "Epochs since last improvement: (5,)\n",
            "No improvement for 5 consecutive epochs, terminating...\n"
          ]
        }
      ],
      "source": [
        "fit(t_params, checkpoint=checkpoint, m_params=m_params, logger=logger)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeXG397won_X",
        "outputId": "bb43daae-1f80-4a38-fc38-28119e9fdc78"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aravec.txt\n",
            "BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained_finetune_finetune.pth.tar\n",
            "BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar\n",
            "checkpoint_flickr8k_skipgram_ar_arabert_pretrained_finetune_finetune.pth.tar\n",
            "checkpoint_flickr8k_skipgram_ar_arabert_pretrained.pth.tar\n",
            "drive\n",
            "experiments\n",
            "flickr8k\n",
            "flickr8kimagescaptions.zip\n",
            "full_grams_sg_300_wiki.mdl\n",
            "full_grams_sg_300_wiki.mdl.trainables.syn1neg.npy\n",
            "full_grams_sg_300_wiki.mdl.wv.vectors.npy\n",
            "full_grams_sg_300_wiki.zip\n",
            "Image-Captioning\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMMO_K-2LaYR"
      },
      "source": [
        "### Test Scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained_finetune_finetune.pth.tar /content/drive/MyDrive/ImageCaptioning/skipgram/"
      ],
      "metadata": {
        "id": "C7AJQiEDqko4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:52:17.735973Z",
          "iopub.status.busy": "2021-07-02T09:52:17.735653Z",
          "iopub.status.idle": "2021-07-02T09:52:18.162418Z",
          "shell.execute_reply": "2021-07-02T09:52:18.161492Z",
          "shell.execute_reply.started": "2021-07-02T09:52:17.735943Z"
        },
        "id": "knnG-VzB6gu7",
        "outputId": "eb898093-390c-43d8-8a9d-27359a4435d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Checkpoint!!\n",
            "Last Epoch: 21\n",
            "Best Bleu-4: 23.536\n"
          ]
        }
      ],
      "source": [
        "checkpoint = load_checkpoint(\"BEST_checkpoint_flickr8k_skipgram_ar_arabert_pretrained_finetune_finetune.pth.tar\")\n",
        "decoder = checkpoint['decoder']\n",
        "decoder = decoder.to(device)\n",
        "decoder.eval()\n",
        "encoder = checkpoint['encoder']\n",
        "encoder = encoder.to(device)\n",
        "encoder.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-02T09:52:35.780129Z",
          "iopub.status.busy": "2021-07-02T09:52:35.779796Z",
          "iopub.status.idle": "2021-07-02T09:59:00.851666Z",
          "shell.execute_reply": "2021-07-02T09:59:00.850406Z",
          "shell.execute_reply.started": "2021-07-02T09:52:35.780099Z"
        },
        "id": "reIYwZ6O6ncg",
        "outputId": "e000f7e9-88d8-436f-e015-5d1d89ace20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EVALUATING AT BEAM SIZE 1:   0%|          | 0/1000 [00:00<?, ?it/s]Image-Captioning/eval.py:93: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prev_word_inds = top_k_words // vocab_size  # (s)\n",
            "EVALUATING AT BEAM SIZE 1: 100%|██████████| 1000/1000 [00:58<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 57.457\n",
            "2: 43.794\n",
            "3: 31.863\n",
            "4: 22.814\n",
            "-------------------------\n",
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EVALUATING AT BEAM SIZE 3: 100%|██████████| 1000/1000 [00:58<00:00, 17.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 59.903\n",
            "2: 47.406\n",
            "3: 36.130\n",
            "4: 26.897\n",
            "-------------------------\n",
            "Dataset split: test\n",
            "Unique images: 1000\n",
            "Total size: 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EVALUATING AT BEAM SIZE 5: 100%|██████████| 1000/1000 [01:03<00:00, 15.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Bleu-n Scores -----\n",
            "1: 58.708\n",
            "2: 46.523\n",
            "3: 35.712\n",
            "4: 27.012\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "from eval import test_score\n",
        "\n",
        "test_dict = {}\n",
        "\n",
        "for i in [1, 3, 5]:\n",
        "    \n",
        "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)\n",
        "    if i == 3:\n",
        "        test_dict['b1'] = b1\n",
        "        test_dict['b2'] = b2\n",
        "        test_dict['b3'] = b3\n",
        "    \n",
        "    test_dict[f'b4-b{i}'] = b4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "skipgram - Ar pretrained with Arabert preprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}