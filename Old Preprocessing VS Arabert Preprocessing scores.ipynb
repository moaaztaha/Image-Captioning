{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:06:17.133766Z",
     "iopub.status.busy": "2021-07-17T13:06:17.133354Z",
     "iopub.status.idle": "2021-07-17T13:06:17.181700Z",
     "shell.execute_reply": "2021-07-17T13:06:17.180619Z",
     "shell.execute_reply.started": "2021-07-17T13:06:17.133730Z"
    },
    "id": "b4366e4d"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:06:18.808551Z",
     "iopub.status.busy": "2021-07-17T13:06:18.808173Z",
     "iopub.status.idle": "2021-07-17T13:06:23.008079Z",
     "shell.execute_reply": "2021-07-17T13:06:23.007029Z",
     "shell.execute_reply.started": "2021-07-17T13:06:18.808492Z"
    },
    "id": "4034c69e"
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from train import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os import path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:06:38.929331Z",
     "iopub.status.busy": "2021-07-17T13:06:38.928921Z",
     "iopub.status.idle": "2021-07-17T13:06:38.978858Z",
     "shell.execute_reply": "2021-07-17T13:06:38.977752Z",
     "shell.execute_reply.started": "2021-07-17T13:06:38.929301Z"
    },
    "id": "b8ce76f9"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "encoder_dim = 2048 # resnet101\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "decoder_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# training parameters\n",
    "epochs = 30  # number of epochs to train for (if early stopping is not triggered)\n",
    "batch_size = 256\n",
    "workers = 2\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "pretrained_embeddings = False\n",
    "fine_tune_embeddings = False\n",
    "checkpoint = None  # path to checkpoint, None if none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Preprocessing to Arabert  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:07:02.652391Z",
     "iopub.status.busy": "2021-07-17T13:07:02.652020Z",
     "iopub.status.idle": "2021-07-17T13:07:02.698928Z",
     "shell.execute_reply": "2021-07-17T13:07:02.697758Z",
     "shell.execute_reply.started": "2021-07-17T13:07:02.652357Z"
    },
    "id": "d7a302e3"
   },
   "outputs": [],
   "source": [
    "DATA_JSON_PATH = 'old_ar_data.json'\n",
    "IMGS_PATH = 'flickr/Images/'\n",
    "DATA_NAME = 'TESTING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:07:07.551421Z",
     "iopub.status.busy": "2021-07-17T13:07:07.551059Z",
     "iopub.status.idle": "2021-07-17T13:07:08.027838Z",
     "shell.execute_reply": "2021-07-17T13:07:08.026347Z",
     "shell.execute_reply.started": "2021-07-17T13:07:07.551388Z"
    },
    "id": "a4b1a677",
    "outputId": "9356268d-4297-4f43-c44e-3aef77004680"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [00:00<00:00, 514407.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5788"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq = 30\n",
    "vocab = build_vocab(DATA_JSON_PATH, max_seq=max_seq)\n",
    "vocab_len = len(vocab); vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T13:07:28.390568Z",
     "iopub.status.busy": "2021-07-17T13:07:28.390150Z",
     "iopub.status.idle": "2021-07-17T13:07:28.442817Z",
     "shell.execute_reply": "2021-07-17T13:07:28.441335Z",
     "shell.execute_reply.started": "2021-07-17T13:07:28.390526Z"
    },
    "id": "ff6df2d0",
    "outputId": "dcf14d12-9a82-49ef-b74b-66b728e23823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " ['<pad>',\n",
       "  '<sos>',\n",
       "  '<eos>',\n",
       "  '<unk>',\n",
       "  'طفلة',\n",
       "  'صغيرة',\n",
       "  'تتسلق',\n",
       "  'إلى',\n",
       "  'كلب',\n",
       "  'أسود'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.itos.keys())[:10], list(vocab.itos.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T14:31:30.992363Z",
     "iopub.status.busy": "2021-07-17T14:31:30.991995Z",
     "iopub.status.idle": "2021-07-17T14:31:31.341563Z",
     "shell.execute_reply": "2021-07-17T14:31:31.340228Z",
     "shell.execute_reply.started": "2021-07-17T14:31:30.992328Z"
    },
    "id": "cgtlSQWzjNwz",
    "outputId": "9df0886b-4b65-4a7b-d4bc-36b41f0c9e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpoint!!\n",
      "Last Epoch: 19\n",
      "Best Bleu-4: 6.862300456763069\n"
     ]
    }
   ],
   "source": [
    "m = load_checkpoint(\"models/BEST_checkpoint_flickr8k_ar_finetune.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = m['encoder'].eval()\n",
    "decoder = m['decoder'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T15:07:27.757142Z",
     "iopub.status.busy": "2021-07-17T15:07:27.756791Z",
     "iopub.status.idle": "2021-07-17T15:21:46.839602Z",
     "shell.execute_reply": "2021-07-17T15:21:46.838395Z",
     "shell.execute_reply.started": "2021-07-17T15:07:27.757112Z"
    },
    "id": "reIYwZ6O6ncg",
    "outputId": "56059b76-ff0b-4176-eef8-67e938da89d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 1:   0%|          | 0/1000 [00:00<?, ?it/s]/home/kelwa/anaconda3/envs/yolo5/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/kelwa/anaconda3/envs/yolo5/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "EVALUATING AT BEAM SIZE 1: 100%|██████████| 1000/1000 [00:24<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 39.95516959427624\n",
      "2: 25.77931292578018\n",
      "3: 15.10781606368901\n",
      "4: 8.64667118061901\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 2: 100%|██████████| 1000/1000 [00:27<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 40.68928313941436\n",
      "2: 26.982549212073188\n",
      "3: 16.459546825901818\n",
      "4: 9.631675158047099\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 3: 100%|██████████| 1000/1000 [00:30<00:00, 33.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 40.373911854332825\n",
      "2: 26.615634981477243\n",
      "3: 16.09711443584611\n",
      "4: 9.384744789396482\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 4: 100%|██████████| 1000/1000 [00:34<00:00, 28.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 40.48892525456145\n",
      "2: 26.861057340847083\n",
      "3: 16.299550030840223\n",
      "4: 9.621167436145724\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 5: 100%|██████████| 1000/1000 [00:36<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 39.84779810028518\n",
      "2: 26.47471808239697\n",
      "3: 15.929967050767372\n",
      "4: 9.330062157193685\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from eval import test_score\n",
    "\n",
    "for i in range(1, 6):\n",
    "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results of the best beam size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 2: 100%|██████████| 1000/1000 [00:27<00:00, 36.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 40.68928313941436\n",
      "2: 26.982549212073188\n",
      "3: 16.459546825901818\n",
      "4: 9.631675158047099\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "references, hypotheses = test_score(2, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab, return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_old_tokens = [[[vocab.itos[i] for i in refe] for refe in refes] for refes in references]\n",
    "hypotheses_old_tokens = [[vocab.itos[i] for i in hypo] for hypo in hypotheses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-09-28 11:55:09,013 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "\n",
    "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_ara_tokens = [araby.tokenize(arabert_prep.preprocess(\" \".join(i))) for i in hypotheses_old_tokens]\n",
    "references_ara_tokens = [[araby.tokenize(arabert_prep.preprocess(\" \".join(i))) for i in ref] for ref in references_old_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 54.85289890804387\n",
      "2: 43.93811436252674\n",
      "3: 34.76736607534273\n",
      "4: 27.80241332075155\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54.85289890804387, 43.93811436252674, 34.76736607534273, 27.80241332075155)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_scores(references_ara_tokens, hypotheses_ara_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabet to old Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_JSON_PATH = 'data/ar_data.json'\n",
    "IMGS_PATH = 'flickr/Images/'\n",
    "DATA_NAME = 'TESTING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [00:00<00:00, 281365.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3309"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq = 65\n",
    "vocab = build_vocab(DATA_JSON_PATH, max_seq=max_seq)\n",
    "vocab_len = len(vocab); vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " ['<pad>', '<sos>', '<eos>', '<unk>', '+', 'ة', 'طفل', 'صغير', 'تتسلق', 'إلى'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.itos.keys())[:10], list(vocab.itos.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpoint!!\n",
      "Last Epoch: 9\n",
      "Best Bleu-4: 24.949378413361714\n"
     ]
    }
   ],
   "source": [
    "m = load_checkpoint(\"ar_models/BEST_checkpoint_flickr8k_ar_arabert_pretrained_finetune.pth.tar\")\n",
    "encoder = m['encoder'].eval()\n",
    "decoder = m['decoder'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 1: 100%|██████████| 1000/1000 [00:36<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 59.27134312126155\n",
      "2: 45.52397958654338\n",
      "3: 33.58850576504064\n",
      "4: 24.918812277227662\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 2: 100%|██████████| 1000/1000 [00:43<00:00, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 59.68623977817169\n",
      "2: 46.88248014003475\n",
      "3: 35.44609658225986\n",
      "4: 26.921966136090035\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 3: 100%|██████████| 1000/1000 [00:49<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 60.32593136195551\n",
      "2: 47.5536072957737\n",
      "3: 36.147037636633875\n",
      "4: 27.524282207029003\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 4: 100%|██████████| 1000/1000 [00:57<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 59.51223743176995\n",
      "2: 47.318183310877345\n",
      "3: 36.32951749139962\n",
      "4: 27.893442570349023\n",
      "-------------------------\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 5: 100%|██████████| 1000/1000 [01:02<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 58.678484239386094\n",
      "2: 46.85683508774053\n",
      "3: 36.14555791431082\n",
      "4: 27.864202291806382\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from eval import test_score\n",
    "for i in range(1, 6):\n",
    "    b1, b2, b3, b4 = test_score(i, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 4: 100%|██████████| 1000/1000 [00:57<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 59.51223743176995\n",
      "2: 47.318183310877345\n",
      "3: 36.32951749139962\n",
      "4: 27.893442570349023\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "references, hypotheses = test_score(4, encoder, decoder, IMGS_PATH, DATA_JSON_PATH, vocab, return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_ara_tokens = [[[vocab.itos[i] for i in refe] for refe in refes] for refes in references]\n",
    "hypotheses_ara_tokens = [[vocab.itos[i] for i in hypo] for hypo in hypotheses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_sent_tokens = [[arabert_prep.unpreprocess(' '.join(w for w in i)) for i in refe] for refe in references_ara_tokens] \n",
    "hypotheses_sent_tokens = [arabert_prep.unpreprocess(' '.join(w for w in i)) for i in hypotheses_ara_tokens]\n",
    "assert len(references_sent_tokens) == len(hypotheses_sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_old_tokens = [[araby.tokenize(i)  for i in refe] for refe in references_sent_tokens] \n",
    "hypotheses_old_tokens = [araby.tokenize(i)  for i in hypotheses_sent_tokens]\n",
    "assert len(references_old_tokens) == len(hypotheses_old_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Bleu-n Scores -----\n",
      "1: 32.26797327283087\n",
      "2: 20.74686106020747\n",
      "3: 11.73920224562103\n",
      "4: 6.022065664696533\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32.26797327283087, 20.74686106020747, 11.73920224562103, 6.022065664696533)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_scores(references_old_tokens, hypotheses_old_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Predictions info\n",
    "- Ground Truth Captions [separete df]\n",
    "- Araby Catpions and Arabert captions with their number of tokens (print the number of words later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the ground truth captions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>امرأة شقراء في قميص أزرق تنتظر رحلة</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>امرأة شقراء في الشارع تشير الى سيارة أجرة</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>المرأة في الثوب الأزرق تمد بذراعها لحركة المرو...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>صبي في ملابس السباحة الزرقاء على الشاطئ</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>صبي يبتسم للكاميرا على الشاطئ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  \\\n",
       "126  1056338697_4f7d7ce270.jpg   \n",
       "127  1056338697_4f7d7ce270.jpg   \n",
       "128  1056338697_4f7d7ce270.jpg   \n",
       "144   106490881_5a2dd9b7bd.jpg   \n",
       "145   106490881_5a2dd9b7bd.jpg   \n",
       "\n",
       "                                               caption  tok_len  \n",
       "126                امرأة شقراء في قميص أزرق تنتظر رحلة        7  \n",
       "127          امرأة شقراء في الشارع تشير الى سيارة أجرة        8  \n",
       "128  المرأة في الثوب الأزرق تمد بذراعها لحركة المرو...        9  \n",
       "144            صبي في ملابس السباحة الزرقاء على الشاطئ        7  \n",
       "145                      صبي يبتسم للكاميرا على الشاطئ        5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_json('old_ar_data.json')\n",
    "ground_truth = df[df['split'] == 'test'].drop(['split', 'tokens'], axis=1)\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from caption import CaptionDataset, caption_image\n",
    "from utils import load_checkpoint, print_scores\n",
    "from dataset import build_vocab\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/BEST_checkpoint_flickr8k_ar_finetune.pth.tar'\n",
    "IMGS_PATH = 'flickr/Images/'\n",
    "DATA_JSON_PATH = 'old_ar_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [00:00<00:00, 497345.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 5788\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n",
      "--------------------\n",
      "Loaded Checkpoint!!\n",
      "Last Epoch: 19\n",
      "Best Bleu-4: 6.862300456763069\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(DATA_JSON_PATH)\n",
    "print('len:',len(vocab))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "bs = 1\n",
    "loader = DataLoader(\n",
    "            dataset=CaptionDataset(IMGS_PATH, DATA_JSON_PATH,\n",
    "                                    transforms=transform, vocab=vocab, split='test'),\n",
    "            batch_size=bs,\n",
    "            num_workers=7,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "print('-'*20)\n",
    "checkpoint = load_checkpoint(model_path)\n",
    "encoder = checkpoint['encoder'].eval()\n",
    "decoder = checkpoint['decoder'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 2: 100%|██████████| 1000/1000 [00:27<00:00, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NO COMPLETED:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "references, hypothesis, img_ids = caption_image(loader, vocab, encoder,\n",
    "                                               decoder, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_tokens = [[vocab.itos[i] for i in hypo] for hypo in hypothesis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>old_hypotheses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[رجل, في, قميص, أزرق, يقفز, في, الهواء]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, يجلس, على, لوح, التزلج, في, الهواء]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, على, العشب]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[صبي, صغير, يلعب, في, الشارع]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name                                  old_hypotheses\n",
       "0  1056338697_4f7d7ce270.jpg         [رجل, في, قميص, أزرق, يقفز, في, الهواء]\n",
       "1   106490881_5a2dd9b7bd.jpg  [صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]\n",
       "2  1082379191_ec1e53f996.jpg       [رجل, يجلس, على, لوح, التزلج, في, الهواء]\n",
       "3  1084040636_97d9633581.jpg                   [كلب, أبيض, يركض, على, العشب]\n",
       "4  1096395242_fc69f0ae5a.jpg                   [صبي, صغير, يلعب, في, الشارع]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\"file_name\":img_ids, \"old_hypotheses\": hypotheses_tokens})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>old_hypotheses</th>\n",
       "      <th>old_tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[رجل, في, قميص, أزرق, يقفز, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, يجلس, على, لوح, التزلج, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, على, العشب]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[صبي, صغير, يلعب, في, الشارع]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name                                  old_hypotheses  \\\n",
       "0  1056338697_4f7d7ce270.jpg         [رجل, في, قميص, أزرق, يقفز, في, الهواء]   \n",
       "1   106490881_5a2dd9b7bd.jpg  [صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]   \n",
       "2  1082379191_ec1e53f996.jpg       [رجل, يجلس, على, لوح, التزلج, في, الهواء]   \n",
       "3  1084040636_97d9633581.jpg                   [كلب, أبيض, يركض, على, العشب]   \n",
       "4  1096395242_fc69f0ae5a.jpg                   [صبي, صغير, يلعب, في, الشارع]   \n",
       "\n",
       "   old_tok_len  \n",
       "0            7  \n",
       "1            8  \n",
       "2            7  \n",
       "3            5  \n",
       "4            5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['old_tok_len'] = df['old_hypotheses'].apply(lambda x: len(x)).values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabert Predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'ar_models/BEST_checkpoint_flickr8k_ar_arabert_pretrained_finetune.pth.tar'\n",
    "IMGS_PATH = 'flickr/Images/'\n",
    "DATA_JSON_PATH = 'data/ar_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [00:00<00:00, 304476.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 3309\n",
      "Dataset split: test\n",
      "Unique images: 1000\n",
      "Total size: 3000\n",
      "--------------------\n",
      "Loaded Checkpoint!!\n",
      "Last Epoch: 9\n",
      "Best Bleu-4: 24.949378413361714\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(DATA_JSON_PATH)\n",
    "print('len:',len(vocab))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "bs = 1\n",
    "loader = DataLoader(\n",
    "            dataset=CaptionDataset(IMGS_PATH, DATA_JSON_PATH,\n",
    "                                    transforms=transform, vocab=vocab, split='test'),\n",
    "            batch_size=bs,\n",
    "            num_workers=7,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "print('-'*20)\n",
    "checkpoint = load_checkpoint(model_path)\n",
    "encoder = checkpoint['encoder'].eval()\n",
    "decoder = checkpoint['decoder'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 4: 100%|██████████| 1000/1000 [00:56<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NO COMPLETED:  25\n"
     ]
    }
   ],
   "source": [
    "references, hypothesis, img_ids = caption_image(loader, vocab, encoder,\n",
    "                                               decoder, 4)\n",
    "hypotheses_tokens = [[vocab.itos[i] for i in hypo] for hypo in hypothesis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hypotheses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, في, ال, +, هواء]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, يقفز, في, ال, +, ماء]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1   106490881_5a2dd9b7bd.jpg   \n",
       "2  1082379191_ec1e53f996.jpg   \n",
       "3  1084040636_97d9633581.jpg   \n",
       "4  1096395242_fc69f0ae5a.jpg   \n",
       "\n",
       "                                          hypotheses  \n",
       "0           [فتا, +, ة, صغير, +, ة, في, ال, +, هواء]  \n",
       "1                  [صبي, صغير, يقفز, في, ال, +, ماء]  \n",
       "2  [رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...  \n",
       "3  [ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...  \n",
       "4  [فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_df = pd.DataFrame.from_dict({\"file_name\":img_ids, \"hypotheses\": hypotheses_tokens})\n",
    "rest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hypotheses</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, في, ال, +, هواء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, يقفز, في, ال, +, ماء]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1   106490881_5a2dd9b7bd.jpg   \n",
       "2  1082379191_ec1e53f996.jpg   \n",
       "3  1084040636_97d9633581.jpg   \n",
       "4  1096395242_fc69f0ae5a.jpg   \n",
       "\n",
       "                                          hypotheses  tok_len  \n",
       "0           [فتا, +, ة, صغير, +, ة, في, ال, +, هواء]       10  \n",
       "1                  [صبي, صغير, يقفز, في, ال, +, ماء]        7  \n",
       "2  [رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...       13  \n",
       "3  [ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...       19  \n",
       "4  [فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...       19  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_df['tok_len'] = rest_df['hypotheses'].apply(lambda x: len(x)).values\n",
    "rest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_df['file_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>old_hypotheses</th>\n",
       "      <th>old_tok_len</th>\n",
       "      <th>hypotheses</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[رجل, في, قميص, أزرق, يقفز, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, في, ال, +, هواء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]</td>\n",
       "      <td>8</td>\n",
       "      <td>[صبي, صغير, يقفز, في, ال, +, ماء]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, يجلس, على, لوح, التزلج, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "      <td>[رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, على, العشب]</td>\n",
       "      <td>5</td>\n",
       "      <td>[ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[صبي, صغير, يلعب, في, الشارع]</td>\n",
       "      <td>5</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>925491651_57df3a5b36.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, في, الماء]</td>\n",
       "      <td>5</td>\n",
       "      <td>[كلب, يركض, في, ال, +, ماء]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>96420612_feb18fc6c6.jpg</td>\n",
       "      <td>[رجل, في, قميص, أبيض, يقفز, فوق, منحدر]</td>\n",
       "      <td>7</td>\n",
       "      <td>[رجل, يرتدي, قميص, +, ا, أحمر, و, +, أسود, +, ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>968081289_cdba83ce2e.jpg</td>\n",
       "      <td>[امرأة, في, قميص, أزرق, يقفز, فوق, الماء]</td>\n",
       "      <td>7</td>\n",
       "      <td>[امرأ, +, ة, صغير, +, ة, في, ال, +, ماء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>[مجموعة, من, الأطفال, الصغار, يجلسون, على, مقعد]</td>\n",
       "      <td>7</td>\n",
       "      <td>[مجموع, +, ة, من, ال, +, أطفال, و, +, ال, +, أ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>[رجل, يتسلق, الصخور]</td>\n",
       "      <td>3</td>\n",
       "      <td>[رجل, يرتدي, قميص, +, ا, أحمر, و, +, قبع, +, ة]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  \\\n",
       "0    1056338697_4f7d7ce270.jpg   \n",
       "1     106490881_5a2dd9b7bd.jpg   \n",
       "2    1082379191_ec1e53f996.jpg   \n",
       "3    1084040636_97d9633581.jpg   \n",
       "4    1096395242_fc69f0ae5a.jpg   \n",
       "..                         ...   \n",
       "970   925491651_57df3a5b36.jpg   \n",
       "971    96420612_feb18fc6c6.jpg   \n",
       "972   968081289_cdba83ce2e.jpg   \n",
       "973   979383193_0a542a059d.jpg   \n",
       "974   997722733_0cb5439472.jpg   \n",
       "\n",
       "                                       old_hypotheses  old_tok_len  \\\n",
       "0             [رجل, في, قميص, أزرق, يقفز, في, الهواء]            7   \n",
       "1      [صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]            8   \n",
       "2           [رجل, يجلس, على, لوح, التزلج, في, الهواء]            7   \n",
       "3                       [كلب, أبيض, يركض, على, العشب]            5   \n",
       "4                       [صبي, صغير, يلعب, في, الشارع]            5   \n",
       "..                                                ...          ...   \n",
       "970                      [كلب, أبيض, يركض, في, الماء]            5   \n",
       "971           [رجل, في, قميص, أبيض, يقفز, فوق, منحدر]            7   \n",
       "972         [امرأة, في, قميص, أزرق, يقفز, فوق, الماء]            7   \n",
       "973  [مجموعة, من, الأطفال, الصغار, يجلسون, على, مقعد]            7   \n",
       "974                              [رجل, يتسلق, الصخور]            3   \n",
       "\n",
       "                                            hypotheses  tok_len  \n",
       "0             [فتا, +, ة, صغير, +, ة, في, ال, +, هواء]       10  \n",
       "1                    [صبي, صغير, يقفز, في, ال, +, ماء]        7  \n",
       "2    [رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...       13  \n",
       "3    [ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...       19  \n",
       "4    [فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...       19  \n",
       "..                                                 ...      ...  \n",
       "970                        [كلب, يركض, في, ال, +, ماء]        6  \n",
       "971  [رجل, يرتدي, قميص, +, ا, أحمر, و, +, أسود, +, ...       17  \n",
       "972           [امرأ, +, ة, صغير, +, ة, في, ال, +, ماء]       10  \n",
       "973  [مجموع, +, ة, من, ال, +, أطفال, و, +, ال, +, أ...       22  \n",
       "974    [رجل, يرتدي, قميص, +, ا, أحمر, و, +, قبع, +, ة]       11  \n",
       "\n",
       "[975 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(rest_df, on='file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.merge(rest_df, on='file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>old_hypotheses</th>\n",
       "      <th>old_tok_len</th>\n",
       "      <th>hypotheses</th>\n",
       "      <th>tok_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2317714088_bcd081f926.jpg</td>\n",
       "      <td>[مجموعة, من, الناس, يجلسون, على, الثلج]</td>\n",
       "      <td>6</td>\n",
       "      <td>[رجل, +, ان, يقف, +, ان, في, ال, +, ثلج]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>[مجموعة, من, الأطفال, الصغار, يجلسون, على, مقعد]</td>\n",
       "      <td>7</td>\n",
       "      <td>[مجموع, +, ة, من, ال, +, أطفال, و, +, ال, +, أ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>541063517_35044c554a.jpg</td>\n",
       "      <td>[رجل, يقف, على, قمة, جبل]</td>\n",
       "      <td>5</td>\n",
       "      <td>[رجل, يقف, على, ال, +, جبل]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>3015863181_92ff43f4d8.jpg</td>\n",
       "      <td>[فتاة, صغيرة, في, قميص, أبيض]</td>\n",
       "      <td>5</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, في, ال, +, شارع]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2938120171_970564e3d8.jpg</td>\n",
       "      <td>[كلب, بني, يركض, على, طول, العشب]</td>\n",
       "      <td>6</td>\n",
       "      <td>[اثنين, من, ال, +, كلاب, يلعب, +, ان, في, ال, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>3256043809_47258e0b3e.jpg</td>\n",
       "      <td>[كلب, أبيض, وأسود, يركض, في, الثلج]</td>\n",
       "      <td>6</td>\n",
       "      <td>[اثنين, من, ال, +, كلاب, يلعب, +, ون, في, ال, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1404832008_68e432665b.jpg</td>\n",
       "      <td>[فتاة, صغيرة, في, الماء]</td>\n",
       "      <td>4</td>\n",
       "      <td>[رجل, يقفز, في, ال, +, ماء]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>820169182_f5e78d7d19.jpg</td>\n",
       "      <td>[طفل, صغير, يلعب, في, الهواء]</td>\n",
       "      <td>5</td>\n",
       "      <td>[طفل, +, ان, يلعب, +, ان, في, ال, +, هواء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2831217847_555b2f95ca.jpg</td>\n",
       "      <td>[سيارة, سيارة, حمراء]</td>\n",
       "      <td>3</td>\n",
       "      <td>[سيار, +, ة, صغير, +, ة, في, ال, +, ماء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2594902417_f65d8866a8.jpg</td>\n",
       "      <td>[اثنين, من, الكلاب, تلعب, في, حقل]</td>\n",
       "      <td>6</td>\n",
       "      <td>[اثنين, من, ال, +, كلاب, يلعب, +, ان, في, ال, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2909875716_25c8652614.jpg</td>\n",
       "      <td>[فتاة, صغيرة, في, ثوب, أبيض, وأسود, في, حقل]</td>\n",
       "      <td>8</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, صغير, +, ة, في, ال, +,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2649406158_ded6be38de.jpg</td>\n",
       "      <td>[كلب, يركض, على, مسار]</td>\n",
       "      <td>4</td>\n",
       "      <td>[ال, +, كلب, ال, +, بني, و, +, ال, +, بني, و, ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>494921598_af73bda568.jpg</td>\n",
       "      <td>[رجل, يرتدي, سترة, حمراء]</td>\n",
       "      <td>4</td>\n",
       "      <td>[لاعب, كر, +, ة, ال, +, قدم]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2103568100_5d018c495b.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, في, الماء]</td>\n",
       "      <td>5</td>\n",
       "      <td>[كلب, +, ان, يلعب, +, ان, في, ال, +, ماء]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2285570521_05015cbf4b.jpg</td>\n",
       "      <td>[شخص, يتزلج, على, تلة, ثلجي]</td>\n",
       "      <td>5</td>\n",
       "      <td>[ال, +, متزلج, في, ال, +, ثلج]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2883099128_0b056eed9e.jpg</td>\n",
       "      <td>[صبي, في, قميص, أزرق, يلعب, كرة, التنس]</td>\n",
       "      <td>7</td>\n",
       "      <td>[صبي, صغير, يقفز, في, ال, +, هواء]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>766099402_cdda6964f0.jpg</td>\n",
       "      <td>[امرأة, في, قميص, أحمر, &lt;unk&gt;, &lt;unk&gt;]</td>\n",
       "      <td>6</td>\n",
       "      <td>[امرأ, +, ة, في, ال, +, شارع]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2866254827_9a8f592017.jpg</td>\n",
       "      <td>[رجل, يركب, دراجة, نارية, في, الشارع]</td>\n",
       "      <td>6</td>\n",
       "      <td>[رجل, يركب, دراج, +, ة, ناري, +, ة]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3071676551_a65741e372.jpg</td>\n",
       "      <td>[رجل, يركب, موجة]</td>\n",
       "      <td>3</td>\n",
       "      <td>[راكب, ال, +, أمواج, في, ال, +, ماء]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2419221084_01a14176b4.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, على, العشب]</td>\n",
       "      <td>5</td>\n",
       "      <td>[اثنين, من, ال, +, كلاب, يلعب, +, ون, في, ال, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_name  \\\n",
       "197  2317714088_bcd081f926.jpg   \n",
       "973   979383193_0a542a059d.jpg   \n",
       "932   541063517_35044c554a.jpg   \n",
       "461  3015863181_92ff43f4d8.jpg   \n",
       "430  2938120171_970564e3d8.jpg   \n",
       "604  3256043809_47258e0b3e.jpg   \n",
       "50   1404832008_68e432665b.jpg   \n",
       "962   820169182_f5e78d7d19.jpg   \n",
       "378  2831217847_555b2f95ca.jpg   \n",
       "299  2594902417_f65d8866a8.jpg   \n",
       "412  2909875716_25c8652614.jpg   \n",
       "324  2649406158_ded6be38de.jpg   \n",
       "904   494921598_af73bda568.jpg   \n",
       "127  2103568100_5d018c495b.jpg   \n",
       "181  2285570521_05015cbf4b.jpg   \n",
       "399  2883099128_0b056eed9e.jpg   \n",
       "957   766099402_cdda6964f0.jpg   \n",
       "391  2866254827_9a8f592017.jpg   \n",
       "489  3071676551_a65741e372.jpg   \n",
       "229  2419221084_01a14176b4.jpg   \n",
       "\n",
       "                                       old_hypotheses  old_tok_len  \\\n",
       "197           [مجموعة, من, الناس, يجلسون, على, الثلج]            6   \n",
       "973  [مجموعة, من, الأطفال, الصغار, يجلسون, على, مقعد]            7   \n",
       "932                         [رجل, يقف, على, قمة, جبل]            5   \n",
       "461                     [فتاة, صغيرة, في, قميص, أبيض]            5   \n",
       "430                 [كلب, بني, يركض, على, طول, العشب]            6   \n",
       "604               [كلب, أبيض, وأسود, يركض, في, الثلج]            6   \n",
       "50                           [فتاة, صغيرة, في, الماء]            4   \n",
       "962                     [طفل, صغير, يلعب, في, الهواء]            5   \n",
       "378                             [سيارة, سيارة, حمراء]            3   \n",
       "299                [اثنين, من, الكلاب, تلعب, في, حقل]            6   \n",
       "412      [فتاة, صغيرة, في, ثوب, أبيض, وأسود, في, حقل]            8   \n",
       "324                            [كلب, يركض, على, مسار]            4   \n",
       "904                         [رجل, يرتدي, سترة, حمراء]            4   \n",
       "127                      [كلب, أبيض, يركض, في, الماء]            5   \n",
       "181                      [شخص, يتزلج, على, تلة, ثلجي]            5   \n",
       "399           [صبي, في, قميص, أزرق, يلعب, كرة, التنس]            7   \n",
       "957             [امرأة, في, قميص, أحمر, <unk>, <unk>]            6   \n",
       "391             [رجل, يركب, دراجة, نارية, في, الشارع]            6   \n",
       "489                                 [رجل, يركب, موجة]            3   \n",
       "229                     [كلب, أبيض, يركض, على, العشب]            5   \n",
       "\n",
       "                                            hypotheses  tok_len  \n",
       "197           [رجل, +, ان, يقف, +, ان, في, ال, +, ثلج]       10  \n",
       "973  [مجموع, +, ة, من, ال, +, أطفال, و, +, ال, +, أ...       22  \n",
       "932                        [رجل, يقف, على, ال, +, جبل]        6  \n",
       "461           [فتا, +, ة, صغير, +, ة, في, ال, +, شارع]       10  \n",
       "430  [اثنين, من, ال, +, كلاب, يلعب, +, ان, في, ال, ...       12  \n",
       "604  [اثنين, من, ال, +, كلاب, يلعب, +, ون, في, ال, ...       12  \n",
       "50                         [رجل, يقفز, في, ال, +, ماء]        6  \n",
       "962         [طفل, +, ان, يلعب, +, ان, في, ال, +, هواء]       10  \n",
       "378           [سيار, +, ة, صغير, +, ة, في, ال, +, ماء]       10  \n",
       "299  [اثنين, من, ال, +, كلاب, يلعب, +, ان, في, ال, ...       12  \n",
       "412  [فتا, +, ة, صغير, +, ة, صغير, +, ة, في, ال, +,...       13  \n",
       "324  [ال, +, كلب, ال, +, بني, و, +, ال, +, بني, و, ...       41  \n",
       "904                       [لاعب, كر, +, ة, ال, +, قدم]        7  \n",
       "127          [كلب, +, ان, يلعب, +, ان, في, ال, +, ماء]       10  \n",
       "181                     [ال, +, متزلج, في, ال, +, ثلج]        7  \n",
       "399                 [صبي, صغير, يقفز, في, ال, +, هواء]        7  \n",
       "957                      [امرأ, +, ة, في, ال, +, شارع]        7  \n",
       "391                [رجل, يركب, دراج, +, ة, ناري, +, ة]        8  \n",
       "489               [راكب, ال, +, أمواج, في, ال, +, ماء]        8  \n",
       "229  [اثنين, من, ال, +, كلاب, يلعب, +, ون, في, ال, ...       12  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['old_captions'] = full_df.old_hypotheses.apply(lambda x: \" \".join(i for i in x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['captions'] = full_df.hypotheses.apply(lambda x: arabert_prep.unpreprocess(' '.join(w for w in x))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>old_hypotheses</th>\n",
       "      <th>old_tok_len</th>\n",
       "      <th>hypotheses</th>\n",
       "      <th>tok_len</th>\n",
       "      <th>old_captions</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[رجل, في, قميص, أزرق, يقفز, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, في, ال, +, هواء]</td>\n",
       "      <td>10</td>\n",
       "      <td>رجل في قميص أزرق يقفز في الهواء</td>\n",
       "      <td>فتاة صغيرة في الهواء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>[صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]</td>\n",
       "      <td>8</td>\n",
       "      <td>[صبي, صغير, يقفز, في, ال, +, ماء]</td>\n",
       "      <td>7</td>\n",
       "      <td>صبي صغير في قميص أزرق يركض على الشاطئ</td>\n",
       "      <td>صبي صغير يقفز في الماء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>[رجل, يجلس, على, لوح, التزلج, في, الهواء]</td>\n",
       "      <td>7</td>\n",
       "      <td>[رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...</td>\n",
       "      <td>13</td>\n",
       "      <td>رجل يجلس على لوح التزلج في الهواء</td>\n",
       "      <td>رجل وامرأة يقفان في الماء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>[كلب, أبيض, يركض, على, العشب]</td>\n",
       "      <td>5</td>\n",
       "      <td>[ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...</td>\n",
       "      <td>19</td>\n",
       "      <td>كلب أبيض يركض على العشب</td>\n",
       "      <td>الكلب الكلب البني والأبيض والأبيض</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096395242_fc69f0ae5a.jpg</td>\n",
       "      <td>[صبي, صغير, يلعب, في, الشارع]</td>\n",
       "      <td>5</td>\n",
       "      <td>[فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...</td>\n",
       "      <td>19</td>\n",
       "      <td>صبي صغير يلعب في الشارع</td>\n",
       "      <td>فتاة صغيرة صغيرة صغيرة صغيرة في الشارع</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name                                  old_hypotheses  \\\n",
       "0  1056338697_4f7d7ce270.jpg         [رجل, في, قميص, أزرق, يقفز, في, الهواء]   \n",
       "1   106490881_5a2dd9b7bd.jpg  [صبي, صغير, في, قميص, أزرق, يركض, على, الشاطئ]   \n",
       "2  1082379191_ec1e53f996.jpg       [رجل, يجلس, على, لوح, التزلج, في, الهواء]   \n",
       "3  1084040636_97d9633581.jpg                   [كلب, أبيض, يركض, على, العشب]   \n",
       "4  1096395242_fc69f0ae5a.jpg                   [صبي, صغير, يلعب, في, الشارع]   \n",
       "\n",
       "   old_tok_len                                         hypotheses  tok_len  \\\n",
       "0            7           [فتا, +, ة, صغير, +, ة, في, ال, +, هواء]       10   \n",
       "1            8                  [صبي, صغير, يقفز, في, ال, +, ماء]        7   \n",
       "2            7  [رجل, و, +, امرأ, +, ة, يقف, +, ان, في, ال, +,...       13   \n",
       "3            5  [ال, +, كلب, ال, +, كلب, ال, +, بني, و, +, ال,...       19   \n",
       "4            5  [فتا, +, ة, صغير, +, ة, صغير, +, ة, صغير, +, ة...       19   \n",
       "\n",
       "                            old_captions  \\\n",
       "0        رجل في قميص أزرق يقفز في الهواء   \n",
       "1  صبي صغير في قميص أزرق يركض على الشاطئ   \n",
       "2      رجل يجلس على لوح التزلج في الهواء   \n",
       "3                كلب أبيض يركض على العشب   \n",
       "4                صبي صغير يلعب في الشارع   \n",
       "\n",
       "                                 captions  \n",
       "0                    فتاة صغيرة في الهواء  \n",
       "1                  صبي صغير يقفز في الماء  \n",
       "2               رجل وامرأة يقفان في الماء  \n",
       "3       الكلب الكلب البني والأبيض والأبيض  \n",
       "4  فتاة صغيرة صغيرة صغيرة صغيرة في الشارع  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_json('results_comparison.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
